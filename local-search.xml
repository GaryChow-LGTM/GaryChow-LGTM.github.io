<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Flink FileSystemTableSink Code Intro</title>
    <link href="/2025/07/14/Flink-FileSystemTableSink-Code-Intro/"/>
    <url>/2025/07/14/Flink-FileSystemTableSink-Code-Intro/</url>
    
    <content type="html"><![CDATA[<h1 id="æºç åˆ†æ-Flink-FileSystemTableSink-ä¸­è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥çš„åˆ›å»ºä¸è°ƒç”¨æœºåˆ¶è¯¦è§£"><a href="#æºç åˆ†æ-Flink-FileSystemTableSink-ä¸­è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥çš„åˆ›å»ºä¸è°ƒç”¨æœºåˆ¶è¯¦è§£" class="headerlink" title="æºç åˆ†æ - Flink FileSystemTableSink ä¸­è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥çš„åˆ›å»ºä¸è°ƒç”¨æœºåˆ¶è¯¦è§£"></a>æºç åˆ†æ - Flink FileSystemTableSink ä¸­è‡ªå®šä¹‰åˆ†åŒºç­–ç•¥çš„åˆ›å»ºä¸è°ƒç”¨æœºåˆ¶è¯¦è§£</h1><p>åœ¨ä½¿ç”¨ Flink é€šè¿‡ Table API æˆ– SQL å†™å…¥æ–‡ä»¶ç³»ç»Ÿæ—¶ï¼Œè‹¥å¯ç”¨äº†è‡ªå®šä¹‰åˆ†åŒºï¼Œç³»ç»Ÿå¦‚ä½•æ³¨å…¥å¹¶åº”ç”¨å‚æ•° sink.partition-commit.policy.kind æ¥æ§åˆ¶åˆ†åŒºæäº¤è¡Œä¸ºï¼Ÿæœ¬æ–‡å°†ä»æºç è§’åº¦æ¢³ç†è¿™å¥—æœºåˆ¶çš„è°ƒç”¨è·¯å¾„ä¸å®ç°ç»†èŠ‚ã€‚</p><p>æœ¬äººå®ç°çš„ [FLINK-32388]Add the ability to pass parameters to CUSTOM PartitionCommitPolicy <a href="https://github.com/apache/flink/pull/22831">https://github.com/apache/flink/pull/22831</a> ä¹Ÿæ˜¯åŸºäºæœ¬ç¯‡æ–‡ç« çš„æºç åˆ†æè€Œå®ç°çš„ã€‚</p><p>ç¤ºä¾‹ï¼š</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"># é…ç½®åŒç­–ç•¥é“¾ï¼ˆå…ƒæ•°æ®æäº¤+è‡ªå®šä¹‰ï¼‰<br>sink.partition-commit.policy.kind: custom<br><br># è‡ªå®šä¹‰ç­–ç•¥é…ç½®<br>sink.partition-commit.policy.custom.class: com.company.CustomPolicy<br>sink.partition-commit.policy.custom.parameters: param1,param2<br></code></pre></td></tr></table></figure><hr><h2 id="ä¸€ã€è°ƒç”¨é“¾æ¦‚è§ˆï¼šå‚æ•°ä½œç”¨äºå“ªé‡Œï¼Ÿ"><a href="#ä¸€ã€è°ƒç”¨é“¾æ¦‚è§ˆï¼šå‚æ•°ä½œç”¨äºå“ªé‡Œï¼Ÿ" class="headerlink" title="ä¸€ã€è°ƒç”¨é“¾æ¦‚è§ˆï¼šå‚æ•°ä½œç”¨äºå“ªé‡Œï¼Ÿ"></a><strong>ä¸€ã€è°ƒç”¨é“¾æ¦‚è§ˆï¼šå‚æ•°ä½œç”¨äºå“ªé‡Œï¼Ÿ</strong></h2><p>å½“ç”¨æˆ·æäº¤ Flink SQL ä½œä¸šï¼ŒFileSystemTableSink ä¼šä½œä¸º TableSink å‚ä¸ç‰©ç†æ‰§è¡Œè®¡åˆ’çš„æ„å»ºã€‚å…¶æ ¸å¿ƒçš„å‚æ•°å¤„ç†é€»è¾‘å‘ç”Ÿåœ¨å¦‚ä¸‹è°ƒç”¨é“¾ä¸­ï¼š</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">translateToPlanInternal</span><br> â””â”€â”€ createSinkTransformation<br>     â””â”€â”€ getSinkRuntimeProvider<br>         â””â”€â”€ consumeDataStream<br>             â””â”€â”€ consume<br>                 â””â”€â”€ createStreamingSink<br>                     â””â”€â”€ sinkï¼ˆåˆ›å»º PartitionCommitterï¼‰<br>                         â””â”€â”€ initializeStateï¼ˆæ„å»ºç­–ç•¥é“¾ï¼‰<br></code></pre></td></tr></table></figure><hr><h2 id="äºŒã€ç‰©ç†è®¡åˆ’è½¬æ¢ï¼šä»-Plan-åˆ°-Sink-çš„è½¬åŒ–"><a href="#äºŒã€ç‰©ç†è®¡åˆ’è½¬æ¢ï¼šä»-Plan-åˆ°-Sink-çš„è½¬åŒ–" class="headerlink" title="äºŒã€ç‰©ç†è®¡åˆ’è½¬æ¢ï¼šä» Plan åˆ° Sink çš„è½¬åŒ–"></a><strong>äºŒã€ç‰©ç†è®¡åˆ’è½¬æ¢ï¼šä» Plan åˆ° Sink çš„è½¬åŒ–</strong></h2><p>Flink Planner åœ¨æ„é€ ç‰©ç†æ‰§è¡Œè®¡åˆ’æ—¶ï¼ˆTransformation æˆ– DataStreamï¼‰ï¼Œä¼šè°ƒç”¨ TableSink çš„ translateToPlanInternal æ–¹æ³•ã€‚åœ¨æµå¼å†™å…¥æ–‡ä»¶ç³»ç»Ÿæ—¶ï¼Œæœ€ç»ˆä¼šè¿›å…¥ consume æ–¹æ³•ä¸­ï¼š</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> SinkRuntimeProvider <span class="hljs-title function_">getSinkRuntimeProvider</span><span class="hljs-params">(Context sinkContext)</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">DataStreamSinkProvider</span>() &#123;<br>        <span class="hljs-meta">@Override</span><br>        <span class="hljs-keyword">public</span> DataStreamSink&lt;?&gt; consumeDataStream(<br>                ProviderContext providerContext, DataStream&lt;RowData&gt; dataStream) &#123;<br>            <span class="hljs-keyword">return</span> consume(providerContext, dataStream, sinkContext);<br>        &#125;<br>    &#125;;<br>&#125;<br></code></pre></td></tr></table></figure><p>é€šè¿‡â€æ•°æ®æ˜¯å¦æœ‰ç•Œâ€æ¥åˆ¤æ–­æ˜¯å¦æ˜¯æµå¤„ç†ï¼ˆunboundedï¼‰ï¼š</p><ul><li>è‹¥ä¸ºæµæ¨¡å¼ï¼Œåˆ™è¿›å…¥ createStreamingSinkï¼Œæ„å»º FileSystemSinkï¼›</li><li>å¦åˆ™ä½¿ç”¨ createBatchSink æ‰§è¡Œæ‰¹é‡è¾“å‡ºã€‚</li></ul><hr><h2 id="ä¸‰ã€ç­–ç•¥é“¾æ„å»ºæ ¸å¿ƒï¼šcreateStreamingSink-sink"><a href="#ä¸‰ã€ç­–ç•¥é“¾æ„å»ºæ ¸å¿ƒï¼šcreateStreamingSink-sink" class="headerlink" title="ä¸‰ã€ç­–ç•¥é“¾æ„å»ºæ ¸å¿ƒï¼šcreateStreamingSink -&gt; sink"></a><strong>ä¸‰ã€ç­–ç•¥é“¾æ„å»ºæ ¸å¿ƒï¼šcreateStreamingSink -&gt; sink</strong></h2><p>createStreamingSink ä¸­æœ€å…³é”®çš„è°ƒç”¨æ˜¯ sink() æ–¹æ³•ï¼Œè´Ÿè´£å°†æ•°æ®å†™å…¥æ–‡ä»¶ç³»ç»Ÿå¹¶æ‰§è¡Œåˆ†åŒºæäº¤ç­–ç•¥ï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§å’Œå¯è§æ€§ã€‚</p><p>å®ƒè´Ÿè´£æœ€ç»ˆåˆ›å»ºåˆ†åŒºæäº¤ç»„ä»¶ PartitionCommitterï¼Œå¹¶å°†å…¶ä¸ writerStream è¿›è¡Œè¿æ¥ï¼š</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> DataStreamSink&lt;?&gt; sink(<br>    ProviderContext providerContext,<br>    DataStream&lt;PartitionCommitInfo&gt; writerStream,<br>    Path path,<br>    ObjectIdentifier tableIdentifier,<br>    List&lt;String&gt; partitionKeys,<br>    TableMetaStoreFactory metaStoreFactory,<br>    FileSystemFactory fsFactory,<br>    ReadableConfig tableOptions<br>) &#123;<br>    <span class="hljs-comment">// å‚æ•°åˆ¤æ–­ï¼šæ˜¯å¦å¯ç”¨åˆ†åŒºæäº¤ç­–ç•¥</span><br>    <span class="hljs-keyword">if</span> (partitionKeys.size() &gt; <span class="hljs-number">0</span> &amp;&amp; options.contains(SINK_PARTITION_COMMIT_POLICY_KIND)) &#123;<br>        <span class="hljs-comment">// æ„å»ºæäº¤å™¨</span><br>        <span class="hljs-type">PartitionCommitter</span> <span class="hljs-variable">committer</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">PartitionCommitter</span>(<br>            path, tableIdentifier, partitionKeys, metaStoreFactory, fsFactory, tableOptions.toConfiguration()<br>        );<br>        <span class="hljs-keyword">return</span> writerStream.transform(<span class="hljs-string">&quot;Partition Committer&quot;</span>, committer);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><hr><h2 id="å››ã€è¿è¡Œæ—¶ç­–ç•¥é“¾æ„å»ºæœºåˆ¶-PartitionCommitter"><a href="#å››ã€è¿è¡Œæ—¶ç­–ç•¥é“¾æ„å»ºæœºåˆ¶-PartitionCommitter" class="headerlink" title="å››ã€è¿è¡Œæ—¶ç­–ç•¥é“¾æ„å»ºæœºåˆ¶: PartitionCommitter"></a><strong>å››ã€è¿è¡Œæ—¶ç­–ç•¥é“¾æ„å»ºæœºåˆ¶: PartitionCommitter</strong></h2><p>åœ¨ Flink Job å¯åŠ¨æˆ–æ¢å¤æ—¶ï¼ŒPartitionCommitter.initializeState() è¢«è‡ªåŠ¨è°ƒç”¨ï¼š</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">initializeState</span><span class="hljs-params">(StateInitializationContext context)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>    <span class="hljs-type">PartitionCommitPolicyFactory</span> <span class="hljs-variable">factory</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">PartitionCommitPolicyFactory</span>(<br>        conf.get(SINK_PARTITION_COMMIT_POLICY_KIND),     <span class="hljs-comment">// å¦‚ &quot;metastore,success-file&quot;</span><br>        conf.get(SINK_PARTITION_COMMIT_POLICY_CLASS),     <span class="hljs-comment">// è‡ªå®šä¹‰ç±»åï¼ˆå¯é€‰ï¼‰</span><br>        conf.get(SINK_PARTITION_COMMIT_SUCCESS_FILE_NAME), <span class="hljs-comment">// success-file ç­–ç•¥ç”¨</span><br>        conf.get(SINK_PARTITION_COMMIT_POLICY_CLASS_PARAMETERS) <span class="hljs-comment">// è‡ªå®šä¹‰ç±»å‚æ•°ï¼ˆå¯é€‰ï¼‰</span><br>    );<br>    <span class="hljs-built_in">this</span>.policies = factory.createPolicyChain(<br>        getUserCodeClassloader(), <span class="hljs-comment">// ç”¨æˆ·ç±»åŠ è½½å™¨</span><br>        () -&gt; &#123; <span class="hljs-comment">// è·å–æ–‡ä»¶ç³»ç»Ÿå®ä¾‹çš„å·¥å‚</span><br>            <span class="hljs-keyword">try</span> &#123;<br>                <span class="hljs-keyword">return</span> fsFactory.create(locationPath.toUri());<br>            &#125; <span class="hljs-keyword">catch</span> (IOException e) &#123;<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">RuntimeException</span>(e);<br>            &#125;<br>        &#125;<br>    );<br>&#125;<br></code></pre></td></tr></table></figure><hr><h2 id="äº”ã€ç­–ç•¥å·¥å‚-PartitionCommitPolicyFactory-çš„æ ¸å¿ƒé€»è¾‘"><a href="#äº”ã€ç­–ç•¥å·¥å‚-PartitionCommitPolicyFactory-çš„æ ¸å¿ƒé€»è¾‘" class="headerlink" title="äº”ã€ç­–ç•¥å·¥å‚ PartitionCommitPolicyFactory çš„æ ¸å¿ƒé€»è¾‘"></a><strong>äº”ã€ç­–ç•¥å·¥å‚ PartitionCommitPolicyFactory çš„æ ¸å¿ƒé€»è¾‘</strong></h2><p>ç­–ç•¥é“¾çš„åˆ›å»ºä¼šç”¨åˆ°ç”¨æˆ·è‡ªå®šä¹‰ç±»çš„ç±»åŠ è½½å™¨(UserCodeClassloader)å’Œæ–‡ä»¶ç³»ç»Ÿå·¥å‚(FileSystemÂ factory)ï¼Œç¡®ä¿ç­–ç•¥èƒ½å¤Ÿæ­£ç¡®åŠ è½½ç”¨æˆ·ä»£ç å’Œæ“ä½œåˆ†åŒºæ–‡ä»¶ç³»ç»Ÿã€‚</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/** Create a policy chain. */</span><br><span class="hljs-keyword">public</span> List&lt;PartitionCommitPolicy&gt; <span class="hljs-title function_">createPolicyChain</span><span class="hljs-params">(</span><br><span class="hljs-params">        ClassLoader cl, Supplier&lt;FileSystem&gt; fsSupplier)</span> &#123;<br>    String[] policyStrings = policyKind.split(<span class="hljs-string">&quot;,&quot;</span>);<br>    <span class="hljs-keyword">return</span> Arrays.stream(policyStrings)<br>            .map(<br>                    name -&gt; &#123;<br>                        <span class="hljs-keyword">switch</span> (name.toLowerCase()) &#123;<br>                            <span class="hljs-keyword">case</span> PartitionCommitPolicy.METASTORE:<br>                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">MetastoreCommitPolicy</span>();<br>                            <span class="hljs-keyword">case</span> PartitionCommitPolicy.SUCCESS_FILE:<br>                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SuccessFileCommitPolicy</span>(<br>                                        successFileName, fsSupplier.get());<br>                            <span class="hljs-keyword">case</span> PartitionCommitPolicy.CUSTOM:<br>                                <span class="hljs-keyword">try</span> &#123;<br>                                    <span class="hljs-keyword">if</span> (parameters != <span class="hljs-literal">null</span> &amp;&amp; !parameters.isEmpty()) &#123;<br>                                        String[] paramStrings =<br>                                                parameters.toArray(<span class="hljs-keyword">new</span> <span class="hljs-title class_">String</span>[<span class="hljs-number">0</span>]);<br>                                        Class&lt;?&gt;[] classes = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Class</span>&lt;?&gt;[parameters.size()];<br>                                        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; i &lt; parameters.size(); i++) &#123;<br>                                            classes[i] = String.class;<br>                                        &#125;<br>                                        <span class="hljs-keyword">return</span> (PartitionCommitPolicy)<br>                                                cl.loadClass(customClass)<br>                                                        .getConstructor(classes)<br>                                                        .newInstance((Object[]) paramStrings);<br>                                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                                        <span class="hljs-keyword">return</span> (PartitionCommitPolicy)<br>                                                cl.loadClass(customClass).newInstance();<br>                                    &#125;&#125;&#125;&#125;&#125;)<br>            .collect(Collectors.toList());&#125;<br>&#125;<br></code></pre></td></tr></table></figure><blockquote><p>ğŸ’¡ å…³é”®ç‚¹ï¼šè‡ªå®šä¹‰ç±»å¿…é¡»å®ç° PartitionCommitPolicy æ¥å£ï¼Œå¹¶æä¾›åˆé€‚çš„æ„é€ æ–¹æ³•ï¼ˆå¸¦å‚æˆ–æ— å‚å‡å¯ï¼‰ã€‚</p></blockquote><hr><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a><strong>æ€»ç»“</strong></h2><p>å‚æ•°å¦‚ <code>sink.partition-commit.policy.kind = metastore,success-file</code> çš„æ³¨å…¥ç”Ÿæ•ˆæµç¨‹å¦‚ä¸‹ï¼š</p><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs isbl">ç”¨æˆ·é…ç½®<br>  â†“<br><span class="hljs-variable">FileSystemTableSink</span> -&gt; <span class="hljs-function"><span class="hljs-title">sink</span>()</span><br>  â†“<br>æ„é€  <span class="hljs-variable">PartitionCommitter</span><br>  â†“<br><span class="hljs-function"><span class="hljs-title">initializeState</span>()</span><br>  â†“<br><span class="hljs-variable">PartitionCommitPolicyFactory</span> -&gt; <span class="hljs-function"><span class="hljs-title">createPolicyChain</span>()</span><br>  â†“<br>åˆ›å»ºç­–ç•¥å®ä¾‹ â†’ æ„æˆç­–ç•¥é“¾ â†’ å®ç° <span class="hljs-variable">PartitionCommitter</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>CodeDive</tag>
      
      <tag>Apache Flink</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ingress and Route53 Issues with Druid AWS Deployments</title>
    <link href="/2025/03/19/ingress-and-route53-issues-with-druid-aws-deployments/"/>
    <url>/2025/03/19/ingress-and-route53-issues-with-druid-aws-deployments/</url>
    
    <content type="html"><![CDATA[<h1 id="Ingress-and-Route53-Issues-with-Druid-AWS-Deployments"><a href="#Ingress-and-Route53-Issues-with-Druid-AWS-Deployments" class="headerlink" title="Ingress and Route53 Issues with Druid AWS Deployments"></a>Ingress and Route53 Issues with Druid AWS Deployments</h1><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p> When deploying Druid with Kubernetes on AWS, it is common to use AWS ALB (Application Load Balancer) for traffic routing and load balancing. By configuring Kubernetesâ€™ Ingress resource, ALB can route traffic to different services. At the same time, Route 53 needs to be configured to handle DNS domain name resolution so that applications can be accessed via domain names.</p><p> This configuration example shows how to set up the AWS ALB Ingress Controller to associate with the Kubernetes Ingress resource.</p><h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><ol><li><p><strong>Obtaining the ALB Certificate ARN</strong>: If you need to configure an SSL&#x2F;TLS certificate for ALB, you can obtain the certificate ARN through AWS ACM (AWS Certificate Manager), which <strong>you need to request from the SRE team</strong>. This certificate is used for HTTPS configuration. The following is a sample configuration:</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">ingress:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">alb-ingress-route</span><br>  <span class="hljs-attr">domain:</span> <span class="hljs-string">druid-1.net</span><br>  <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br><br><span class="hljs-attr">ingress2:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">alb-ingress2-route</span><br>  <span class="hljs-attr">domain:</span> <span class="hljs-string">druid-2.net</span><br>  <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br><br><span class="hljs-attr">ingressClass:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">alb</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/certificate-arn:</span> <span class="hljs-string">arn:aws:acm:xxx</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/subnets:</span> <span class="hljs-string">sub-xxx</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/group.name:</span> <span class="hljs-string">druid</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/healthcheck-path:</span> <span class="hljs-string">/status/health</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/healthcheck-port:</span> <span class="hljs-string">&quot;8888&quot;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/listen-ports:</span> <span class="hljs-string">&#x27;[&#123;&quot;HTTP&quot;: 80&#125;, &#123;&quot;HTTPS&quot;: 443&#125;]&#x27;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/manage-backend-security-group-rules:</span> <span class="hljs-string">&quot;true&quot;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/scheme:</span> <span class="hljs-string">internal</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/success-codes:</span> <span class="hljs-string">&quot;200&quot;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/tags:</span> <span class="hljs-string">Owner=Gary</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/target-type:</span> <span class="hljs-string">ip</span><br><br></code></pre></td></tr></table></figure></li><li><p><strong>Get Kubernetes Ingress address</strong>: Query the Ingress resource in Kubernetes via <code>kubectl</code> to get the ALB address. The following is a sample command and output:</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">bwdev get ingress<br>NAME                      CLASS   HOSTS                               ADDRESS                                                                  PORTS   AGE<br>alb-ingress-route         alb     druid-1.net          internal-k8s-druid-xxx.elb.amazonaws.com   80      31d<br>alb-ingress2-route        alb     druid-2.net   internal-k8s-druid-xxx.elb.amazonaws.com   80      31d<br></code></pre></td></tr></table></figure><p>  The <code>ADDRESS</code> field is the DNS address of the AWS ALB. Use it as a record for configuring Route 53.</p></li><li><p><strong>Modify the AWS Route 53 resource</strong>: Configure the appropriate A record or CNAME record for your domain name in AWS Route 53, ensuring that the <code>druid-1.net</code> and <code>druid-2.net</code> domain names point to the DNS address of the ALB (for example: <code>internal-k8s-druid-xxx.elb.amazonaws.com</code> ).</p><p>  In the AWS Route 53 console, perform the following steps:</p><ul><li>Create or update an A record that points to the DNS address of the ALB.</li><li>Ensure that the domain name resolution is set to Public or Private as required.</li></ul><p>  Example record:</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">druid-1.net</span>   <span class="hljs-string">A</span>   <span class="hljs-string">internal-k8s-druid-xxx.elb.amazonaws.com</span><br><span class="hljs-string">druid-2.net</span>   <span class="hljs-string">A</span>   <span class="hljs-string">internal-k8s-druid-xxx.elb.amazonaws.com</span><br></code></pre></td></tr></table></figure></li><li><p><strong>Verify Configuration</strong>: After completing the ALB and Route 53 configuration, you can verify that the ALB is routing traffic properly by accessing domain names such as <code>druid-1.net</code> and <code>druid-2.net</code>.</p></li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p> With the ALB Ingress Controller and Route 53 properly configured, you can route traffic to services in Kubernetes and use AWS-provided certificates for HTTPS encryption. The key steps include obtaining the certificate ARN, querying the Ingress address, and updating the Route 53 configuration. Ensure that all resources and domains are configured correctly to access your application.</p><hr><h1 id="Druid-AWSéƒ¨ç½²çš„ingresså’Œroute53é—®é¢˜"><a href="#Druid-AWSéƒ¨ç½²çš„ingresså’Œroute53é—®é¢˜" class="headerlink" title="Druid AWSéƒ¨ç½²çš„ingresså’Œroute53é—®é¢˜"></a>Druid AWSéƒ¨ç½²çš„ingresså’Œroute53é—®é¢˜</h1><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>åœ¨ AWS ä¸Šä½¿ç”¨ Kubernetes éƒ¨ç½² Druid æ—¶ï¼Œé€šå¸¸ä¼šä½¿ç”¨ AWS ALBï¼ˆApplication Load Balancerï¼‰æ¥è¿›è¡Œæµé‡çš„è·¯ç”±å’Œè´Ÿè½½å‡è¡¡ã€‚é€šè¿‡é…ç½® Kubernetes çš„ Ingress èµ„æºï¼ŒALB å¯ä»¥å°†æµé‡è·¯ç”±åˆ°ä¸åŒçš„æœåŠ¡ã€‚ä¸æ­¤åŒæ—¶ï¼Œè¿˜éœ€è¦é…ç½® Route 53 æ¥å¤„ç† DNS åŸŸåè§£æï¼Œä»¥ä¾¿é€šè¿‡åŸŸåè®¿é—®åº”ç”¨ã€‚</p><p>è¯¥é…ç½®ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•è®¾ç½® AWS ALB Ingress Controller ä¸ Kubernetes Ingress èµ„æºçš„å…³è”ã€‚</p><h2 id="è°ƒè¯•"><a href="#è°ƒè¯•" class="headerlink" title="è°ƒè¯•"></a>è°ƒè¯•</h2><ol><li><p><strong>è·å– ALB è¯ä¹¦ ARN</strong>ï¼šå¦‚æœéœ€è¦ä¸º ALB é…ç½® SSL&#x2F;TLS è¯ä¹¦ï¼Œå¯ä»¥é€šè¿‡ AWS ACMï¼ˆAWS Certificate Managerï¼‰è·å¾—è¯ä¹¦ ARNã€‚<strong>éœ€è¦å‘ SRE å›¢é˜Ÿè¯·æ±‚è¯¥è¯ä¹¦ ARN</strong>ã€‚è¿™ä¸ªè¯ä¹¦ç”¨äº HTTPS é…ç½®ã€‚ä»¥ä¸‹æ˜¯ç¤ºä¾‹é…ç½®ï¼š</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">ingress:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">alb-ingress-route</span><br>  <span class="hljs-attr">domain:</span> <span class="hljs-string">druid-1.net</span><br>  <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br><br><span class="hljs-attr">ingress2:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">alb-ingress2-route</span><br>  <span class="hljs-attr">domain:</span> <span class="hljs-string">druid-2.net</span><br>  <span class="hljs-attr">enabled:</span> <span class="hljs-literal">true</span><br><br><span class="hljs-attr">ingressClass:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">alb</span><br>  <span class="hljs-attr">annotations:</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/certificate-arn:</span> <span class="hljs-string">arn:aws:acm:xxx</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/subnets:</span> <span class="hljs-string">sub-xxx</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/group.name:</span> <span class="hljs-string">druid</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/healthcheck-path:</span> <span class="hljs-string">/status/health</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/healthcheck-port:</span> <span class="hljs-string">&quot;8888&quot;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/listen-ports:</span> <span class="hljs-string">&#x27;[&#123;&quot;HTTP&quot;: 80&#125;, &#123;&quot;HTTPS&quot;: 443&#125;]&#x27;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/manage-backend-security-group-rules:</span> <span class="hljs-string">&quot;true&quot;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/scheme:</span> <span class="hljs-string">internal</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/success-codes:</span> <span class="hljs-string">&quot;200&quot;</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/tags:</span> <span class="hljs-string">Owner=Gary</span><br>    <span class="hljs-attr">alb.ingress.kubernetes.io/target-type:</span> <span class="hljs-string">ip</span><br></code></pre></td></tr></table></figure></li><li><p><strong>è·å– Kubernetes Ingress åœ°å€</strong>ï¼šé€šè¿‡ <code>kubectl</code> æŸ¥è¯¢ Kubernetes ä¸­çš„ Ingress èµ„æºï¼Œè·å– ALB åœ°å€ã€‚ä»¥ä¸‹æ˜¯å‘½ä»¤å’Œè¾“å‡ºç¤ºä¾‹ï¼š</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">bwdev get ingress<br>NAME                      CLASS   HOSTS                               ADDRESS                                                                  PORTS   AGE<br>alb-ingress-route         alb     druid-1.net          internal-k8s-druid-xxx.elb.amazonaws.com   80      31d<br>alb-ingress2-route        alb     druid-2.net   internal-k8s-druid-xxx.elb.amazonaws.com   80      31d<br></code></pre></td></tr></table></figure><p> <code>ADDRESS</code> å­—æ®µå³ä¸º AWS ALB çš„ DNS åœ°å€ã€‚å°†å…¶ç”¨ä½œé…ç½® Route 53 çš„è®°å½•ã€‚</p></li><li><p><strong>ä¿®æ”¹ AWS Route 53 èµ„æº</strong>ï¼šåœ¨ AWS Route 53 ä¸­ä¸ºæ‚¨çš„åŸŸåé…ç½®ç›¸åº”çš„ A è®°å½•æˆ– CNAME è®°å½•ï¼Œç¡®ä¿ <code>druid-1.net</code> å’Œ <code>druid-2.net</code> åŸŸåæŒ‡å‘ ALB çš„ DNS åœ°å€ï¼ˆä¾‹å¦‚ï¼š<code>internal-k8s-druid-xxx.elb.amazonaws.com</code>ï¼‰ã€‚</p><p> åœ¨ AWS Route 53 æ§åˆ¶å°ä¸­ï¼Œæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š</p><ul><li>åˆ›å»ºæˆ–æ›´æ–° A è®°å½•ï¼ŒæŒ‡å‘ ALB çš„ DNS åœ°å€ã€‚</li><li>ç¡®ä¿åŸŸåè§£æè®¾ç½®ä¸ºå…¬å…±æˆ–ç§æœ‰æ ¹æ®éœ€æ±‚ã€‚</li></ul><p> ç¤ºä¾‹è®°å½•ï¼š</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">druid-1.net</span>   <span class="hljs-string">A</span>   <span class="hljs-string">internal-k8s-druid-xxx.elb.amazonaws.com</span><br><span class="hljs-string">druid-2.net</span>   <span class="hljs-string">A</span>   <span class="hljs-string">internal-k8s-druid-xxx.elb.amazonaws.com</span><br></code></pre></td></tr></table></figure></li><li><p><strong>éªŒè¯é…ç½®</strong>ï¼šå®Œæˆ ALB å’Œ Route 53 é…ç½®åï¼Œæ‚¨å¯ä»¥é€šè¿‡è®¿é—®åŸŸåï¼ˆå¦‚ <code>druid-1.net</code> å’Œ <code>druid-2.net</code>ï¼‰éªŒè¯ ALB æ˜¯å¦æ­£å¸¸è·¯ç”±æµé‡ã€‚</p></li></ol><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>é€šè¿‡æ­£ç¡®é…ç½® ALB Ingress Controller å’Œ Route 53ï¼Œæ‚¨å¯ä»¥å°†æµé‡è·¯ç”±åˆ° Kubernetes ä¸­çš„æœåŠ¡ï¼Œå¹¶ä¸”ä½¿ç”¨ AWS æä¾›çš„è¯ä¹¦è¿›è¡Œ HTTPS åŠ å¯†ã€‚å…³é”®çš„æ­¥éª¤åŒ…æ‹¬è·å–è¯ä¹¦ ARNã€æŸ¥è¯¢ Ingress åœ°å€ä»¥åŠæ›´æ–° Route 53 é…ç½®ã€‚ç¡®ä¿æ‰€æœ‰èµ„æºå’ŒåŸŸåé…ç½®æ­£ç¡®ï¼Œä»¥ä¾¿è®¿é—®æ‚¨çš„åº”ç”¨ç¨‹åºã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>Debug</tag>
      
      <tag>Druid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Frame Size Configuration and RowTooLarge Error Resolution in Druid</title>
    <link href="/2025/03/19/Frame-Size-Configuration-and-RowTooLarge-Error-Resolution-in-Druid/"/>
    <url>/2025/03/19/Frame-Size-Configuration-and-RowTooLarge-Error-Resolution-in-Druid/</url>
    
    <content type="html"><![CDATA[<h1 id="Frame-Size-Configuration-and-RowTooLarge-Error-Resolution-in-Druid"><a href="#Frame-Size-Configuration-and-RowTooLarge-Error-Resolution-in-Druid" class="headerlink" title="Frame Size Configuration and RowTooLarge Error Resolution in Druid"></a>Frame Size Configuration and RowTooLarge Error Resolution in Druid</h1><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p> In Apache Druid, data processing usually involves dividing large-scale data into multiple â€œframesâ€ for processing. In this process, the frame size is a key parameter that determines how much data can be processed in each frame. A frame size that is too large or too small can affect performance or cause processing to fail. This error log indicates that while processing a particular piece of data, a row of data was encountered whose size exceeded the specified frame size, causing the task to fail.</p><p> Error Message:</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">RowTooLarge</span>: Encountered row that cannot fit in a single frame (max frame size = <span class="hljs-number">1</span>,<span class="hljs-number">000</span>,<span class="hljs-number">000</span>)<br></code></pre></td></tr></table></figure><p> Indicates that while processing data, Druid encountered a row of data whose size exceeded <code>1,000,000</code> bytes (i.e., <code>STANDARD_FRAME_SIZE</code> ) and was unable to fit the current frame size limit.</p><h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><ol><li><p><strong>Frame Size Configuration</strong>: As you can see from the code snippet, Druidâ€™s default frame size is <code>1,000,000</code> bytes. the value of <code>STANDARD_FRAME_SIZE</code> is statically defined:</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">STANDARD_FRAME_SIZE</span> <span class="hljs-operator">=</span> <span class="hljs-number">1_000_000</span>;<br></code></pre></td></tr></table></figure><p>  This value is used as the standard frame size for memory allocation during Druid task execution:</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java">  <span class="hljs-keyword">final</span> <span class="hljs-type">InputChannels</span> <span class="hljs-variable">inputChannels</span> <span class="hljs-operator">=</span><br>      <span class="hljs-keyword">new</span> <span class="hljs-title class_">InputChannelsImpl</span>(<br>          workOrder.getQueryDefinition(),<br>          InputSlices.allReadablePartitions(workOrder.getInputs()),<br>          inputChannelFactory,<br>          () -&gt; ArenaMemoryAllocator.createOnHeap(frameContext.memoryParameters().getStandardFrameSize()),<br>          exec,<br>          cancellationId<br>      );<br>    <br><span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getStandardFrameSize</span><span class="hljs-params">()</span><br>&#123;<br>  <span class="hljs-keyword">return</span> STANDARD_FRAME_SIZE;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>Task Failure Reason</strong>: The task failed because a row of data exceeded the <code>1,000,000</code> byte size limit and could not fit into a single frame. This error message indicates that during execution, a row of data was too large for the set maximum frame size, causing the task to fail.</p></li><li><p><strong>Modifying the frame size</strong>: If larger rows of data need to be processed, consider increasing the size of <code>STANDARD_FRAME_SIZE</code> to allow larger rows of data to be processed per frame. For example, this could be modified to <code>2,000,000</code> or higher:</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">STANDARD_FRAME_SIZE</span> <span class="hljs-operator">=</span> <span class="hljs-number">2_000_000</span>;<br></code></pre></td></tr></table></figure></li><li><p><strong>Memory Optimization</strong>: Increasing the frame size may increase memory consumption, so there is a trade-off between memory usage and data processing performance. If there is not enough memory, increasing the frame size may cause problems such as memory overflow. When adjusting this value, you need to consider the overall system memory and load.</p></li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p> The task failed because a row of data exceeded the maximum frame size ( <code>1,000,000</code> bytes) configured by Druid. To resolve this issue, you can consider the following options:</p><ol><li><strong>Increase the frame size</strong>: Increase <code>STANDARD_FRAME_SIZE</code> to a larger value, such as <code>2,000,000</code> or higher, to be able to handle larger rows of data.</li><li><strong>Optimize data row size</strong>: If possible, adjust how data is generated to reduce the size of a single row of data.</li><li><strong>Memory management</strong>: Increasing the frame size may increase memory consumption and you need to make sure that the system has enough memory available.</li></ol><p> When adjusting the frame size, it is recommended to test it in conjunction with actual memory usage to avoid other problems caused by insufficient memory.</p><hr><h1 id="Druid-ä¸­å¸§å¤§å°é…ç½®åŠ-RowTooLarge-é”™è¯¯è§£å†³æ–¹æ¡ˆ"><a href="#Druid-ä¸­å¸§å¤§å°é…ç½®åŠ-RowTooLarge-é”™è¯¯è§£å†³æ–¹æ¡ˆ" class="headerlink" title="Druid ä¸­å¸§å¤§å°é…ç½®åŠ RowTooLarge é”™è¯¯è§£å†³æ–¹æ¡ˆ"></a>Druid ä¸­å¸§å¤§å°é…ç½®åŠ RowTooLarge é”™è¯¯è§£å†³æ–¹æ¡ˆ</h1><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>åœ¨ Apache Druid ä¸­ï¼Œæ•°æ®å¤„ç†é€šå¸¸æ¶‰åŠå°†å¤§è§„æ¨¡æ•°æ®åˆ†ä¸ºå¤šä¸ªâ€œå¸§â€ï¼ˆframeï¼‰è¿›è¡Œå¤„ç†ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œå¸§å¤§å°ï¼ˆframe sizeï¼‰æ˜¯ä¸€ä¸ªå…³é”®å‚æ•°ï¼Œå®ƒå†³å®šäº†æ¯ä¸ªå¸§æœ€å¤šå¯ä»¥å¤„ç†å¤šå°‘æ•°æ®ã€‚å¸§å¤§å°è¿‡å¤§æˆ–è¿‡å°éƒ½å¯èƒ½å½±å“æ€§èƒ½æˆ–å¯¼è‡´å¤„ç†å¤±è´¥ã€‚è¯¥é”™è¯¯æ—¥å¿—è¡¨æ˜åœ¨å¤„ç†æŸä¸€æ•°æ®æ—¶ï¼Œé‡åˆ°ä¸€ä¸ªè¡Œæ•°æ®å¤§å°è¶…è¿‡äº†æŒ‡å®šçš„å¸§å¤§å°ï¼Œä»è€Œå¯¼è‡´ä»»åŠ¡å¤±è´¥ã€‚</p><p>é”™è¯¯ä¿¡æ¯ï¼š</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">RowTooLarge</span>: Encountered row that cannot fit in a single frame (max frame size = <span class="hljs-number">1</span>,<span class="hljs-number">000</span>,<span class="hljs-number">000</span>)<br></code></pre></td></tr></table></figure><p>è¡¨æ˜åœ¨å¤„ç†æ•°æ®æ—¶ï¼ŒDruid é‡åˆ°äº†ä¸€ä¸ªæ•°æ®è¡Œï¼Œå®ƒçš„å¤§å°è¶…è¿‡äº† <code>1,000,000</code> å­—èŠ‚ï¼ˆå³ <code>STANDARD_FRAME_SIZE</code>ï¼‰ï¼Œæ— æ³•é€‚é…å½“å‰çš„å¸§å¤§å°é™åˆ¶ã€‚</p><h2 id="è°ƒè¯•"><a href="#è°ƒè¯•" class="headerlink" title="è°ƒè¯•"></a>è°ƒè¯•</h2><ol><li><p><strong>å¸§å¤§å°é…ç½®</strong>ï¼šä»ä»£ç ç‰‡æ®µå¯ä»¥çœ‹åˆ°ï¼ŒDruid é»˜è®¤çš„å¸§å¤§å°æ˜¯ <code>1,000,000</code> å­—èŠ‚ã€‚<code>STANDARD_FRAME_SIZE</code> çš„å€¼æ˜¯é™æ€å®šä¹‰çš„ï¼š</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">STANDARD_FRAME_SIZE</span> <span class="hljs-operator">=</span> <span class="hljs-number">1_000_000</span>;<br></code></pre></td></tr></table></figure><p> è¯¥å€¼åœ¨ Druid ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­è¢«ç”¨ä½œå†…å­˜åˆ†é…çš„æ ‡å‡†å¸§å¤§å°ï¼š</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java">  <span class="hljs-keyword">final</span> <span class="hljs-type">InputChannels</span> <span class="hljs-variable">inputChannels</span> <span class="hljs-operator">=</span><br>      <span class="hljs-keyword">new</span> <span class="hljs-title class_">InputChannelsImpl</span>(<br>          workOrder.getQueryDefinition(),<br>          InputSlices.allReadablePartitions(workOrder.getInputs()),<br>          inputChannelFactory,<br>          () -&gt; ArenaMemoryAllocator.createOnHeap(frameContext.memoryParameters().getStandardFrameSize()),<br>          exec,<br>          cancellationId<br>      );<br>    <br><span class="hljs-keyword">public</span> <span class="hljs-type">int</span> <span class="hljs-title function_">getStandardFrameSize</span><span class="hljs-params">()</span><br>&#123;<br>  <span class="hljs-keyword">return</span> STANDARD_FRAME_SIZE;<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>ä»»åŠ¡å¤±è´¥åŸå› </strong>ï¼šä»»åŠ¡å¤±è´¥çš„åŸå› æ˜¯æŸä¸ªæ•°æ®è¡Œçš„å¤§å°è¶…è¿‡äº† <code>1,000,000</code> å­—èŠ‚çš„é™åˆ¶ï¼Œå¯¼è‡´æ— æ³•è£…å…¥å•ä¸€å¸§ä¸­ã€‚è¯¥é”™è¯¯ä¿¡æ¯è¡¨æ˜ï¼Œåœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼ŒæŸä¸€è¡Œæ•°æ®å¤ªå¤§ï¼Œè¶…è¿‡äº†è®¾ç½®çš„å¸§æœ€å¤§å¤§å°ï¼Œå¯¼è‡´ä»»åŠ¡å¤±è´¥ã€‚</p></li><li><p><strong>ä¿®æ”¹å¸§å¤§å°</strong>ï¼šå¦‚æœéœ€è¦å¤„ç†æ›´å¤§çš„æ•°æ®è¡Œï¼Œå¯ä»¥è€ƒè™‘å¢åŠ  <code>STANDARD_FRAME_SIZE</code> çš„å¤§å°ï¼Œä»è€Œå…è®¸æ¯ä¸ªå¸§å¤„ç†æ›´å¤§çš„æ•°æ®è¡Œã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†å…¶ä¿®æ”¹ä¸º <code>2,000,000</code> æˆ–æ›´é«˜ï¼š</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">STANDARD_FRAME_SIZE</span> <span class="hljs-operator">=</span> <span class="hljs-number">2_000_000</span>;<br></code></pre></td></tr></table></figure></li><li><p><strong>å†…å­˜ä¼˜åŒ–</strong>ï¼šå¢åŠ å¸§å¤§å°å¯èƒ½ä¼šå¢åŠ å†…å­˜æ¶ˆè€—ï¼Œå› æ­¤éœ€è¦æƒè¡¡å†…å­˜ä½¿ç”¨å’Œæ•°æ®å¤„ç†æ€§èƒ½ã€‚å¦‚æœå†…å­˜ä¸è¶³ï¼Œå¢åŠ å¸§å¤§å°å¯èƒ½ä¼šå¯¼è‡´å†…å­˜æº¢å‡ºç­‰é—®é¢˜ã€‚è°ƒæ•´è¯¥å€¼æ—¶ï¼Œéœ€è¦è€ƒè™‘ç³»ç»Ÿå†…å­˜å’Œè´Ÿè½½çš„æ•´ä½“æƒ…å†µã€‚</p></li></ol><h2 id="ç»“è®º"><a href="#ç»“è®º" class="headerlink" title="ç»“è®º"></a>ç»“è®º</h2><p>ä»»åŠ¡å¤±è´¥æ˜¯ç”±äºæŸä¸€è¡Œæ•°æ®è¶…è¿‡äº† Druid é…ç½®çš„æœ€å¤§å¸§å¤§å°ï¼ˆ<code>1,000,000</code> å­—èŠ‚ï¼‰ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæ‚¨å¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ç§æ–¹æ¡ˆï¼š</p><ol><li><strong>å¢åŠ å¸§å¤§å°</strong>ï¼šå°† <code>STANDARD_FRAME_SIZE</code> å¢åŠ åˆ°æ›´å¤§çš„å€¼ï¼Œå¦‚ <code>2,000,000</code> æˆ–æ›´é«˜ï¼Œä»¥ä¾¿èƒ½å¤Ÿå¤„ç†æ›´å¤§çš„æ•°æ®è¡Œã€‚</li><li><strong>ä¼˜åŒ–æ•°æ®è¡Œå¤§å°</strong>ï¼šå¦‚æœå¯èƒ½ï¼Œè°ƒæ•´æ•°æ®çš„ç”Ÿæˆæ–¹å¼ï¼Œå‡å°‘å•è¡Œæ•°æ®çš„å¤§å°ã€‚</li><li><strong>å†…å­˜ç®¡ç†</strong>ï¼šå¢åŠ å¸§å¤§å°å¯èƒ½ä¼šå¢åŠ å†…å­˜æ¶ˆè€—ï¼Œéœ€è¦ç¡®ä¿ç³»ç»Ÿæœ‰è¶³å¤Ÿçš„å¯ç”¨å†…å­˜ã€‚</li></ol><p>è°ƒæ•´å¸§å¤§å°æ—¶ï¼Œå»ºè®®ç»“åˆå®é™…å†…å­˜ä½¿ç”¨æƒ…å†µè¿›è¡Œæµ‹è¯•ï¼Œé¿å…å› å†…å­˜ä¸è¶³å¯¼è‡´å…¶ä»–é—®é¢˜ã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>Debug</tag>
      
      <tag>Druid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spark HistoryServer Intros and Troubleshooting</title>
    <link href="/2024/07/31/spark-history-debug/"/>
    <url>/2024/07/31/spark-history-debug/</url>
    
    <content type="html"><![CDATA[<h2 id="HistoryServer-Introduction"><a href="#HistoryServer-Introduction" class="headerlink" title="HistoryServer Introduction"></a>HistoryServer Introduction</h2><p>HistoryServer is an HTTP service built into Spark, we can start it with the following code. When HistoryServer is started, it starts two threads to parse and clean the log files.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./sbin/start-history-server.sh<br></code></pre></td></tr></table></figure><p>This creates a web interface at <code>http://&lt;server-url&gt;:8080</code>, listing incomplete and completed applications and attempts.</p><p>The spark jobs themselves must be configured to log events, and to log them to the same shared, writable directory. </p><p>For example, if the server was configured with a log directory of <code>hdfs://namenode/spark-logs</code>, then the client-side options would be:</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">spark<span class="hljs-selector-class">.eventLog</span><span class="hljs-selector-class">.enabled</span> true<br>spark<span class="hljs-selector-class">.eventLog</span><span class="hljs-selector-class">.dir</span> hdfs:<span class="hljs-comment">//namenode/spark-logs</span><br></code></pre></td></tr></table></figure><p><img src="/2024/07/31/spark-history-debug/img1.png" title="img1"></p><p>To introduce the Spark History Server, the flowchart below outlines its workflow.</p><p>The Spark History Server relies on the Spark Event system. During a Spark task, various SparkListenerEvents are generated, like ApplicationStart and StageCompleted. These events are sent to the ListenerBus, where they are monitored by registered listeners. The EventLoggingListener writes these events to a JSON log file on a file system like HDFS.</p><p>The FsHistoryProvider in the History Server scans the log storage path periodically, extracts profile information (such as Application_id, user, status, start_time, end_time, event_log_path) from the log files, and maintains a list of this data. When a user accesses the UI, the system searches this list for the requested task and reads the corresponding event log file for details if it exists.</p><h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>In some cases, after submitting a job using Spark, the log information corresponding to the appId cannot be found in the <strong>Spark HistoryServer WebUI (v3.2.1)</strong>. </p><p>As a result, users cannot analyze the job log through the HistoryServer (HS). Upon analyzing the source code, it was found that the issue is due to the misuse of a data structure in a multithreading context.</p><h2 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h2><p>Before explaining the problem, itâ€™s important to understand the key data structure in HS. The misuse of this data structure causes the issue. HS uses a data structure called Listing to store key-value pairs, such as:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs xml">&lt;appId, InfoData<span class="hljs-tag">&lt;<span class="hljs-name">appId</span>&gt;</span>&gt;<br>&lt;logPath, InfoData<span class="hljs-tag">&lt;<span class="hljs-name">logPath</span>&gt;</span>&gt;<br></code></pre></td></tr></table></figure><h2 id="Log-Parsing-Process"><a href="#Log-Parsing-Process" class="headerlink" title="Log Parsing Process"></a>Log Parsing Process</h2><p>The HS runs the <code>checkForLogs</code> method every 10 seconds by default to build the application list based on the current contents of the log directory. During each execution, this method scans the specified logDir and parses the log files to update its KVStore listing. The process includes two main methods:</p><ol><li>update&#x2F;add log file records respectively</li><li>remove stale log file records.</li></ol><p>These methods are executed in different threads via <code>submitLogProcessTask</code>.</p><h2 id="Issue-Scenario"><a href="#Issue-Scenario" class="headerlink" title="Issue Scenario"></a>Issue Scenario</h2><p>When <code>checkForLogs</code> is executed for the first time, the ABC job submitted by the user is still running. The file name in the log directory is <code>ABC.inprocess</code>, so the KVStore <code>Listing</code> adds two new entries:</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c">&lt;&#x27;ABC&#x27;, InfoData&lt;&#x27;ABC&#x27;&gt;&gt;<br>&lt;&#x27;/tmp/ABC.inprocess&#x27;, InfoData&lt;&#x27;/tmp/ABC.inprocess&#x27;&gt;&gt;<br></code></pre></td></tr></table></figure><p>In the next run of <code>checkForLogs</code>, now the ABC application has finished, the log file <code>/tmp/ABC.inprocess</code> has been deleted, and the new log file path is <code>/tmp/ABC</code>, so in this run of <code>checkForLogs</code>, two threads will start and do following things:</p><p><strong>Thread 1</strong>: update&#x2F;add log file records, this thread will parsing the log path <code>/tmp/ABC</code>. First it will update the<code> &lt;&#39;ABC&#39;, InfoData&lt;&#39;ABC&#39;&gt;&gt;</code> in the KVstore Listing, second it will add a new record <code>&lt;&#39;/tmp/ABC&#39;, InfoData&lt;&#39;/tmp/ABC&#39;&gt;&gt;</code> in KVstore Listing.</p><p><strong>Thread 2</strong>: remove stale log file records, this thread will notice that the log path <code>/tmp/ABC.inprocess</code> has disappeared. First it will filter this path as a stale data, second it will start <code>cleanAppData</code> method, in this method the following code will be executed:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">val</span> <span class="hljs-variable">app</span> <span class="hljs-operator">=</span> load(appId)<br></code></pre></td></tr></table></figure><p>Usually, by the time this method loads the <code>appId</code>, Thread 1 has already updated <code>&lt;&#39;ABC&#39;, InfoData&lt;&#39;ABC&#39;&gt;&gt;</code> in the KVStore Listing. Therefore, when the following code executes, the value of <code>isStale</code> will be <code>false</code>.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">val</span> <span class="hljs-variable">isStale</span> <span class="hljs-operator">=</span> attempt.headOption.exists &#123; a =&gt;<br>   <span class="hljs-keyword">if</span> (a.logPath != <span class="hljs-keyword">new</span> <span class="hljs-title class_">Path</span>(logPath).getName()) &#123;<br>     <span class="hljs-literal">false</span><br>   &#125; <span class="hljs-keyword">else</span> &#123;<br>     ...<br>     <span class="hljs-literal">true</span><br>   &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>However, in some cases, when this method loads the <code>appId</code>, Thread 1 has not finished the update. As a result, when the code above executes, the value of <code>isStale</code> will be <code>true</code>. The worst outcome is that it will delete the log file record <code>&lt;&#39;ABC&#39;, InfoData&lt;&#39;ABC&#39;&gt;&gt;</code> in the KVStore Listing after Thread 1 has completed the update.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">if</span> (isStale) &#123;<br>   <span class="hljs-keyword">if</span> (others.nonEmpty) &#123;<br>     <span class="hljs-type">val</span> <span class="hljs-variable">newAppInfo</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ApplicationInfoWrapper</span>(app.info, others)<br>     listing.write(newAppInfo)<br>   &#125; <span class="hljs-keyword">else</span> &#123;<br>     listing.delete(classOf[ApplicationInfoWrapper], appId)<br>   &#125;<br> &#125;<br>&#125; <span class="hljs-keyword">catch</span> &#123;<br>  <span class="hljs-keyword">case</span> _: NoSuchElementException =&gt;<br>&#125;<br></code></pre></td></tr></table></figure><p>So, the log file record <code>&lt;&#39;ABC&#39;, InfoData&lt;&#39;ABC&#39;&gt;&gt;</code> will be permanently removed. When users access the WebUI for this application, they will see â€œApplication not foundâ€ even though the log file for the app still exists.</p><p>One thing to note is that the log file record <code>&lt;&#39;ABC&#39;, InfoData&lt;&#39;ABC&#39;&gt;&gt;</code> will not be added to the KVStore Listing again. In the next run of <code>checkForLogs</code>, the entry <code>&lt;&#39;/tmp/ABC&#39;, InfoData&lt;&#39;/tmp/ABC&#39;&gt;&gt;</code> indicates that the log file of ABC does not need to be reloaded, so the method will skip this log file.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-type">val</span> <span class="hljs-variable">info</span> <span class="hljs-operator">=</span> listing.read(classOf[LogInfo], reader.rootPath.toString())<br> <br><span class="hljs-keyword">if</span> (shouldReloadLog(info, reader)) &#123;<br>    ...<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-literal">false</span><br>    &#125;<br></code></pre></td></tr></table></figure><p>To better show the process of bug occurrence, below is the flowchart</p><p><img src="/2024/07/31/spark-history-debug/img2.png" title="img2"></p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>Due to multi-thread error common use of KVstore Listing, we make the <code>cleanAppData</code> method atomic, just like the addListing mothod, this allows threads to use KVstore Listing without data errors. </p><p>For example:</p><p>If Thread 1 gets the lock on the KVstore Listing before Thread 2, it will update the record of <code>&lt;appId, InfoData&lt;appId&gt;&gt;</code>, so Thread 2 can safely get the record and it will make isStale be <code>false</code>, so the <code>cleanAppData</code> method will not delete the record in KVstore Listing.</p><p>If Thread 2 gets the lock on the KVstore Listing before Thread 1, it will make isStale be <code>true</code>, and the <code>cleanAppData</code> method will delete the record in KVstore Listing. But it will be ok, beacuse Thread 1 will add the record of <code>&lt;appId, InfoData&lt;appId&gt;&gt;</code> in KVstore Listing again.</p><p>In all situations above, the record of KVstore Listing will not remove unexpectedly.</p><p>This is the method used to fix the problem in Spark v3.2.2 (<a href="https://github.com/apache/spark/pull/36424/files">https://github.com/apache/spark/pull/36424/files</a>).</p>]]></content>
    
    
    
    <tags>
      
      <tag>Debug</tag>
      
      <tag>Spark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes nodeAffinity &amp; nodeSelector Intros</title>
    <link href="/2024/07/31/Kubernetes-nodeAffinity-And-Selector/"/>
    <url>/2024/07/31/Kubernetes-nodeAffinity-And-Selector/</url>
    
    <content type="html"><![CDATA[<h2 id="Kubernetes-çš„äº²å’Œæ€§è°ƒåº¦"><a href="#Kubernetes-çš„äº²å’Œæ€§è°ƒåº¦" class="headerlink" title="Kubernetes çš„äº²å’Œæ€§è°ƒåº¦"></a>Kubernetes çš„äº²å’Œæ€§è°ƒåº¦</h2><p>K8sçš„ POD æ˜¯è‡ªåŠ¨è°ƒåº¦é€‰æ‹©æŸä¸ª NODE çš„ï¼Œé»˜è®¤æƒ…å†µä¸‹è°ƒåº¦å™¨è€ƒè™‘çš„æ˜¯èµ„æºè¶³å¤Ÿï¼Œå¹¶ä¸”è´Ÿè½½å°½é‡å¹³å‡ï¼Œä½†æ˜¯æœ‰çš„æ—¶å€™æˆ‘ä»¬éœ€è¦èƒ½å¤Ÿæ›´åŠ ç»†ç²’åº¦çš„å»æ§åˆ¶ POD çš„è°ƒåº¦ï¼Œæ¯”å¦‚æ§åˆ¶ POD æ˜¯å¦åœ¨åŒä¸€ NODE ä¸Šã€‚è¿™å°±éœ€è¦ç”¨åˆ° Kubernetes é‡Œé¢çš„ä¸€ä¸ªæ¦‚å¿µï¼š<strong>äº²å’Œæ€§</strong>ï¼Œäº²å’Œæ€§ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š<code>nodeAffinity</code>å’Œ<code>podAffinity</code>ã€‚</p><h2 id="nodeSelector"><a href="#nodeSelector" class="headerlink" title="nodeSelector"></a>nodeSelector</h2><p>ç”¨æˆ·å¯ä»¥éå¸¸çµæ´»çš„åˆ©ç”¨ <code>label</code> æ¥ç®¡ç†é›†ç¾¤ä¸­çš„èµ„æºï¼Œæ¯”å¦‚æœ€å¸¸è§çš„ä¸€ä¸ªå°±æ˜¯ service é€šè¿‡åŒ¹é… <code>label</code> å»é€‰æ‹© POD çš„ã€‚è€Œ POD çš„è°ƒåº¦ä¹Ÿå¯ä»¥æ ¹æ®èŠ‚ç‚¹çš„ label è¿›è¡Œç‰¹å®šçš„éƒ¨ç½²ã€‚</p><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹æˆ‘ä»¬çš„ node çš„ labelï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get nodes --show-labels<br>NAME            STATUS    ROLES     AGE       VERSION   LABELS<br>192.168.1.140   Ready     &lt;none&gt;    42d       v1.8.1    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=192.168.1.140<br>192.168.1.161   Ready     &lt;none&gt;    118d      v1.8.1    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/cluster-service=<span class="hljs-literal">true</span>,kubernetes.io/hostname=192.168.1.161<br>192.168.1.170   Ready     &lt;none&gt;    118d      v1.8.1    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/cluster-service=<span class="hljs-literal">true</span>,kubernetes.io/hostname=192.168.1.170<br>192.168.1.172   Ready     &lt;none&gt;    114d      v1.8.1    beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/cluster-service=<span class="hljs-literal">true</span>,kubernetes.io/hostname=192.168.1.172<br><br></code></pre></td></tr></table></figure><p>ç°åœ¨æˆ‘ä»¬å…ˆç»™èŠ‚ç‚¹<strong>192.168.1.140</strong>å¢åŠ ä¸€ä¸ª<code>source=qikqiak</code>çš„æ ‡ç­¾ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl label nodes 192.168.1.140 <span class="hljs-built_in">source</span>=qikqiak<br>node <span class="hljs-string">&quot;192.168.1.140&quot;</span> labeled<br><br></code></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸Šé¢çš„<code>--show-labels</code>å‚æ•°å¯ä»¥æŸ¥çœ‹ä¸Šè¿°æ ‡ç­¾æ˜¯å¦ç”Ÿæ•ˆã€‚å½“ node è¢«æ‰“ä¸Šäº†ç›¸å…³æ ‡ç­¾åï¼Œåœ¨è°ƒåº¦çš„æ—¶å€™å°±å¯ä»¥ä½¿ç”¨è¿™äº›æ ‡ç­¾äº†ï¼Œåªéœ€è¦åœ¨ POD çš„ spec å­—æ®µä¸­æ·»åŠ <code>nodeSelector</code>å­—æ®µï¼Œé‡Œé¢æ˜¯æˆ‘ä»¬éœ€è¦è¢«è°ƒåº¦çš„èŠ‚ç‚¹çš„ labelã€‚ä¾‹å¦‚ï¼Œä¸‹é¢æ˜¯æˆ‘ä»¬ä¹‹å‰çš„ä¸€ä¸ªé»˜è®¤çš„ busybox POD çš„ YAML æ–‡ä»¶ï¼š</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">busybox-pod</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">test-busybox</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">command:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;3600&quot;</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span><br>    <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">Always</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">test-busybox</span><br><br></code></pre></td></tr></table></figure><p>ç„¶åæˆ‘éœ€è¦è®©ä¸Šé¢çš„ POD è¢«è°ƒåº¦åˆ°140çš„èŠ‚ç‚¹ä¸Šï¼Œé‚£ä¹ˆæœ€ç®€å•çš„æ–¹æ³•å°±æ˜¯å»åŒ¹é…140ä¸Šé¢çš„ labelï¼Œå¦‚ä¸‹ï¼š</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">busybox-pod</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">test-busybox</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">command:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;3600&quot;</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span><br>    <span class="hljs-attr">imagePullPolicy:</span> <span class="hljs-string">Always</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">test-busybox</span><br>  <span class="hljs-attr">nodeSelector:</span><br>    <span class="hljs-attr">source:</span> <span class="hljs-string">qikqiak</span><br><br></code></pre></td></tr></table></figure><p>ç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡ describe å‘½ä»¤æŸ¥çœ‹è°ƒåº¦ç»“æœï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl describe pod test-busybox<br>......<br>Events:<br>  Type    Reason                 Age   From                    Message<br>  ----    ------                 ----  ----                    -------<br>  Normal  Scheduled              49s   default-scheduler       Successfully assigned test-busybox to 192.168.1.140<br>  Normal  SuccessfulMountVolume  49s   kubelet, 192.168.1.140  MountVolume.SetUp succeeded <span class="hljs-keyword">for</span> volume <span class="hljs-string">&quot;default-token-hmpbz&quot;</span><br>  Normal  Pulling                49s   kubelet, 192.168.1.140  pulling image <span class="hljs-string">&quot;busybox&quot;</span><br>  Normal  Pulled                 41s   kubelet, 192.168.1.140  Successfully pulled image <span class="hljs-string">&quot;busybox&quot;</span><br>  Normal  Created                41s   kubelet, 192.168.1.140  Created container<br>  Normal  Started                41s   kubelet, 192.168.1.140  Started container<br><br></code></pre></td></tr></table></figure><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ° Events ä¸‹é¢çš„ä¿¡æ¯ï¼Œä¸Šé¢çš„ POD è¢«æ­£ç¡®çš„è°ƒåº¦åˆ°äº†140èŠ‚ç‚¹ã€‚é€šè¿‡ä¸Šé¢çš„ä¾‹å­æˆ‘ä»¬å¯ä»¥æ„Ÿå—åˆ°<code>nodeSelector</code>çš„æ–¹å¼æ¯”è¾ƒç›´è§‚ï¼Œä½†æ˜¯è¿˜å¤Ÿçµæ´»ï¼Œæ§åˆ¶ç²’åº¦åå¤§ï¼Œä¸‹é¢æˆ‘ä»¬å†çœ‹å¦å¤–ä¸€ç§æ›´åŠ çµæ´»çš„æ–¹å¼ï¼š<code>nodeAffinity</code>ã€‚</p><h2 id="nodeAffinity"><a href="#nodeAffinity" class="headerlink" title="nodeAffinity"></a>nodeAffinity</h2><p><code>nodeAffinity</code>å°±æ˜¯èŠ‚ç‚¹äº²å’Œæ€§ï¼Œç›¸å¯¹åº”çš„æ˜¯<code>Anti-Affinity</code>ï¼Œå°±æ˜¯åäº²å’Œæ€§ï¼Œè¿™ç§æ–¹æ³•æ¯”ä¸Šé¢çš„<code>nodeSelector</code>æ›´åŠ çµæ´»ï¼Œå®ƒå¯ä»¥è¿›è¡Œä¸€äº›ç®€å•çš„é€»è¾‘ç»„åˆäº†ï¼Œä¸åªæ˜¯ç®€å•çš„ç›¸ç­‰åŒ¹é…ã€‚ è°ƒåº¦å¯ä»¥åˆ†æˆè½¯ç­–ç•¥å’Œç¡¬ç­–ç•¥ä¸¤ç§æ–¹å¼ï¼Œè½¯ç­–ç•¥å°±æ˜¯å¦‚æœä½ æ²¡æœ‰æ»¡è¶³è°ƒåº¦è¦æ±‚çš„èŠ‚ç‚¹çš„è¯ï¼ŒPOD å°±ä¼šå¿½ç•¥è¿™æ¡è§„åˆ™ï¼Œç»§ç»­å®Œæˆè°ƒåº¦è¿‡ç¨‹ï¼Œè¯´ç™½äº†å°±æ˜¯<strong>æ»¡è¶³æ¡ä»¶æœ€å¥½äº†ï¼Œæ²¡æœ‰çš„è¯ä¹Ÿæ— æ‰€è°“äº†</strong>çš„ç­–ç•¥ï¼›è€Œç¡¬ç­–ç•¥å°±æ¯”è¾ƒå¼ºç¡¬äº†ï¼Œå¦‚æœæ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹çš„è¯ï¼Œå°±ä¸æ–­é‡è¯•ç›´åˆ°æ»¡è¶³æ¡ä»¶ä¸ºæ­¢ï¼Œç®€å•è¯´å°±æ˜¯<strong>ä½ å¿…é¡»æ»¡è¶³æˆ‘çš„è¦æ±‚ï¼Œä¸ç„¶æˆ‘å°±ä¸å¹²</strong>çš„ç­–ç•¥ã€‚ </p><p><code>nodeAffinity</code>åˆ†ä¸ºä»¥ä¸‹ä¸¤ç§ç­–ç•¥ï¼š</p><ol><li><code>preferredDuringSchedulingIgnoredDuringExecution</code> è½¯ç­–ç•¥</li><li><code>requiredDuringSchedulingIgnoredDuringExecution</code> ç¡¬ç­–ç•¥ã€‚</li></ol><p>å¦‚ä¸‹ä¾‹å­ï¼šï¼ˆ<strong>test-node-affinity.yaml</strong>ï¼‰</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">with-node-affinity</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">node-affinity-pod</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">with-node-affinity</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attr">affinity:</span><br>    <span class="hljs-attr">nodeAffinity:</span><br>      <span class="hljs-attr">requiredDuringSchedulingIgnoredDuringExecution:</span><br>        <span class="hljs-attr">nodeSelectorTerms:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">matchExpressions:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">kubernetes.io/hostname</span><br>            <span class="hljs-attr">operator:</span> <span class="hljs-string">NotIn</span><br>            <span class="hljs-attr">values:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.140</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.161</span><br>      <span class="hljs-attr">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">weight:</span> <span class="hljs-number">1</span><br>        <span class="hljs-attr">preference:</span><br>          <span class="hljs-attr">matchExpressions:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">source</span><br>            <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span><br>            <span class="hljs-attr">values:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-string">qikqiak</span><br><br></code></pre></td></tr></table></figure><p>ä¸Šé¢è¿™ä¸ª POD é¦–å…ˆæ˜¯è¦æ±‚ POD ä¸èƒ½è¿è¡Œåœ¨140å’Œ161ä¸¤ä¸ªèŠ‚ç‚¹ä¸Šï¼Œå¦‚æœæœ‰ä¸ªèŠ‚ç‚¹æ»¡è¶³<code>source=qikqiak</code>çš„è¯å°±ä¼˜å…ˆè°ƒåº¦åˆ°è¿™ä¸ªèŠ‚ç‚¹ä¸Šï¼ŒåŒæ ·çš„æˆ‘ä»¬å¯ä»¥ä½¿ç”¨<code>descirbe</code>å‘½ä»¤æŸ¥çœ‹å…·ä½“çš„è°ƒåº¦æƒ…å†µæ˜¯å¦æ»¡è¶³æˆ‘ä»¬çš„è¦æ±‚ã€‚è¿™é‡Œçš„åŒ¹é…é€»è¾‘æ˜¯ label çš„å€¼åœ¨æŸä¸ªåˆ—è¡¨ä¸­ï¼Œç°åœ¨<code>Kubernetes</code>æä¾›çš„æ“ä½œç¬¦æœ‰ä¸‹é¢çš„å‡ ç§ï¼š</p><ul><li>Inï¼šlabel çš„å€¼åœ¨æŸä¸ªåˆ—è¡¨ä¸­</li><li>NotInï¼šlabel çš„å€¼ä¸åœ¨æŸä¸ªåˆ—è¡¨ä¸­</li><li>Gtï¼šlabel çš„å€¼å¤§äºæŸä¸ªå€¼</li><li>Ltï¼šlabel çš„å€¼å°äºæŸä¸ªå€¼</li><li>Existsï¼šæŸä¸ª label å­˜åœ¨</li><li>DoesNotExistï¼šæŸä¸ª label ä¸å­˜åœ¨</li></ul><blockquote><p>å¦‚æœ<code>nodeSelectorTerms</code>ä¸‹é¢æœ‰å¤šä¸ªé€‰é¡¹çš„è¯ï¼Œæ»¡è¶³ä»»ä½•ä¸€ä¸ªæ¡ä»¶å°±å¯ä»¥äº†ï¼›å¦‚æœ<code>matchExpressions</code>æœ‰å¤šä¸ªé€‰é¡¹çš„è¯ï¼Œåˆ™å¿…é¡»åŒæ—¶æ»¡è¶³è¿™äº›æ¡ä»¶æ‰èƒ½æ­£å¸¸è°ƒåº¦ PODã€‚</p></blockquote><h2 id="podAffinity"><a href="#podAffinity" class="headerlink" title="podAffinity"></a>podAffinity</h2><p>ä¸Šé¢ä¸¤ç§æ–¹å¼éƒ½æ˜¯è®© POD å»é€‰æ‹©èŠ‚ç‚¹çš„ï¼Œæœ‰çš„æ—¶å€™æˆ‘ä»¬ä¹Ÿå¸Œæœ›èƒ½å¤Ÿæ ¹æ® POD ä¹‹é—´çš„å…³ç³»è¿›è¡Œè°ƒåº¦ï¼Œ<code>Kubernetes</code>åœ¨1.4ç‰ˆæœ¬å¼•å…¥çš„<code>podAffinity</code>æ¦‚å¿µå°±å¯ä»¥å®ç°æˆ‘ä»¬è¿™ä¸ªéœ€æ±‚ã€‚</p><p>å’Œ<code>nodeAffinity</code>ç±»ä¼¼ï¼Œ<code>podAffinity</code>ä¹Ÿæœ‰<code>requiredDuringSchedulingIgnoredDuringExecution</code>å’Œ <code>preferredDuringSchedulingIgnoredDuringExecution</code>ä¸¤ç§è°ƒåº¦ç­–ç•¥ï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯å¦‚æœè¦ä½¿ç”¨äº’æ–¥æ€§ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨<code>podAntiAffinity</code>å­—æ®µã€‚ å¦‚ä¸‹ä¾‹å­ï¼Œæˆ‘ä»¬å¸Œæœ›<code>with-pod-affinity</code>å’Œ<code>busybox-pod</code>èƒ½å¤Ÿå°±è¿‘éƒ¨ç½²ï¼Œè€Œä¸å¸Œæœ›å’Œ<code>node-affinity-pod</code>éƒ¨ç½²åœ¨åŒä¸€ä¸ªæ‹“æ‰‘åŸŸä¸‹é¢ï¼šï¼ˆ<strong>test-pod-affinity.yaml</strong>ï¼‰</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">with-pod-affinity</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">pod-affinity-pod</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">with-pod-affinity</span><br>    <span class="hljs-attr">image:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attr">affinity:</span><br>    <span class="hljs-attr">podAffinity:</span><br>      <span class="hljs-attr">requiredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">labelSelector:</span><br>          <span class="hljs-attr">matchExpressions:</span><br>          <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">app</span><br>            <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span><br>            <span class="hljs-attr">values:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-string">busybox-pod</span><br>        <span class="hljs-attr">topologyKey:</span> <span class="hljs-string">kubernetes.io/hostname</span><br>    <span class="hljs-attr">podAntiAffinity:</span><br>      <span class="hljs-attr">preferredDuringSchedulingIgnoredDuringExecution:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">weight:</span> <span class="hljs-number">1</span><br>        <span class="hljs-attr">podAffinityTerm:</span><br>          <span class="hljs-attr">labelSelector:</span><br>            <span class="hljs-attr">matchExpressions:</span><br>            <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">app</span><br>              <span class="hljs-attr">operator:</span> <span class="hljs-string">In</span><br>              <span class="hljs-attr">values:</span><br>              <span class="hljs-bullet">-</span> <span class="hljs-string">node-affinity-pod</span><br>          <span class="hljs-attr">topologyKey:</span> <span class="hljs-string">kubernetes.io/hostname</span><br><br></code></pre></td></tr></table></figure><p>ä¸Šé¢è¿™ä¸ªä¾‹å­ä¸­çš„ POD éœ€è¦è°ƒåº¦åˆ°æŸä¸ªæŒ‡å®šçš„ä¸»æœºä¸Šï¼Œè‡³å°‘æœ‰ä¸€ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œäº†è¿™æ ·çš„ PODï¼šè¿™ä¸ª POD æœ‰ä¸€ä¸ª<code>app=busybox-pod</code>çš„ labelã€‚<code>podAntiAffinity</code>åˆ™æ˜¯å¸Œæœ›æœ€å¥½ä¸è¦è°ƒåº¦åˆ°è¿™æ ·çš„èŠ‚ç‚¹ï¼šè¿™ä¸ªèŠ‚ç‚¹ä¸Šè¿è¡Œäº†æŸä¸ª PODï¼Œè€Œè¿™ä¸ª POD æœ‰<code>app=node-affinity-pod</code>çš„ labelã€‚æ ¹æ®å‰é¢ä¸¤ä¸ª POD çš„å®šä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥é¢„è§ä¸Šé¢è¿™ä¸ª POD åº”è¯¥ä¼šè¢«è°ƒåº¦åˆ°140çš„èŠ‚ç‚¹ä¸Šï¼Œå› ä¸º<code>busybox-pod</code>è¢«è°ƒåº¦åˆ°äº†140èŠ‚ç‚¹ï¼Œè€Œ<code>node-affinity-pod</code>è¢«è°ƒåº¦åˆ°äº†140ä»¥ä¸ºçš„èŠ‚ç‚¹ï¼Œæ­£å¥½æ»¡è¶³ä¸Šé¢çš„éœ€æ±‚ã€‚é€šè¿‡<code>describe</code>æŸ¥çœ‹ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl describe pod with-pod-affinity<br>......<br>Events:<br>  Type    Reason                 Age   From                    Message<br>  ----    ------                 ----  ----                    -------<br>  Normal  Scheduled              8s    default-scheduler       Successfully assigned with-pod-affinity to 192.168.1.140<br>  Normal  SuccessfulMountVolume  7s    kubelet, 192.168.1.140  MountVolume.SetUp succeeded <span class="hljs-keyword">for</span> volume <span class="hljs-string">&quot;default-token-lcl77&quot;</span><br>  Normal  Pulling                7s    kubelet, 192.168.1.140  pulling image <span class="hljs-string">&quot;nginx&quot;</span><br><br></code></pre></td></tr></table></figure><p>ä¸Šé¢çš„äº‹ä»¶ä¿¡æ¯ä¹ŸéªŒè¯äº†æˆ‘ä»¬çš„æƒ³æ³•ã€‚</p><blockquote><p>åœ¨<code>labelSelector</code>å’Œ <code>topologyKey</code>çš„åŒçº§ï¼Œè¿˜å¯ä»¥å®šä¹‰ namespaces åˆ—è¡¨ï¼Œè¡¨ç¤ºåŒ¹é…å“ªäº› namespace é‡Œé¢çš„ podï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œä¼šåŒ¹é…å®šä¹‰çš„ pod æ‰€åœ¨çš„ namespaceï¼›å¦‚æœå®šä¹‰äº†è¿™ä¸ªå­—æ®µï¼Œä½†æ˜¯å®ƒçš„å€¼ä¸ºç©ºï¼Œåˆ™åŒ¹é…æ‰€æœ‰çš„ namespacesã€‚</p></blockquote><p>æŸ¥çœ‹ä¸Šé¢æˆ‘ä»¬å®šä¹‰çš„3ä¸ª POD ç»“æœï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl get po -o wide<br>NAME                 READY     STATUS    RESTARTS   AGE       IP             NODE<br>test-busybox         1/1       Running   0          8m        172.30.95.18   192.168.1.140<br>with-node-affinity   1/1       Running   0          10m       172.30.81.25   192.168.1.172<br>with-pod-affinity    1/1       Running   0          8m        172.30.95.17   192.168.1.140<br><br></code></pre></td></tr></table></figure><p>äº²å’Œæ€§&#x2F;åäº²å’Œæ€§è°ƒåº¦ç­–ç•¥æ¯”è¾ƒå¦‚ä¸‹ï¼š</p><table><thead><tr><th>è°ƒåº¦ç­–ç•¥</th><th>åŒ¹é…æ ‡ç­¾</th><th>æ“ä½œç¬¦</th><th>æ‹“æ‰‘åŸŸæ”¯æŒ</th><th>è°ƒåº¦ç›®æ ‡</th></tr></thead><tbody><tr><td>nodeAffinity</td><td>ä¸»æœº</td><td>In, NotIn, Exists, DoesNotExist, Gt, Lt</td><td>å¦</td><td>æŒ‡å®šä¸»æœº</td></tr><tr><td>podAffinity</td><td>POD</td><td>In, NotIn, Exists, DoesNotExist</td><td>æ˜¯</td><td>PODä¸æŒ‡å®šPODåŒä¸€æ‹“æ‰‘åŸŸ</td></tr><tr><td>podAnitAffinity</td><td>POD</td><td>In, NotIn, Exists, DoesNotExist</td><td>æ˜¯</td><td>PODä¸æŒ‡å®šPODä¸åœ¨åŒä¸€æ‹“æ‰‘åŸŸ</td></tr></tbody></table><h2 id="æ±¡ç‚¹ï¼ˆTaintsï¼‰ä¸å®¹å¿ï¼ˆtolerationsï¼‰"><a href="#æ±¡ç‚¹ï¼ˆTaintsï¼‰ä¸å®¹å¿ï¼ˆtolerationsï¼‰" class="headerlink" title="æ±¡ç‚¹ï¼ˆTaintsï¼‰ä¸å®¹å¿ï¼ˆtolerationsï¼‰"></a>æ±¡ç‚¹ï¼ˆTaintsï¼‰ä¸å®¹å¿ï¼ˆtolerationsï¼‰</h2><p>å¯¹äº<code>nodeAffinity</code>æ— è®ºæ˜¯ç¡¬ç­–ç•¥è¿˜æ˜¯è½¯ç­–ç•¥æ–¹å¼ï¼Œéƒ½æ˜¯è°ƒåº¦ POD åˆ°é¢„æœŸèŠ‚ç‚¹ä¸Šï¼Œè€Œ<code>Taints</code>æ°å¥½ä¸ä¹‹ç›¸åï¼Œå¦‚æœä¸€ä¸ªèŠ‚ç‚¹æ ‡è®°ä¸º Taints ï¼Œé™¤é POD ä¹Ÿè¢«æ ‡è¯†ä¸ºå¯ä»¥å®¹å¿æ±¡ç‚¹èŠ‚ç‚¹ï¼Œå¦åˆ™è¯¥ Taints èŠ‚ç‚¹ä¸ä¼šè¢«è°ƒåº¦podã€‚</p><p>æ¯”å¦‚ç”¨æˆ·å¸Œæœ›æŠŠ Master èŠ‚ç‚¹ä¿ç•™ç»™ Kubernetes ç³»ç»Ÿç»„ä»¶ä½¿ç”¨ï¼Œæˆ–è€…æŠŠä¸€ç»„å…·æœ‰ç‰¹æ®Šèµ„æºé¢„ç•™ç»™æŸäº› PODï¼Œåˆ™æ±¡ç‚¹å°±å¾ˆæœ‰ç”¨äº†ï¼ŒPOD ä¸ä¼šå†è¢«è°ƒåº¦åˆ° taint æ ‡è®°è¿‡çš„èŠ‚ç‚¹ã€‚taint æ ‡è®°èŠ‚ç‚¹ä¸¾ä¾‹å¦‚ä¸‹ï¼š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ kubectl taint nodes 192.168.1.40 key=value:NoSchedule<br>node <span class="hljs-string">&quot;192.168.1.40&quot;</span> tainted<br><br></code></pre></td></tr></table></figure><p>å¦‚æœä»ç„¶å¸Œæœ›æŸä¸ª POD è°ƒåº¦åˆ° taint èŠ‚ç‚¹ä¸Šï¼Œåˆ™å¿…é¡»åœ¨ Spec ä¸­åšå‡º<code>Toleration</code>å®šä¹‰ï¼Œæ‰èƒ½è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ï¼Œä¸¾ä¾‹å¦‚ä¸‹ï¼š</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">tolerations:</span><br><span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;key&quot;</span><br><span class="hljs-attr">operator:</span> <span class="hljs-string">&quot;Equal&quot;</span><br><span class="hljs-attr">value:</span> <span class="hljs-string">&quot;value&quot;</span><br><span class="hljs-attr">effect:</span> <span class="hljs-string">&quot;NoSchedule&quot;</span><br><br></code></pre></td></tr></table></figure><p>effect å…±æœ‰ä¸‰ä¸ªå¯é€‰é¡¹ï¼Œå¯æŒ‰å®é™…éœ€æ±‚è¿›è¡Œè®¾ç½®ï¼š</p><ol><li><code>NoSchedule</code>ï¼šé™¤éå…·æœ‰åŒ¹é…çš„å®¹å¿åº¦è§„çº¦ï¼Œå¦åˆ™æ–°çš„ Pod ä¸ä¼šè¢«è°ƒåº¦åˆ°å¸¦æœ‰æ±¡ç‚¹çš„èŠ‚ç‚¹ä¸Šã€‚ å½“å‰æ­£åœ¨èŠ‚ç‚¹ä¸Šè¿è¡Œçš„ Pod ä¸ä¼šè¢«é©±é€ã€‚</li><li><code>PreferNoSchedule</code>ï¼šPreferNoSchedule æ˜¯â€œåå¥½â€æˆ–â€œè½¯æ€§â€çš„ NoScheduleã€‚ æ§åˆ¶å¹³é¢å°†å°è¯•é¿å…å°†ä¸èƒ½å®¹å¿æ±¡ç‚¹çš„ Pod è°ƒåº¦åˆ°çš„èŠ‚ç‚¹ä¸Šï¼Œä½†ä¸èƒ½ä¿è¯å®Œå…¨é¿å…ã€‚</li><li><code>NoExecute</code>ï¼šè¯¥é€‰é¡¹æ„å‘³ç€ä¸€æ—¦ Taint ç”Ÿæ•ˆï¼Œå¦‚è¯¥èŠ‚ç‚¹å†…æ­£åœ¨è¿è¡Œçš„ POD æ²¡æœ‰å¯¹åº” Tolerate è®¾ç½®ï¼Œä¼šç›´æ¥è¢«é€å‡ºã€‚</li></ol><h2 id="Refer"><a href="#Refer" class="headerlink" title="Refer"></a>Refer</h2><ul><li><a href="https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration/">https://kubernetes.io/zh-cn/docs/concepts/scheduling-eviction/taint-and-toleration/</a></li><li><a href="https://kubernetes.io/docs/concepts/configuration/assign-pod-node/">https://kubernetes.io/docs/concepts/configuration/assign-pod-node/</a></li><li><a href="https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/">https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/</a></li><li><a href="https://coreos.com/fleet/docs/latest/affinity.html">https://coreos.com/fleet/docs/latest/affinity.html</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes Probes Intros</title>
    <link href="/2024/07/31/Kubernetes-Probes/"/>
    <url>/2024/07/31/Kubernetes-Probes/</url>
    
    <content type="html"><![CDATA[<h2 id="Probes-Introduction"><a href="#Probes-Introduction" class="headerlink" title="Probes Introduction"></a>Probes Introduction</h2><ul><li><p><strong>å­˜æ´»æ€§æ¢æµ‹ (Liveness probes):</strong> å­˜æ´»æ€§æ¢é’ˆï¼Œç”¨äºåˆ¤æ–­å®¹å™¨æ˜¯ä¸æ˜¯å¥åº·ï¼Œå¦‚æœä¸æ»¡è¶³å¥åº·æ¡ä»¶ï¼Œé‚£ä¹ˆ Kubelet å°†æ ¹æ® Pod ä¸­è®¾ç½®çš„ restartPolicy ï¼ˆé‡å¯ç­–ç•¥ï¼‰æ¥åˆ¤æ–­ï¼ŒPod æ˜¯å¦è¦è¿›è¡Œé‡å¯æ“ä½œã€‚</p><blockquote><p>LivenessProbe æŒ‰ç…§é…ç½®å»æ¢æµ‹ ( è¿›ç¨‹ã€æˆ–è€…ç«¯å£ã€æˆ–è€…å‘½ä»¤æ‰§è¡Œåæ˜¯å¦æˆåŠŸç­‰ç­‰)ï¼Œæ¥åˆ¤æ–­å®¹å™¨æ˜¯ä¸æ˜¯æ­£å¸¸ã€‚å¦‚æœæ¢æµ‹ä¸åˆ°ï¼Œä»£è¡¨å®¹å™¨ä¸å¥åº·ï¼ˆå¯ä»¥é…ç½®è¿ç»­å¤šå°‘æ¬¡å¤±è´¥æ‰è®°ä¸ºä¸å¥åº·ï¼‰ï¼Œåˆ™ kubelet ä¼šæ€æ‰è¯¥å®¹å™¨ï¼Œå¹¶æ ¹æ®å®¹å™¨çš„é‡å¯ç­–ç•¥åšç›¸åº”çš„å¤„ç†ã€‚å¦‚æœæœªé…ç½®å­˜æ´»æ¢é’ˆï¼Œåˆ™é»˜è®¤å®¹å™¨å¯åŠ¨ä¸ºé€šè¿‡ï¼ˆSuccessï¼‰çŠ¶æ€ã€‚å³æ¢é’ˆè¿”å›çš„å€¼æ°¸è¿œæ˜¯ Successã€‚å³ Success å pod çŠ¶æ€æ˜¯ RUNING</p></blockquote></li><li><p><strong>å°±ç»ªæ€§æ¢æµ‹ (Readiness probes):</strong> å°±ç»ªæ€§æ¢é’ˆï¼Œç”¨äºåˆ¤æ–­å®¹å™¨å†…çš„ç¨‹åºæ˜¯å¦å­˜æ´»ï¼ˆæˆ–è€…è¯´æ˜¯å¦å¥åº·ï¼‰ï¼Œåªæœ‰ç¨‹åº(æœåŠ¡)æ­£å¸¸ï¼Œ å®¹å™¨å¼€å§‹å¯¹å¤–æä¾›ç½‘ç»œè®¿é—®ï¼ˆå¯åŠ¨å®Œæˆå¹¶å°±ç»ªï¼‰ã€‚</p><blockquote><p>å®¹å™¨å¯åŠ¨åæŒ‰ç…§ ReadinessProbe é…ç½®è¿›è¡Œæ¢æµ‹ï¼Œæ— é—®é¢˜åç»“æœä¸ºæˆåŠŸå³çŠ¶æ€ä¸º Successã€‚pod çš„ READY çŠ¶æ€ä¸º trueï¼Œä» 0&#x2F;1 å˜ä¸º 1&#x2F;1ã€‚å¦‚æœå¤±è´¥ç»§ç»­ä¸º 0&#x2F;1ï¼ŒçŠ¶æ€ä¸º falseã€‚è‹¥æœªé…ç½®å°±ç»ªæ¢é’ˆï¼Œåˆ™é»˜è®¤çŠ¶æ€å®¹å™¨å¯åŠ¨åä¸º Successã€‚å¯¹äºæ­¤ podã€æ­¤ pod å…³è”çš„ Service èµ„æºã€EndPoint çš„å…³ç³»ä¹Ÿå°†åŸºäº Pod çš„ Ready çŠ¶æ€è¿›è¡Œè®¾ç½®ï¼Œå¦‚æœ Pod è¿è¡Œè¿‡ç¨‹ä¸­ Ready çŠ¶æ€å˜ä¸º falseï¼Œåˆ™ç³»ç»Ÿè‡ªåŠ¨ä» Service èµ„æº å…³è”çš„ EndPoint åˆ—è¡¨ä¸­å»é™¤æ­¤ podï¼Œå±Šæ—¶ service èµ„æºæ¥æ”¶åˆ° GET è¯·æ±‚åï¼Œkube-proxy å°†ä¸€å®šä¸ä¼šæŠŠæµé‡å¼•å…¥æ­¤ pod ä¸­ï¼Œé€šè¿‡è¿™ç§æœºåˆ¶å°±èƒ½é˜²æ­¢å°†æµé‡è½¬å‘åˆ°ä¸å¯ç”¨çš„ Pod ä¸Šã€‚å¦‚æœ Pod æ¢å¤ä¸º Ready çŠ¶æ€ã€‚å°†å†ä¼šè¢«åŠ å› Endpoint åˆ—è¡¨ã€‚kube-proxy ä¹Ÿå°†æœ‰æ¦‚ç‡é€šè¿‡è´Ÿè½½æœºåˆ¶ä¼šå¼•å…¥æµé‡åˆ°æ­¤ pod ä¸­ã€‚</p></blockquote></li><li><p><strong>å¯åŠ¨æ¢æµ‹ (Startup Probes):</strong> å¯¹äºæ—§åº”ç”¨éœ€è¦æ›´é•¿çš„å¯åŠ¨æ—¶é—´ï¼Œè¿™æ—¶å€™æ—¢ä¸æƒ³é‡å¯åº”ç”¨ä¹Ÿä¸æƒ³è®©è¯·æ±‚è®¿é—®è¿›æ¥ï¼Œå¯ä»¥è®¾ç½®å¯åŠ¨æ¢æµ‹ç»™è¶³å¤Ÿçš„å¯åŠ¨æ—¶é—´ä¿è¯åº”ç”¨å¯åŠ¨æˆåŠŸ</p></li></ul><h2 id="Execution-Order"><a href="#Execution-Order" class="headerlink" title="Execution Order"></a>Execution Order</h2><p>å¯ä»¥è‡ªå®šä¹‰åœ¨ pod å¯åŠ¨æ—¶æ˜¯å¦æ‰§è¡Œè¿™äº›æ£€æµ‹ï¼Œå¦‚æœä¸è®¾ç½®ï¼Œåˆ™æ£€æµ‹ç»“æœå‡é»˜è®¤ä¸ºé€šè¿‡ï¼›</p><p>å¦‚æœè®¾ç½®ï¼Œåˆ™é¡ºåºä¸ºï¼š <code>startupProbe --&gt; readinessProbe --&gt; livenessProbe</code></p><p>ä½†æ˜¯çœŸçš„æ˜¯ä¸Šé¢çš„é¡ºåºå˜›ï¼Ÿ å®˜æ–¹æ–‡æ¡£ä¸Šå´è¯´ä¸æ˜¯ï¼Œå…¶ä¸­æœ‰ä¸€æ®µè¯´åˆ°ã€‚</p><blockquote><p>Caution: Liveness probes do not wait for readiness probes to succeed. If you want to wait before executing a liveness probe you should use initialDelaySeconds or a startupProbe.</p></blockquote><blockquote><p>livenessProbe ä¸ä¼šç­‰å¾… readinessProbe æˆåŠŸã€‚å¦‚æœä½ æƒ³åœ¨æ‰§è¡Œ livenessProbe ä¹‹å‰ç­‰å¾…ï¼Œä½ åº”è¯¥ä½¿ç”¨ initialDelaySeconds æˆ– startupProbeã€‚</p></blockquote><p>æ‰€ä»¥çœŸæ­£çš„é¡ºåºæ˜¯ï¼š<code>startupProbe --&gt; readinessProbe(livenessProbe)</code></p><p>readinessProbe å’Œ livenessProbe ä¹‹é—´æ˜¯å¼‚æ­¥å¹¶å‘çš„ã€‚</p><h2 id="LivenessProbe-ReadinessProbe-Usage"><a href="#LivenessProbe-ReadinessProbe-Usage" class="headerlink" title="LivenessProbe &amp; ReadinessProbe Usage"></a>LivenessProbe &amp; ReadinessProbe Usage</h2><h3 id="æ¢æµ‹æ–¹æ³•"><a href="#æ¢æµ‹æ–¹æ³•" class="headerlink" title="æ¢æµ‹æ–¹æ³•"></a>æ¢æµ‹æ–¹æ³•</h3><p>LivenessProbe å’Œ ReadinessProbe ä¸¤ç§æ¢é’ˆéƒ½æ”¯æŒä¸‹é¢ä¸‰ç§æ¢æµ‹æ–¹æ³•ï¼š</p><ul><li>ExecActionï¼šåœ¨å®¹å™¨ä¸­æ‰§è¡ŒæŒ‡å®šçš„å‘½ä»¤ï¼Œå¦‚æœæ‰§è¡ŒæˆåŠŸï¼Œé€€å‡ºç ä¸º 0 åˆ™æ¢æµ‹æˆåŠŸã€‚</li><li>HTTPGetActionï¼šé€šè¿‡å®¹å™¨çš„ IP åœ°å€ã€ç«¯å£å·åŠè·¯å¾„è°ƒç”¨ HTTP Get æ–¹æ³•ï¼Œå¦‚æœå“åº”çš„çŠ¶æ€ç å¤§äºç­‰äº - 200 ä¸”å°äº 400ï¼Œåˆ™è®¤ä¸ºå®¹å™¨ å¥åº·ã€‚</li><li>TCPSocketActionï¼šé€šè¿‡å®¹å™¨çš„ IP åœ°å€å’Œç«¯å£å·æ‰§è¡Œ TCP æ£€ æŸ¥ï¼Œå¦‚æœèƒ½å¤Ÿå»ºç«‹ TCP è¿æ¥ï¼Œåˆ™è¡¨æ˜å®¹å™¨å¥åº·ã€‚</li></ul><h2 id="æ¢æµ‹å‚æ•°"><a href="#æ¢æµ‹å‚æ•°" class="headerlink" title="æ¢æµ‹å‚æ•°"></a>æ¢æµ‹å‚æ•°</h2><p>LivenessProbe å’Œ ReadinessProbe ä¸¤ç§æ¢é’ˆçš„ç›¸å…³å±æ€§<br>æ¢é’ˆ(Probe)æœ‰è®¸å¤šå¯é€‰å­—æ®µï¼Œå¯ä»¥ç”¨æ¥æ›´åŠ ç²¾ç¡®çš„æ§åˆ¶ Liveness å’Œ Readiness ä¸¤ç§æ¢é’ˆçš„è¡Œä¸º(Probe)ï¼š</p><ul><li><p>initialDelaySecondsï¼šå®¹å™¨å¯åŠ¨åè¦ç­‰å¾…å¤šå°‘ç§’åå°±æ¢é’ˆå¼€å§‹å·¥ä½œï¼Œå•ä½â€œç§’â€ï¼Œé»˜è®¤æ˜¯ 0 ç§’ï¼Œæœ€å°å€¼æ˜¯ 0</p></li><li><p>periodSecondsï¼šæ‰§è¡Œæ¢æµ‹çš„æ—¶é—´é—´éš”ï¼ˆå•ä½æ˜¯ç§’ï¼‰ï¼Œé»˜è®¤ä¸º 10sï¼Œå•ä½â€œç§’â€ï¼Œæœ€å°å€¼æ˜¯ 1</p></li><li><p>timeoutSecondsï¼šæ¢é’ˆæ‰§è¡Œæ£€æµ‹è¯·æ±‚åï¼Œç­‰å¾…å“åº”çš„è¶…æ—¶æ—¶é—´ï¼Œé»˜è®¤ä¸º 1sï¼Œå•ä½â€œç§’â€ï¼Œæœ€å°å€¼æ˜¯ 1</p></li><li><p>successThresholdï¼šæ¢é’ˆæ£€æµ‹å¤±è´¥åè®¤ä¸ºæˆåŠŸçš„æœ€å°è¿æ¥æˆåŠŸæ¬¡æ•°ï¼Œé»˜è®¤ä¸º 1sï¼Œåœ¨ Liveness æ¢é’ˆä¸­å¿…é¡»ä¸º 1sï¼Œæœ€å°å€¼ä¸º 1sã€‚</p></li><li><p>failureThresholdï¼šæ¢æµ‹å¤±è´¥çš„é‡è¯•æ¬¡æ•°ï¼Œé‡è¯•ä¸€å®šæ¬¡æ•°åå°†è®¤ä¸ºå¤±è´¥ï¼Œåœ¨ readiness æ¢é’ˆä¸­ï¼ŒPod ä¼šè¢«æ ‡è®°ä¸ºæœªå°±ç»ªï¼Œé»˜è®¤ä¸º 3sï¼Œæœ€å°å€¼ä¸º 1s</p><blockquote><p>Tipsï¼šinitialDelaySeconds åœ¨ ReadinessProbe å…¶å®å¯ä»¥ä¸ç”¨é…ç½®ï¼Œä¸é…ç½®é»˜è®¤ pod åˆšå¯åŠ¨ï¼Œå¼€å§‹è¿›è¡Œ ReadinessProbe æ¢æµ‹ï¼Œç­‰æœåŠ¡å¯åŠ¨åå¹¶æ£€æŸ¥ success æˆåŠŸåï¼ŒREADY çŠ¶æ€è‡ªç„¶æ­£å¸¸ã€‚</p></blockquote></li></ul><h2 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">liveness-http</span><br>    <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">test:</span> <span class="hljs-string">liveness</span><br><span class="hljs-attr">spec:</span><br>    <span class="hljs-attr">containers:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">liveness</span><br>          <span class="hljs-attr">image:</span> <span class="hljs-string">test.com/test-http-prober:v0.0.1</span><br>          <span class="hljs-attr">LivenessProbe:</span><br>              <span class="hljs-attr">failureThreshold:</span> <span class="hljs-number">5</span> <span class="hljs-comment">#æ£€æµ‹å¤±è´¥5æ¬¡è¡¨ç¤ºæœªå°±ç»ª</span><br>              <span class="hljs-attr">initialDelaySeconds:</span> <span class="hljs-number">20</span> <span class="hljs-comment">#å»¶è¿ŸåŠ è½½æ—¶é—´</span><br>              <span class="hljs-attr">periodSeconds:</span> <span class="hljs-number">10</span> <span class="hljs-comment">#é‡è¯•æ—¶é—´é—´éš”</span><br>              <span class="hljs-attr">timeoutSeconds:</span> <span class="hljs-number">5</span> <span class="hljs-comment">#è¶…æ—¶æ—¶é—´è®¾ç½®</span><br>              <span class="hljs-attr">successThreshold:</span> <span class="hljs-number">2</span> <span class="hljs-comment">#æ£€æŸ¥æˆåŠŸä¸º2æ¬¡è¡¨ç¤ºå°±ç»ª</span><br>              <span class="hljs-attr">httpGet:</span><br>                  <span class="hljs-attr">port:</span> <span class="hljs-number">8082</span><br>                  <span class="hljs-attr">path:</span> <span class="hljs-string">/status/health</span><br></code></pre></td></tr></table></figure><h2 id="Refer"><a href="#Refer" class="headerlink" title="Refer"></a>Refer</h2><ul><li><a href="https://juejin.cn/post/7163135179177852936">https://juejin.cn/post/7163135179177852936</a></li><li><a href="https://juejin.cn/post/7163135453489528845">https://juejin.cn/post/7163135453489528845</a></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Systemd Journal Logs Too Big Debug</title>
    <link href="/2024/06/26/systemd-log-too-big/"/>
    <url>/2024/06/26/systemd-log-too-big/</url>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>æœ€è¿‘çš„æœºå™¨ç£ç›˜å®¹é‡ç»å¸¸æŠ¥è­¦,å‘ç°ä»¥ä¸‹ç›®å½•çš„ç£ç›˜å ç”¨è¾ƒå¤š</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo <span class="hljs-built_in">du</span> -sh ./* --exclude ./proc | <span class="hljs-built_in">sort</span> -rh  | <span class="hljs-built_in">head</span> -n 5<br></code></pre></td></tr></table></figure><p><strong><code>/run/log/journal</code></strong> æ˜¯ Systemd çš„æ—¥å¿—ç›®å½•ï¼Œç”¨äºå­˜å‚¨ Systemd æ—¥å¿—æ–‡ä»¶ã€‚ä½ å¯ä»¥ä½¿ç”¨ <strong><code>journalctl</code></strong> å·¥å…·æ¥ç®¡ç†å’Œæ¸…ç†è¿™äº›æ—¥å¿—æ–‡ä»¶ã€‚ä»¥ä¸‹æ˜¯æ¸…ç† Systemd æ—¥å¿—çš„æ–¹æ³•.</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><h3 id="1-åˆ—å‡ºæ—¥å¿—æ¡ç›®ï¼š"><a href="#1-åˆ—å‡ºæ—¥å¿—æ¡ç›®ï¼š" class="headerlink" title="1. åˆ—å‡ºæ—¥å¿—æ¡ç›®ï¼š"></a>1. åˆ—å‡ºæ—¥å¿—æ¡ç›®ï¼š</h3><p>è‹¥è¦æŸ¥çœ‹å¯ç”¨çš„æ—¥å¿—æ¡ç›®ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š</p><pre><code class="hljs"><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">journalctl</span><br></code></pre></td></tr></table></figure>è¿™å°†æ˜¾ç¤ºå½“å‰å¯ç”¨çš„ Systemd æ—¥å¿—ã€‚</code></pre><h3 id="2-è®¾ç½®æ—¥å¿—ä¿ç•™ç­–ç•¥ï¼š"><a href="#2-è®¾ç½®æ—¥å¿—ä¿ç•™ç­–ç•¥ï¼š" class="headerlink" title="2. è®¾ç½®æ—¥å¿—ä¿ç•™ç­–ç•¥ï¼š"></a>2. è®¾ç½®æ—¥å¿—ä¿ç•™ç­–ç•¥ï¼š</h3><p>Systemd ä½¿ç”¨æ—¥å¿—ä¿ç•™ç­–ç•¥æ¥ç®¡ç†æ—¥å¿—æ–‡ä»¶çš„ä¿ç•™æ—¶é—´ã€‚ä½ å¯ä»¥é€šè¿‡ç¼–è¾‘ <strong><code>/etc/systemd/journald.conf</code></strong> æ–‡ä»¶æ¥é…ç½®æ—¥å¿—ä¿ç•™ç­–ç•¥ã€‚æŸ¥æ‰¾ <strong><code>SystemKeepFree</code><strong>ã€</strong><code>SystemMaxUse</code></strong> å’Œ <strong><code>RuntimeMaxUse</code></strong> é€‰é¡¹ï¼Œç„¶åæ ¹æ®éœ€è¦è¿›è¡Œè®¾ç½®ã€‚ä¾‹å¦‚ï¼š</p><pre><code class="hljs"><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><br>SystemMaxUse=100M<br></code></pre></td></tr></table></figure>è¿™å°†é…ç½® Systemd æ—¥å¿—æœ€å¤§å ç”¨çš„ç£ç›˜ç©ºé—´ä¸º 100MBã€‚ä½ å¯ä»¥æ ¹æ®ä½ çš„éœ€æ±‚è°ƒæ•´æ­¤å€¼ã€‚</code></pre><h3 id="3-æ¸…ç†æ—¥å¿—ï¼š"><a href="#3-æ¸…ç†æ—¥å¿—ï¼š" class="headerlink" title="3. æ¸…ç†æ—¥å¿—ï¼š"></a>3. æ¸…ç†æ—¥å¿—ï¼š</h3><p>ä¸€æ—¦ä½ è®¾ç½®äº†æ—¥å¿—ä¿ç•™ç­–ç•¥ï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥æ¸…ç†æ—¥å¿—ï¼š</p><pre><code class="hljs"><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">sudo journalctl <span class="hljs-attr">--vacuum-time</span>=<span class="hljs-number">1</span>h<br></code></pre></td></tr></table></figure>è¿™å°†åˆ é™¤ä¸‰å¤©å‰çš„æ—¥å¿—ï¼Œä¿ç•™æœ€è¿‘ä¸‰å¤©çš„æ—¥å¿—ã€‚ä½ å¯ä»¥æ›´æ”¹ **`--vacuum-time`** æ ‡å¿—çš„å€¼æ¥å®šä¹‰ä¿ç•™å¤šé•¿æ—¶é—´çš„æ—¥å¿—ã€‚</code></pre><h3 id="4-æŸ¥çœ‹æ¸…ç†åçš„æ—¥å¿—å¤§å°ï¼š"><a href="#4-æŸ¥çœ‹æ¸…ç†åçš„æ—¥å¿—å¤§å°ï¼š" class="headerlink" title="4. æŸ¥çœ‹æ¸…ç†åçš„æ—¥å¿—å¤§å°ï¼š"></a>4. æŸ¥çœ‹æ¸…ç†åçš„æ—¥å¿—å¤§å°ï¼š</h3><p>è‹¥è¦éªŒè¯æ¸…ç†åçš„æ—¥å¿—æ–‡ä»¶å¤§å°ï¼Œå¯ä»¥å†æ¬¡è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š</p><pre><code class="hljs"><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">journalctl</span><br></code></pre></td></tr></table></figure>è¿™å°†æ˜¾ç¤ºå½“å‰å¯ç”¨çš„æ—¥å¿—ä¿¡æ¯ï¼ŒåŒ…æ‹¬å·²æ¸…ç†çš„éƒ¨åˆ†ã€‚</code></pre><h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>è¯·æ³¨æ„ï¼Œæ¸…ç† Systemd æ—¥å¿—éœ€è¦è¶³å¤Ÿçš„æƒé™ã€‚ç¡®ä¿ä½ æœ‰è¶³å¤Ÿçš„æƒé™æ¥æ‰§è¡Œè¿™äº›æ“ä½œï¼Œæˆ–è€…ä½¿ç”¨ <strong><code>sudo</code></strong> å‘½ä»¤ä»¥ç®¡ç†å‘˜æƒé™æ‰§è¡Œã€‚æ¸…ç†æ—¥å¿—æ–‡ä»¶å¯èƒ½ä¼šé‡Šæ”¾ç£ç›˜ç©ºé—´ï¼Œä½†ä¹Ÿå¯èƒ½ä¼šå¯¼è‡´ä¸¢å¤±ä¸€äº›æ—§æ—¥å¿—ä¿¡æ¯ï¼Œå› æ­¤è¯·æ ¹æ®ä½ çš„éœ€æ±‚å’Œå­˜å‚¨ç©ºé—´æƒ…å†µæ…é‡é€‰æ‹©æ¸…ç†ç­–ç•¥ã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>Debug</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes FailedScheduling Debug</title>
    <link href="/2024/06/25/Kubernetes-FailedScheduling-Debug/"/>
    <url>/2024/06/25/Kubernetes-FailedScheduling-Debug/</url>
    
    <content type="html"><![CDATA[<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>æ­£åœ¨ä½¿ç”¨Kubernetesè¿›è¡ŒDruidéƒ¨ç½²,å‘ç°æ›´æ”¹stsçš„replicaä¹‹åpodä¸€ç›´å¤„äºpendingçŠ¶æ€,æ¥ä¸‹æ¥é€šè¿‡describeæŸ¥çœ‹podçš„éƒ¨ç½²çŠ¶æ€,å‘ç°ä»¥ä¸‹log</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">nodeSelector_new:</span><br>  <span class="hljs-attr">dedicated:</span> <span class="hljs-string">druid-middlemanager</span><br><br><span class="hljs-attr">tolerations:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;dedicated&quot;</span><br>    <span class="hljs-attr">operator:</span> <span class="hljs-string">&quot;Equal&quot;</span><br>    <span class="hljs-attr">value:</span> <span class="hljs-string">&quot;druid&quot;</span><br>    <span class="hljs-attr">effect:</span> <span class="hljs-string">&quot;NoSchedule&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">Node-Selectors:              dedicated=druid-middlemanager<br>Tolerations:                 dedicated=druid:NoSchedule<br><br>Events:<br>  Type     Reason             Age                 From                Message<br>  ----     ------             ----                ----                -------<br>  Normal   NotTriggerScaleUp  117s                cluster-autoscaler  pod didn<span class="hljs-string">&#x27;t trigger scale-up: 1 node(s) had untolerated taint &#123;dedicated: ***&#125; .......</span><br><span class="hljs-string">  Warning  FailedScheduling   10s (x9 over 2m8s)  default-scheduler   0/84 nodes are available: 1 Insufficient memory, 1 node(s) had untolerated taint &#123;dedicated: ****&#125; ...</span><br></code></pre></td></tr></table></figure><h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2><p>ç¬¬ä¸€ååº”è®¤ä¸ºå¯èƒ½æ˜¯ä»¥ä¸‹Bugs</p><ol><li>nodegroupèµ„æºçš„labelé”™è¯¯</li><li>stsèµ„æºçš„labelé”™è¯¯</li><li>nodegroupçš„auto scaleå¤±æ•ˆ</li></ol><p>é€šè¿‡æ£€æŸ¥sts å’Œ nodegroupçš„dedicatedå’Œtolerationså‘ç°å¹¶æ²¡æœ‰é—®é¢˜,æ’é™¤äº†Bug 1å’ŒBug 2,é‡ç‚¹æ”¾åœ¨Bug 3ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">K8s Labels: foc/bottlerocket=<span class="hljs-literal">true</span> dedicated=druid-middlemanager<br>K8s Taints: dedicated=druid:NoSchedule<br></code></pre></td></tr></table></figure><p>ç›®å‰nodegroupå†…å·²ç»æœ‰äº†ä¸€ä¸ªnode,å¦‚æœèµ„æºä¸å¤Ÿçš„è¯ä¼šåœ¨node groupçš„activitiesæœ‰å°è¯•æ‰©å®¹çš„log,ä½†æ˜¯å¹¶æ²¡æœ‰,å› æ­¤å¹¶ä¸æ˜¯æ‰©å®¹èƒ½è§£å†³çš„é—®é¢˜ã€‚<br>å› æ­¤æ’é™¤äº†Bug 3ã€‚</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>æœ€ç»ˆå‘ç°æ˜¯nodegroupçš„æœºå‹å†…å­˜è¾ƒå°,å³ä¾¿æ‰©å®¹ä¹Ÿæ— æ³•æä¾›è¿™ä¹ˆå¤§å†…å­˜çš„nodeä¾›å•ä¸ªpodä½¿ç”¨,å› æ­¤ä¼šå¯¼è‡´ä»¥ä¸ŠæŠ¥é”™ã€‚<br>è¿™ä¸ªlogså¾ˆå®¹æ˜“è®©äººå¾€èµ„æºlabelä¸åŒ¹é…çš„æ–¹é¢æˆ–è€…auto scaleå¤±æ•ˆçš„æ–¹é¢å»æƒ³,å¾ˆéšè”½çš„bugã€‚</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">resources:</span><br>  <span class="hljs-attr">limits:</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">110Gi</span><br>  <span class="hljs-attr">requests:</span><br>    <span class="hljs-attr">memory:</span> <span class="hljs-string">110Gi</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Debug</tag>
      
      <tag>Druid</tag>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HDFS Decomission Codes and Intros</title>
    <link href="/2024/06/17/HDFS-Decomission-Codes-and-Introduction/"/>
    <url>/2024/06/17/HDFS-Decomission-Codes-and-Introduction/</url>
    
    <content type="html"><![CDATA[<h1 id="HDFS-Decomission-Codes-and-Intros"><a href="#HDFS-Decomission-Codes-and-Intros" class="headerlink" title="HDFS Decomission Codes and Intros"></a>HDFS Decomission Codes and Intros</h1><h2 id="Background-of-HDFS-decomission"><a href="#Background-of-HDFS-decomission" class="headerlink" title="Background of HDFS decomission"></a>Background of HDFS decomission</h2><p> Currently there are 200+ 1.22PB HDFS3 and 100- 480T HDFS nodes, the decommissioning nodes are slow and can only migrate about 150k blocks per hour, on average a node has about 600k blocks and one takes about 4 hours.</p><h2 id="Difference-between-node-drop-and-node-retirement"><a href="#Difference-between-node-drop-and-node-retirement" class="headerlink" title="Difference between node drop and node retirement?"></a><strong>Difference between node drop and node retirement?</strong></h2><h3 id="Node-Decommissioning"><a href="#Node-Decommissioning" class="headerlink" title="Node Decommissioning"></a><strong>Node Decommissioning</strong></h3><p> First of all, normally add the node to the decommissioning list, first tell namenode and yarn not to submit new tasks and write data up; and then wait for the node on the data block in the cluster replication is complete; <strong>this time the decommissioned node is prioritized as the srcNode data source (preferred to choose the decommissioned node as a replicated data source src, because it has no write requests, low load</strong> ), the other nodes from the <strong>decommissioned</strong> node to <strong>replicate data source src</strong>. Other nodes copy data blocks from this retired node to other nodes, so the load on this node will be high at this time. All data blocks are replicated and the node status becomes Decommissioned, which can be viewed from the namenodeURL interface. <strong>Note that the data node decommissioned data to start replication time is also 10 minutes and 30s later, and will not start earlier because it is actively decommissioned, because the namenode and datanode will always maintain a simple master-slave relationship, the namenode node will not actively initiate any IPC calls to the datanode node, the datanode node needs to cooperate with the All operations completed by the namenode are returned through the DatanodeCommand carried by both heartbeat answers.</strong></p><h3 id="Node-Drop"><a href="#Node-Drop" class="headerlink" title="Node Drop"></a>Node Drop</h3><p> For example, forced stop datanode, the physical machine hangs (such as high load drop, sudden network failure, hardware failure, etc.), these are node drop, the general default 10 minutes after 30s (mainly controlled by two parameters) namenode will detect the node communication anomaly drop. Then namenode according to the nodeâ€™s ip, find out all the nodeâ€™s blockid, as well as the corresponding copy of the machine, through the heartbeat mechanism to arrange for data replication, this time the data replication, the data source is not in the node is not down, but one of the multiple copies of the node, the same this time the copy replication also follow the rack-awareness, copy shelving strategy.</p><aside>ğŸ’¡  The difference between node drop and decommissioning of the two is not only the data replication method is different, there is also namenode Under-Replicated Blocks of data replication strategy is not the same (data block block replication level is divided into five kinds); extreme examples such as single-copy node decommissioning data will not be lost, a single-copy node drop data will be really lost;</aside><h3 id="Network-storm-caused-by-node-drop"><a href="#Network-storm-caused-by-node-drop" class="headerlink" title="Network storm caused by node drop"></a>Network storm caused by node drop</h3><p> dozens of T, or even hundreds of T, millions of block node drop, there will be a large number of RPC storms, especially for large-scale high-load clusters on namenode is a big challenge, not only affects the performance of the production, but also there will be a great deal of hidden danger, especially for the bandwidth bottleneck of the limitations of clusters.</p><p> Generally speaking the value of namenode to detect whether datanode is dropped is 10<em>3s (heartbeat time) + 2</em>5min (namenode detection time, the parameter is: <code>dfs.namenode.heartbeat.recheck-interval</code> ) &#x3D; 10min30s. if within 10min30s of time bandwidth continues to hit full, RPC requests are delayed, and datanode and namenode nodes are not communicating well, it is easy to cause other nodes to continue to fall offline, forming a vicious cycle, how should this situation be avoided?</p><p> NameNode maintains a replication priority queue, for the file block with insufficient replicas, the file block with only one replica left will enjoy the highest replication priority. So if you look at a cluster with two replicas, as long as there is an exception in one block, there will be only one replica left, which is the highest-priority block replica, and it will be storm mode replication, which will easily affect the cluster performance if not well controlled, and even hang the cluster. Therefore, it is generally not recommended that the cluster copy factor is 2.</p><aside>ğŸ’¡  L1 (highest): there is a risk of data loss of the block, such as: 1. Only one copy of the block (especially for 2 copies of the block, down a node) or these blocks have 0 active copy; 2, single copy in the node is being decommissioned to own the block.<p> L2:Block replicas whose actual value is much lower than the configured value (e.g., 3 replicas, 2 missing), i.e., blocks whose replica count is less than 1&#x2F;3 of the expected value, and these blocks are replicated with second priority. For example, 4 copies of block, there are 3 lost or broken, it will be replicated with priority than 4 copies of block missing 2.</p><p> L3:Insufficient copies are not as high as those with priority L2, which are replicated first. Third priority.</p><p> L4:block meets the minimum number of copies required. The replica degree requirement is lower than both L2-L3.</p><p> L5:Damaged blocks and currently have available non-damaged replicas</p></aside><h3 id="Parameters-control-RPC-storms-caused-by-node-drops"><a href="#Parameters-control-RPC-storms-caused-by-node-drops" class="headerlink" title="Parameters control RPC storms caused by node drops"></a>Parameters control RPC storms caused by node drops</h3><p> The three parameters are <code>hdfs-site.xml</code> parameters, you can refer to the apache hadoop official website, in fact, there are two aspects of the block replication speed to determine, one is the speed of namenode distribution tasks, the second is the speed of replication between datanode. The former can be understood as the entrance and the latter can be treated as the exit.</p><blockquote><p>These parameters are not available in hadoop 2.7.3</p></blockquote><h4 id="Ingress-Parameters"><a href="#Ingress-Parameters" class="headerlink" title="Ingress Parameters"></a>Ingress Parameters</h4><p> Controls the distribution of tasks from the namenode level. Changes to this parameter require <strong>a restart of the namenode</strong>, not the datanode.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.work.multiplier.per.iteration <br>default=2<br></code></pre></td></tr></table></figure><p> This parameter determines the number of blocks that each DN is told to replicate when the NN has a heartbeat (3s) with the DN to send the task list. For example, if the cluster has 500 nodes and this value is set to 10, then the number of data blocks that a heartbeat namnode can send datanode to replicate is 10*500&#x3D;5000 blocks.</p><p> If a node drops&#x2F;retires and there are 800000 blocks to be replicated, how long does it take for the namenode to finish distributing the task of replicating the blocks to the datanode.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">task</span> <span class="hljs-string">distribution</span> <span class="hljs-string">time</span> <span class="hljs-string">=</span> <br><span class="hljs-string">wait</span> <span class="hljs-string">for</span> <span class="hljs-string">copy</span> <span class="hljs-string">block</span> <span class="hljs-string">number</span> <span class="hljs-string">/</span> <span class="hljs-string">(datanode</span> <span class="hljs-string">number</span> <span class="hljs-string">*</span> <span class="hljs-string">parameters)</span> <span class="hljs-string">*</span> <span class="hljs-string">heartbeat</span> <span class="hljs-string">interval</span> <span class="hljs-string">time</span><br></code></pre></td></tr></table></figure><h4 id="Export-Parameters"><a href="#Export-Parameters" class="headerlink" title="Export Parameters"></a>Export Parameters</h4><p> In contrast to the above, which controls task distribution from the nanode, the following two parameters are controlled at the datanode level, and require <strong>a restart of the namenode</strong>.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">dfs.namenode.replication.max-streams</span><br><span class="hljs-string">default=2</span><br></code></pre></td></tr></table></figure><p> The meaning of this parameter is to control the datanode node to carry out data replication of the maximum number of threads, from the above we know that the block replication priority is divided into five kinds. This parameter controls the replication of blocks that do not contain the highest priority. This parameter controls the replication of blocks that do not contain the highest priority.</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">dfs.namenode.replication.max-streams-hard-limit</span><br><span class="hljs-string">hadoop</span> <span class="hljs-string">default=2,</span> <span class="hljs-string">cdh</span> <span class="hljs-string">default=40</span><br></code></pre></td></tr></table></figure><p> The meaning of this parameter is to control the number of streams copied by all priority blocks of the datanode, including the highest priority; generally used in conjunction with the above and above two parameters each other.</p><aside>ğŸ’¡  The former parameter controls how often the datanode accepts tasks, and the latter two parameters further limit the maximum amount of parallel threaded network transfers that the DataNode can accomplish at one time. How much to set the value of the above parameters depends on the cluster size and cluster configuration, and cannot be determined in the same way. Generally speaking, it is simpler and easier to control from the entrance. For example, the scale of 500 clusters, dfs.namenode.replication.work.multiplier.per.iteration = 10, then the cluster heartbeat distribution of 5000 blocks at a time, if the cluster file storage is broken up in all 500 nodes, each node at the same time replicated 10 blocks (). The actual will be because of the replica shelving policy, rack awareness and so on will not be all the nodes are involved in data replication), each block size 128Mb, then each node's network load is 128 * 10/3 = 546Mb / s, then you have to look at the combination of the actual bandwidth bottlenecks, such a large network IO will affect the normal task of the computation, if so, the value of this If there is, the value should be adjusted down a bit.</aside><h2 id="How-to-go-offline-quickly"><a href="#How-to-go-offline-quickly" class="headerlink" title="How to go offline quickly"></a>How to go offline quickly</h2><p> The essence of how to make nodes go offline quickly is to improve the replication speed of the replica. It is mainly controlled by the above three parameters. The first is to control namenode task distribution, and the second control datanode replication rate, provided that it does not affect the normal production tasks. The smaller the cluster size, the slower the downline, for example, because the total number of distribution will be much slower.</p><p> For example, a 500-unit node <code>dfs.namenode.replication.work.multiplier.per.iteration=10</code>, a 50-unit node this value should be set to 100, both namenode task distribution speed can be consistent. Specifically combined with the actual cluster size settings.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json">&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">10</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams-hard-limit&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">20</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">5</span>&lt;/value&gt;<br>&lt;/property&gt;<br></code></pre></td></tr></table></figure><p> In the test cluster, 15 HDFS, an average of 80k blocks per unit, can migrate 63k blocks per hour, than the initial 12k accelerated by 5 times.</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"># cdh é…ç½®<br>dfs.namenode.replication.work.multiplier.per.iteration=<span class="hljs-number">4</span><br>dfs.namenode.replication.max-streams=<span class="hljs-number">20</span>   <br>dfs.namenode.replication.max-streams-hard-limit=<span class="hljs-number">40</span><br></code></pre></td></tr></table></figure><h4 id="Impact"><a href="#Impact" class="headerlink" title="Impact"></a>Impact</h4><p> Significantly increase CPU Load, CPU IO Wait, Disk IO Wait and other resource utilization.</p><h3 id="Source-Code-Analysis"><a href="#Source-Code-Analysis" class="headerlink" title="Source Code Analysis"></a>Source Code Analysis</h3><p> Once the address of <code>dfs.hosts.exclude</code> is written to conf, refreshNodes can get the exclude list and operate on it.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Rereads conf to get hosts and exclude list file names.</span><br><span class="hljs-comment"> * Rereads the files to update the hosts and exclude lists.  It</span><br><span class="hljs-comment"> * checks if any of the hosts have changed states:</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">refreshNodes</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Configuration conf)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>  refreshHostsReader(conf);<br>  namesystem.writeLock();<br>  <span class="hljs-keyword">try</span> &#123;<br>    refreshDatanodes();<br>    countSoftwareVersions();<br>  &#125; <span class="hljs-keyword">finally</span> &#123;<br>    namesystem.writeUnlock();<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> Read the address of the node through <code>dfs.exclude</code>, then mark it as decommissioned and use monitor to tracking Node.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">public void startDecommission(DatanodeDescriptor node) &#123;<br>  <span class="hljs-keyword">if</span> (!node.isDecommissionInProgress() &amp;&amp; !node.isDecommissioned()) &#123;<br>    // Update DN stats maintained by HeartbeatManager<br>    hbManager.startDecommission(node);<br>    // hbManager.startDecommission will <span class="hljs-built_in">set</span> dead node to decommissioned.<br>    <span class="hljs-keyword">if</span> (node.isDecommissionInProgress()) &#123;<br>      <span class="hljs-keyword">for</span> (DatanodeStorageInfo storage : node.getStorageInfos()) &#123;<br>        LOG.info(<span class="hljs-string">&quot;Starting decommission of &#123;&#125; &#123;&#125; with &#123;&#125; blocks&quot;</span>,<br>            node, storage, storage.numBlocks());<br>      &#125;<br>      node.getLeavingServiceStatus().setStartTime(monotonicNow());<br>      monitor.startTrackingNode(node);<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    LOG.trace(<span class="hljs-string">&quot;startDecommission: Node &#123;&#125; in &#123;&#125;, nothing to do.&quot;</span>,<br>        node, node.getAdminState());<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> Before decommissioning, the cluster stats will be pre-decimated, such as <code>capacityUsed</code>, <code>capacityTotal</code>, and so on.</p><p> monitorâ€™s run() will call processPendingNodes() to take out nodes from the <code>pending nodes</code> and decommission them.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Move any pending nodes into outOfServiceNodeBlocks to initiate the</span><br><span class="hljs-comment"> * decommission or maintenance mode process.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * This method must be executed under the namenode write lock to prevent</span><br><span class="hljs-comment"> * the pendingNodes list from being modified externally.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processPendingNodes</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">while</span> (!pendingNodes.isEmpty() &amp;&amp;<br>      (maxConcurrentTrackedNodes == <span class="hljs-number">0</span> ||<br>          outOfServiceNodeBlocks.size() &lt; maxConcurrentTrackedNodes)) &#123;<br>    outOfServiceNodeBlocks.put(pendingNodes.poll(), <span class="hljs-literal">null</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> After getting the nodes, it will call the check() method, which will get the block information of these nodes and process the PendingReplication Blocks.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">check</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">final</span> List&lt;DatanodeDescriptor&gt; toRemove = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>  <span class="hljs-keyword">if</span> (outOfServiceNodeBlocks.size() == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-comment">// No nodes currently being tracked so simply return</span><br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// Check if there are any pending nodes to process, ie those where the</span><br>  <span class="hljs-comment">// storage has not been scanned yet. For all which are pending, scan</span><br>  <span class="hljs-comment">// the storage and load the under-replicated block list into</span><br>  <span class="hljs-comment">// outOfServiceNodeBlocks. As this does not modify any external structures</span><br>  <span class="hljs-comment">// it can be done under the namenode *read* lock, and the lock can be</span><br>  <span class="hljs-comment">// dropped between each storage on each node.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// TODO - This is an expensive call, depending on how many nodes are</span><br>  <span class="hljs-comment">//        to be processed, but it requires only the read lock and it will</span><br>  <span class="hljs-comment">//        be dropped and re-taken frequently. We may want to throttle this</span><br>  <span class="hljs-comment">//        to process only a few nodes per iteration.</span><br>  outOfServiceNodeBlocks.keySet()<br>      .stream()<br>      .filter(n -&gt; outOfServiceNodeBlocks.get(n) == <span class="hljs-literal">null</span>)<br>      .forEach(n -&gt; scanDatanodeStorage(n, <span class="hljs-literal">true</span>));<br><br>  processMaintenanceNodes();<br>  <span class="hljs-comment">// First check the pending replication list and remove any blocks</span><br>  <span class="hljs-comment">// which are now replicated OK. This list is constrained in size so this</span><br>  <span class="hljs-comment">// call should not be overly expensive.</span><br>  processPendingReplication();<br><br>  <span class="hljs-comment">// Now move a limited number of blocks to pending</span><br>  moveBlocksToPending();<br><br>  <span class="hljs-comment">// Check if any nodes have reached zero blocks and also update the stats</span><br>  <span class="hljs-comment">// exposed via JMX for all nodes still being processed.</span><br>  checkForCompletedNodes(toRemove);<br><br>  <span class="hljs-comment">// Finally move the nodes to their final state if they are ready.</span><br>  processCompletedNodes(toRemove);<br>&#125;<br></code></pre></td></tr></table></figure><ol><li>processPendingReplication() method will call isBlockReplicatedOk() method (the core) will determine whether the block needs reconstruction, and put the information into the <code>*replication queue*</code> in the <code>blockManager</code>.</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">blockManager.neededReconstruction.add(block,<br>    liveReplicas, num.readOnlyReplicas(),<br>    num.outOfServiceReplicas(),<br>    blockManager.getExpectedRedundancyNum(block));<br></code></pre></td></tr></table></figure><ol start="2"><li>The moveBlocksToPending() method determines the length of the queue and the limit of the pending replication, and then creates a block iterator for each node that needs maintenance or delegation, and then each block will continue to call the above mentioned isBlockReplicatedOk() method until the block replication limit is reached, then stop and exit the loop.</li></ol><p> The moveBlocksToPending() method has an interesting piece of locking code.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java">Iterator&lt;DatanodeDescriptor&gt; nodeIter =<br>    Iterables.cycle(iterators.keySet()).iterator();<br><span class="hljs-keyword">while</span> (nodeIter.hasNext()) &#123;<br>  <span class="hljs-comment">// Cycle through each node with blocks which still need processed</span><br>  <span class="hljs-type">DatanodeDescriptor</span> <span class="hljs-variable">dn</span> <span class="hljs-operator">=</span> nodeIter.next();<br>  Iterator&lt;BlockInfo&gt; blockIt = iterators.get(dn);<br>  <span class="hljs-keyword">while</span> (blockIt.hasNext()) &#123;<br>    <span class="hljs-comment">// Process the blocks for the node until we find one that needs</span><br>    <span class="hljs-comment">// replication</span><br>    <span class="hljs-keyword">if</span> (blocksProcessed &gt;= blocksPerLock) &#123;<br>      blocksProcessed = <span class="hljs-number">0</span>;<br>      namesystem.writeUnlock();<br>      namesystem.writeLock();<br>    &#125;<br>    blocksProcessed++;<br>    <span class="hljs-keyword">if</span> (nextBlockAddedToPending(blockIt, dn)) &#123;<br>      <span class="hljs-comment">// Exit the inner &quot;block&quot; loop so an iterator for the next datanode</span><br>      <span class="hljs-comment">// is used for the next block.</span><br>      pendingCount++;<br>      <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure><p> It releases the write lock and then immediately requests a write lock because the <strong><code>blocksProcessed</code></strong> variable is used to keep track of the number of blocks that have been processed. When the number of blocks processed reaches a predetermined threshold of <strong><code>blocksPerLock</code></strong>, it gives other threads waiting for a write lock a chance to execute by releasing the current write lock and acquiring it again. This helps avoid blocking other threads by holding the lock for a long period of time, thus improving concurrency performance.</p><aside>ğŸ’¡<p> Why does the check function call processPendingReplication and then moveBlocksToPending? Canâ€™t it just call one?</p><p> In some cases it is possible to call only one function to process the replication state of a block, but in some cases it may be necessary to call both functions. Letâ€™s see why it is necessary to call both functions in some cases:</p><ol><li><strong><code>processPendingReplication</code></strong>:<ul><li>The main task of this function is to process the blocks that are currently in the â€œpending replicationâ€ state and make sure that they are replicated to the required number of copies. It is usually called periodically by the scheduler to make sure that the blocks in the cluster maintain sufficient redundancy.</li><li>When this function is called, it checks to see which blocks are currently in the pending state and attempts to start replication tasks to replicate those blocks.</li></ul></li><li><strong><code>moveBlocksToPending</code></strong>:<ul><li>The main task of this function is to move blocks to the â€œpending replicationâ€ queue under certain circumstances, e.g., when a node enters maintenance mode or goes offline, to wait for a subsequent replication task.</li><li>When this function is called, it checks if any node is currently in maintenance mode or offline, and then adds the relevant block to the pending replication queue.</li></ul></li></ol><p> Why do we need to call both functions at the same time? Because they donâ€™t deal with exactly the same issues:</p><ul><li><strong><code>processPendingReplication</code></strong> focuses on blocks that are currently pending, while <strong><code>moveBlocksToPending</code></strong> focuses on checking the blocks that need to be processed after a nodeâ€™s state has changed.</li><li>In some cases, new blocks may need to be replicated, or some blocks may need to be moved to the queue waiting to be replicated due to a node state change, so calling both functions simultaneously ensures that the processing of block replication status is comprehensive and timely.</li></ul></aside><ol><li>The checkForCompletedNodes method iterates through the state of the nodes and adds them to the toRemove list if the migration of the blocks is complete.</li><li>The processCompletedNodes method gets the toRemove list, traverses it and sets the status, for example to decommissioned, and removes it from <strong><code>outOfServiceNodeBlocks</code></strong> and <strong><code>pendingRep.</code></strong></li></ol><hr><h1 id="HDFS-Decomission-ä»£ç è§£è¯»ä¸åˆ†æ"><a href="#HDFS-Decomission-ä»£ç è§£è¯»ä¸åˆ†æ" class="headerlink" title="HDFS Decomission ä»£ç è§£è¯»ä¸åˆ†æ"></a>HDFS Decomission ä»£ç è§£è¯»ä¸åˆ†æ</h1><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>ç›®å‰æœ‰200+ 1.22PB HDFS3å’Œ100- 480T HDFSçš„èŠ‚ç‚¹ï¼Œé€€å½¹èŠ‚ç‚¹çš„é€Ÿåº¦è¾ƒæ…¢ï¼Œæ¯å°æ—¶åªèƒ½è¿ç§»150kå·¦å³çš„blocksï¼Œå¹³å‡ä¸€å°èŠ‚ç‚¹æœ‰600kå·¦å³çš„blocksï¼Œä¸€å°éœ€è¦4å°æ—¶å·¦å³ã€‚</p><h2 id="èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ"><a href="#èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ" class="headerlink" title="èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ"></a><strong>èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ</strong></h2><h3 id="èŠ‚ç‚¹é€€å½¹"><a href="#èŠ‚ç‚¹é€€å½¹" class="headerlink" title="èŠ‚ç‚¹é€€å½¹"></a><strong>èŠ‚ç‚¹é€€å½¹</strong></h3><p>é¦–å…ˆæ­£å¸¸å°†èŠ‚ç‚¹åŠ å…¥é€€å½¹åå•ï¼Œå…ˆå‘Šè¯‰namenodeå’Œyarnä¸è¦åœ¨å¾€ä¸Šæäº¤æ–°ä»»åŠ¡å’Œå†™å…¥æ•°æ®äº†ï¼›ç„¶åç­‰å¾…èŠ‚ç‚¹ä¸Šçš„æ•°æ®å—åœ¨é›†ç¾¤ä¸­å¤åˆ¶å®Œæˆï¼›<strong>è¿™ä¸ªæ—¶å€™è¯¥é€€å½¹çš„èŠ‚ç‚¹æ˜¯ä¼˜å…ˆä½œä¸ºsrcNodeæ•°æ®æºçš„ï¼ˆä¼˜å…ˆé€‰æ‹©é€€å½¹ä¸­çš„èŠ‚ç‚¹ä½œä¸ºå¤åˆ¶æ•°æ®æºsrcï¼Œå› ä¸ºå…¶æ— å†™å…¥è¯·æ±‚ï¼Œè´Ÿè½½ä½</strong>ï¼‰ï¼Œå…¶ä»–èŠ‚ç‚¹ä»è¯¥é€€å½¹èŠ‚ç‚¹å¤åˆ¶æ•°æ®å—åˆ°å…¶ä»–èŠ‚ç‚¹çš„ï¼Œæ‰€ä»¥è¿™ä¸ªæ—¶å€™è¯¥èŠ‚ç‚¹çš„è´Ÿè½½ä¼šå¾ˆé«˜ã€‚æ‰€æœ‰æ•°æ®å—å¤åˆ¶å®Œæ¯•ï¼ŒèŠ‚ç‚¹çŠ¶æ€å˜æˆDecommissionedï¼Œå¯ä»¥ä»namenodeURLç•Œé¢æŸ¥çœ‹ã€‚<strong>æ³¨æ„æ•°æ®èŠ‚ç‚¹é€€å½¹æ•°æ®å¼€å§‹å¤åˆ¶çš„æ—¶é—´ä¹Ÿæ˜¯10åˆ†30såï¼Œå¹¶ä¸ä¼šå› ä¸ºæ˜¯ä¸»åŠ¨é€€å½¹è€Œæå‰å¼€å§‹ï¼Œå› ä¸ºnannodeå’Œdatanodeæ°¸è¿œéƒ½æ˜¯ç»´æŒç€ç®€å•çš„ä¸»ä»å…³ç³»ï¼ŒnamenodeèŠ‚ç‚¹ä¸ä¼šä¸»åŠ¨å‘datanodeèŠ‚ç‚¹å‘èµ·ä»»ä½•IPCè°ƒç”¨ï¼ŒdatanodeèŠ‚ç‚¹éœ€è¦é…åˆnamenodeå®Œæˆçš„æ‰€æœ‰æ“ä½œéƒ½æ˜¯é€šè¿‡ä¸¤è€…å¿ƒè·³åº”ç­”æ—¶æºå¸¦çš„DatanodeCommandè¿”å›çš„ã€‚</strong></p><h3 id="èŠ‚ç‚¹æ‰çº¿"><a href="#èŠ‚ç‚¹æ‰çº¿" class="headerlink" title="èŠ‚ç‚¹æ‰çº¿"></a>èŠ‚ç‚¹æ‰çº¿</h3><p>æ¯”å¦‚å¼ºåˆ¶åœæ­¢datanodeï¼Œç‰©ç†æœºæŒ‚äº†ï¼ˆæ¯”å¦‚è´Ÿè½½é«˜æ‰çº¿ï¼Œçªå‘ç½‘ç»œæ•…éšœï¼Œç¡¬ä»¶æ•…éšœç­‰ï¼‰ï¼Œè¿™äº›éƒ½å±äºèŠ‚ç‚¹æ‰çº¿ï¼Œä¸€èˆ¬é»˜è®¤10åˆ†30såï¼ˆä¸»è¦å—ä¸¤ä¸ªå‚æ•°æ§åˆ¶ï¼‰namenodeä¼šæ£€æµ‹åˆ°è¯¥èŠ‚ç‚¹é€šä¿¡å¼‚å¸¸æ‰çº¿ã€‚ç„¶ånamenodeæ ¹æ®è¯¥èŠ‚ç‚¹çš„ipï¼ŒæŸ¥å‡ºè¯¥èŠ‚ç‚¹æ‰€æœ‰çš„blockidï¼Œä»¥åŠå¯¹åº”å‰¯æœ¬æ‰€åœ¨æœºå™¨ï¼Œé€šè¿‡å¿ƒè·³æœºåˆ¶å®‰æ’æ•°æ®å¤åˆ¶ï¼Œè¿™æ—¶å€™æ•°æ®çš„å¤åˆ¶ï¼Œæ•°æ®æºä¸åœ¨æ˜¯æ‰çº¿èŠ‚ç‚¹ï¼Œè€Œæ˜¯å¤šä¸ªå‰¯æœ¬ä¹‹ä¸€æ‰€åœ¨çš„èŠ‚ç‚¹ï¼ŒåŒæ ·è¿™æ—¶å€™å‰¯æœ¬å¤åˆ¶ä¹Ÿéµå¾ªæœºæ¶æ„ŸçŸ¥ï¼Œå‰¯æœ¬æç½®ç­–ç•¥ã€‚</p><aside>ğŸ’¡ èŠ‚ç‚¹æ‰çº¿å’Œé€€å½¹ä¸¤è€…çš„åŒºåˆ«ä¸ä»…æ˜¯æ•°æ®çš„å¤åˆ¶æ–¹å¼ä¸åŒï¼Œè¿˜æœ‰å°±æ˜¯namenodeå¯¹Under-Replicated Blocks çš„æ•°æ®å¤åˆ¶ç­–ç•¥ä¹Ÿæ˜¯ä¸ä¸€æ ·çš„ï¼ˆæ•°æ®å—blockå¤åˆ¶çš„ç­‰çº§åˆ†æˆ5ç§ï¼‰ï¼›æç«¯çš„ä¾‹å­æ¯”å¦‚å•å‰¯æœ¬èŠ‚ç‚¹é€€å½¹æ•°æ®ä¸ä¼šä¸¢å¤±ï¼Œå•å‰¯æœ¬èŠ‚ç‚¹æ‰çº¿åˆ™ä¼šæ•°æ®çœŸçš„ä¸¢å¤±ï¼›</aside><h3 id="èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´"><a href="#èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´" class="headerlink" title="èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´"></a>èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´</h3><p>å‡ åT,ç”šè‡³ä¸Šç™¾T,ä¸Šç™¾ä¸‡blockçš„èŠ‚ç‚¹æ‰çº¿ï¼Œä¼šå‡ºç°å¤§é‡çš„RPCé£æš´ï¼Œå°¤å…¶å¯¹äºå¤§è§„æ¨¡é«˜è´Ÿè½½é›†ç¾¤æ¥è¯´å¯¹namenodeæ˜¯å¾ˆå¤§çš„æŒ‘æˆ˜ï¼Œä¸ä»…å½±å“ç”Ÿäº§æ€§èƒ½ï¼Œä¹Ÿä¼šå­˜åœ¨å¾ˆå¤§çš„éšæ‚£ï¼Œå°¤å…¶æ˜¯å¯¹äºå¸¦å®½æœ‰é™åˆ¶ç“¶é¢ˆçš„é›†ç¾¤ã€‚</p><p>ä¸€èˆ¬æ¥è¯´namenodeæ£€æµ‹datanodeæ˜¯å¦æ‰çº¿çš„å€¼æ˜¯10<em>3sï¼ˆå¿ƒè·³æ—¶é—´ï¼‰+2</em>5minï¼ˆnamenodeæ£€æµ‹æ—¶é—´ï¼Œå‚æ•°æ˜¯ï¼š<code>dfs.namenode.heartbeat.recheck-interval</code>ï¼‰&#x3D;10åˆ†30sã€‚å¦‚æœåœ¨10min30så†…çš„æ—¶é—´å†…å¸¦å®½æŒç»­æ‰“æ»¡ï¼ŒRPCè¯·æ±‚å»¶è¿Ÿï¼Œdatanodeå’ŒnamenodeèŠ‚ç‚¹é€šä¿¡ä¸ç•…ï¼Œå¾ˆå®¹æ˜“é€ æˆå…¶ä»–èŠ‚ç‚¹çš„æŒç»­æ‰çº¿ï¼Œå½¢æˆæ¶æ€§å¾ªç¯ï¼Œè¿™ç§æƒ…å†µåº”è¯¥å¦‚ä½•é¿å…ï¼Ÿ</p><p>NameNode ç»´æŠ¤ä¸€ä¸ªå¤åˆ¶ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œå¯¹äºå‰¯æœ¬ä¸è¶³çš„æ–‡ä»¶ block æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä»…å‰©ä¸‹ä¸€ä¸ªå‰¯æœ¬çš„æ–‡ä»¶ block äº«æœ‰æœ€é«˜çš„å¤åˆ¶ä¼˜å…ˆçº§ã€‚æ‰€ä»¥ä»è¿™é‡Œçœ‹é›†ç¾¤ä¸¤å‰¯æœ¬çš„è¯ï¼Œåªè¦æœ‰ä¸€ä¸ªblockå‡ºç°å¼‚å¸¸ï¼Œå°±åªå‰©ä¸€ä¸ªå‰¯æœ¬ï¼Œå°±æ˜¯æœ€é«˜ä¼˜å…ˆçº§çš„å—å¤åˆ¶ï¼Œä¼šé£æš´æ¨¡å¼å¤åˆ¶ï¼Œæ§åˆ¶ä¸å¥½å¾ˆå®¹æ˜“å½±å“é›†ç¾¤æ€§èƒ½ï¼Œç”šè‡³ææŒ‚é›†ç¾¤ã€‚æ‰€ä»¥ä¸€èˆ¬ä¸å»ºè®®é›†ç¾¤å‰¯æœ¬å› å­æ˜¯2ã€‚</p><aside>ğŸ’¡ L1(æœ€é«˜)ï¼šæœ‰æ•°æ®ä¸¢å¤±é£é™©çš„å—ï¼Œå¦‚ï¼š1.åªæœ‰ä¸€ä¸ªå‰¯æœ¬çš„å—ï¼ˆå°¤å…¶å¯¹äº2å‰¯æœ¬çš„å—ï¼Œä¸‹çº¿ä¸€å°èŠ‚ç‚¹ï¼‰æˆ–è€…è¿™äº›å—æœ‰0ä¸ªactiveå‰¯æœ¬ï¼›2ï¼Œå•å‰¯æœ¬åœ¨æ­£åœ¨é€€å½¹çš„èŠ‚ç‚¹æ‹¥æœ‰çš„å—ã€‚<p>L2:blockå‰¯æœ¬å®é™…å€¼è¿œä½äºé…ç½®çš„å€¼ï¼ˆæ¯”å¦‚3å‰¯æœ¬ï¼Œç¼ºå¤±2ä¸ªï¼‰ï¼Œå³å‰¯æœ¬æ•°ä¸åˆ°æœŸæœ›å€¼1&#x2F;3æ—¶çš„å—ï¼Œè¿™äº›blockä¼šè¢«ç¬¬äºŒä¼˜å…ˆçº§å¤åˆ¶ã€‚æ¯”å¦‚4å‰¯æœ¬çš„block,æœ‰3ä¸ªä¸¢å¤±æˆ–è€…åäº†,å®ƒå°±ä¼šæ¯”4å‰¯æœ¬blockä¸¢å¤±2ä¸ªçš„ä¼˜å…ˆå¤åˆ¶ã€‚</p><p>L3:å‰¯æœ¬ä¸è¶³æ²¡æœ‰ä¼˜å…ˆçº§L2é«˜çš„é‚£äº›å‰¯æœ¬ï¼Œä¼˜å…ˆå¤åˆ¶ã€‚ç¬¬ä¸‰ä¼˜å…ˆçº§ã€‚</p><p>L4:blockæ»¡è¶³è¦æ±‚çš„æœ€å°å‰¯æœ¬æ•°ã€‚å‰¯æœ¬åº¦éœ€æ±‚åº¦æ¯”L2-L3éƒ½ä½ã€‚</p><p>L5:å·²æŸåçš„å—ï¼Œå¹¶ä¸”å½“å‰æœ‰å¯ç”¨çš„éæŸåå‰¯æœ¬</p></aside><h3 id="å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´"><a href="#å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´" class="headerlink" title="å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´"></a>å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´</h3><p>ä¸‰ä¸ªå‚æ•°éƒ½æ˜¯<code>hdfs-site.xml</code>ä¸­å‚æ•°ï¼Œå…·ä½“å¯ä»¥å‚è€ƒapache hadoopå®˜ç½‘ï¼Œå…¶å®å—çš„å¤åˆ¶é€Ÿåº¦æœ‰ä¸¤ä¸ªæ–¹é¢å†³å®šï¼Œä¸€æ˜¯namenodeåˆ†å‘ä»»åŠ¡çš„é€Ÿåº¦ï¼ŒäºŒåˆ™æ˜¯datanodeä¹‹é—´è¿›è¡Œå¤åˆ¶çš„é€Ÿåº¦ã€‚å‰è€…å¯ä»¥ç†è§£æˆå…¥å£ï¼Œåè€…å¯ä»¥å½“æˆå‡ºå£ã€‚</p><blockquote><p>è¿™äº›å‚æ•°åœ¨hadoop2.7.3ä¸­å¹¶æ²¡æœ‰</p></blockquote><h4 id="å…¥å£å‚æ•°"><a href="#å…¥å£å‚æ•°" class="headerlink" title="å…¥å£å‚æ•°"></a>å…¥å£å‚æ•°</h4><p>ä»namenodeå±‚é¢æ§åˆ¶ä»»åŠ¡åˆ†å‘ï¼Œè¿™ä¸ªå‚æ•°ä¿®æ”¹å¿…é¡»<strong>é‡å¯namenode</strong>ï¼Œä¸éœ€è¦é‡å¯datanode.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.work.multiplier.per.iteration <br>è¿™ä¸ªå‚æ•°apache hadoopé»˜è®¤å€¼2ï¼Œcdhé›†ç¾¤é»˜è®¤å€¼10<br></code></pre></td></tr></table></figure><p>è¿™ä¸ªå‚æ•°å†³å®šäº†å½“NNä¸DNè¿›è¡Œå¿ƒè·³ï¼ˆ3sï¼‰å‘é€ä»»åŠ¡åˆ—è¡¨æ—¶ï¼Œå‘Šè¯‰æ¯ä¸ªDNå¯ä»¥è¿›è¡Œå¤åˆ¶çš„blockæ•°é‡ã€‚æ¯”å¦‚é›†ç¾¤æœ‰500ä¸ªèŠ‚ç‚¹ï¼Œè¿™ä¸ªå€¼è®¾ç½®ä¸º10ï¼Œé‚£ä¹ˆä¸€æ¬¡å¿ƒè·³namnodeå¯ä»¥å‘é€datanodeå¤åˆ¶çš„æ•°æ®å—æ•°é‡æ˜¯10*500&#x3D;5000å—ã€‚</p><p>å‡å¦‚ä¸€ä¸ªèŠ‚ç‚¹æ‰çº¿&#x2F;é€€å½¹æœ‰800000å—blockéœ€è¦å¤åˆ¶ï¼Œåˆ™namenodeéœ€è¦å¤šé•¿æ—¶é—´å¯ä»¥å°†å¾…å¤åˆ¶å—çš„ä»»åŠ¡åˆ†å‘å®Œç»™datanodeå‘¢ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">æé™è®¡ç®—çš„ç»“æœï¼š<br>ä»»åŠ¡åˆ†å‘æ—¶é—´=å¾…å¤åˆ¶blockæ€»æ•°/(é›†ç¾¤æ´»è·ƒdn*å‚æ•°å€¼)*å¿ƒè·³æ—¶é—´<br>time=800000/(500*10)=160æ¬¡å¿ƒè·³*3s/æ¯æ¬¡å¿ƒè·³=480s=8åˆ†é’Ÿ<br><br>æ‰€ä»¥èŠ‚ç‚¹è¶Šå¤šï¼Œä¼šåˆ†å‘ä»»åŠ¡è¶Šå¿«,åˆ†å‘é€Ÿåº¦è·ŸèŠ‚ç‚¹æ•°å’Œè¿™ä¸ªå‚æ•°éƒ½æˆæ­£æ¯”<br></code></pre></td></tr></table></figure><h4 id="å‡ºå£å‚æ•°"><a href="#å‡ºå£å‚æ•°" class="headerlink" title="å‡ºå£å‚æ•°"></a>å‡ºå£å‚æ•°</h4><p>ç›¸æ¯”ä¸Šé¢ä»nanodeä»»åŠ¡åˆ†å‘æ§åˆ¶ï¼Œä¸‹é¢ä¸¤ä¸ªä½¿ç”¨datanodeå±‚é¢æ§åˆ¶ï¼Œè¿™ä¸¤ä¸ªå‚æ•°ä¹Ÿéœ€è¦<strong>é‡å¯namenode</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.max-streams<br><br>apache hadoopé»˜è®¤å€¼æ˜¯2ï¼Œcdhé›†ç¾¤é»˜è®¤20ã€‚<br></code></pre></td></tr></table></figure><p>è¿™ä¸ªå‚æ•°å«ä¹‰æ˜¯æ§åˆ¶datanodeèŠ‚ç‚¹è¿›è¡Œæ•°æ®å¤åˆ¶çš„æœ€å¤§çº¿ç¨‹æ•°ï¼Œä»ä¸Šé¢æˆ‘ä»¬çŸ¥é“blockçš„å¤åˆ¶ä¼˜å…ˆçº§åˆ†æˆ5ç§ã€‚è¿™ä¸ªå‚æ•°æ§åˆ¶ä¸åŒ…å«æœ€é«˜ä¼˜å…ˆçº§çš„å—å¤åˆ¶ã€‚æŒ‡é™¤äº†æœ€é«˜ä¼˜å…ˆçº§ä»¥å¤–çš„å¤åˆ¶æµé™åˆ¶ã€‚</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.max-streams-hard-limit<br><br>è¿™ä¸ªå€¼apache hadoopé»˜è®¤å€¼2ï¼Œcdhé›†ç¾¤é»˜è®¤å€¼40<br></code></pre></td></tr></table></figure><p>è¿™ä¸ªå‚æ•°å«ä¹‰æ˜¯æ§åˆ¶datanodeæ‰€æœ‰ä¼˜å…ˆçº§å—å¤åˆ¶çš„æµä¸ªæ•°ï¼ŒåŒ…å«æœ€é«˜ä¼˜å…ˆçº§ï¼›ä¸€èˆ¬ä¸Šé¢å’Œä¸Šé¢ä¸¤ä¸ªå‚æ•°äº’ç›¸çš„é…åˆä½¿ç”¨ã€‚</p><aside>ğŸ’¡ å‰è€…å‚æ•°æ§åˆ¶datanodeæ¥å—ä»»åŠ¡çš„é¢‘ç‡ï¼Œåè€…è¿™ä¸¤ä¸ªå‚æ•°è¿›ä¸€æ­¥é™åˆ¶ DataNode ä¸€æ¬¡å®Œæˆçš„æœ€å¤§å¹¶è¡Œçº¿ç¨‹ç½‘ç»œä¼ è¾“é‡ã€‚å…·ä½“ä¸Šé¢å‚æ•°çš„å€¼è®¾å®šçš„å¤šå°‘ï¼Œå–å†³äºé›†ç¾¤çš„è§„æ¨¡å’Œé›†ç¾¤çš„é…ç½®ï¼Œä¸èƒ½åŒä¸€è€Œè®ºã€‚ä¸€èˆ¬æ¥è¯´ä»å…¥å£æ§åˆ¶æ¯”è¾ƒç®€å•å®¹æ˜“äº›ã€‚æ¯”å¦‚è§„æ¨¡500å°é›†ç¾¤ï¼Œdfs.namenode.replication.work.multiplier.per.iteration=10ï¼Œé‚£ä¹ˆé›†ç¾¤ä¸€æ¬¡å¿ƒè·³åˆ†å‘5000ä¸ªblockçš„é‡ï¼Œå‡å¦‚é›†ç¾¤æ–‡ä»¶å­˜å‚¨å…¨éƒ¨æ‰“æ•£åœ¨500å°èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹åŒæ—¶å¤åˆ¶10ä¸ªblockï¼ˆå®é™…ä¼šå› ä¸ºå‰¯æœ¬æç½®ç­–ç•¥ï¼Œæœºæ¶æ„ŸçŸ¥ç­‰å¹¶ä¸ä¼šæ‰€æœ‰çš„èŠ‚ç‚¹éƒ½å‚ä¸æ•°æ®å¤åˆ¶ï¼‰,æ¯ä¸ªblockå¤§å°128Mb,åˆ™æ¯ä¸ªèŠ‚ç‚¹çš„ç½‘ç»œè´Ÿè½½æ˜¯128*10/3=546Mb/sï¼Œé‚£è¿™æ—¶å€™ä½ å°±è¦çœ‹ä¸‹ç»“åˆå®é™…ä¼šä¸ä¼šæœ‰å¸¦å®½ç“¶é¢ˆï¼Œè¿™ä¹ˆå¤§çš„ç½‘ç»œIOä¼šä¸ä¼šå½±å“æ­£å¸¸ä»»åŠ¡çš„è®¡ç®—ï¼Œå¦‚æœæœ‰çš„è¯ï¼Œè¿™ä¸ªå€¼å°±è¦è°ƒå°ç‚¹ã€‚</aside><h2 id="å¦‚ä½•å¿«é€Ÿä¸‹çº¿"><a href="#å¦‚ä½•å¿«é€Ÿä¸‹çº¿" class="headerlink" title="å¦‚ä½•å¿«é€Ÿä¸‹çº¿"></a>å¦‚ä½•å¿«é€Ÿä¸‹çº¿</h2><p>å¦‚ä½•è®©èŠ‚ç‚¹å¿«é€Ÿä¸‹çº¿çš„æœ¬è´¨å…¶å®å°±æ˜¯æé«˜å‰¯æœ¬çš„å¤åˆ¶é€Ÿåº¦ã€‚ä¸»è¦è¿˜æ˜¯ä¸Šé¢ä¸‰ä¸ªå‚æ•°æ§åˆ¶.ç¬¬ä¸€æ˜¯æ§åˆ¶namenodeä»»åŠ¡åˆ†å‘ï¼Œå…¶æ¬¡æ§åˆ¶datanodeå¤åˆ¶é€Ÿç‡ï¼Œå‰ææ˜¯ä¸å½±å“æ­£å¸¸ç”Ÿäº§ä»»åŠ¡çš„è¿›è¡Œã€‚é›†ç¾¤è§„æ¨¡è¶Šå°ï¼Œä¸‹çº¿çš„è¶Šæ…¢ï¼Œæ¯”å¦‚å› ä¸ºåˆ†å‘çš„æ€»æ•°ä¼šæ…¢å¾ˆå¤šã€‚</p><p>æ¯”å¦‚ä¸€ä¸ª500å°çš„èŠ‚ç‚¹ <code>dfs.namenode.replication.work.multiplier.per.iteration=10</code>ï¼Œä¸€ä¸ª50å°çš„èŠ‚ç‚¹è¿™ä¸ªå€¼è¦è®¾ç½®æˆ100ï¼Œä¸¤è€…namenodeä»»åŠ¡åˆ†å‘çš„é€Ÿåº¦æ‰å¯ä»¥ä¸€è‡´ã€‚å…·ä½“ç»“åˆå®é™…é›†ç¾¤è§„æ¨¡è®¾ç½®ã€‚</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json">&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">10</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams-hard-limit&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">20</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">5</span>&lt;/value&gt;<br>&lt;/property&gt;<br></code></pre></td></tr></table></figure><p>åœ¨æµ‹è¯•é›†ç¾¤ä¸­ï¼Œ15å°HDFSï¼Œå¹³å‡æ¯å°80k blocksï¼Œæ¯å°æ—¶èƒ½è¿ç§»63k blocksï¼Œæ¯”æœ€åˆçš„12kåŠ é€Ÿäº†5å€ã€‚</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json">## cdh é…ç½®<br>dfs.namenode.replication.work.multiplier.per.iteration=<span class="hljs-number">4</span><br>dfs.namenode.replication.max-streams=<span class="hljs-number">20</span>   <br>dfs.namenode.replication.max-streams-hard-limit=<span class="hljs-number">40</span><br></code></pre></td></tr></table></figure><h4 id="å½±å“"><a href="#å½±å“" class="headerlink" title="å½±å“"></a>å½±å“</h4><p>ä¼šæ˜¾è‘—æé«˜CPU Load, CPU IO Wait, Disk IO Waitç­‰èµ„æºä½¿ç”¨ç‡</p><h3 id="æºç åˆ†æ"><a href="#æºç åˆ†æ" class="headerlink" title="æºç åˆ†æ"></a>æºç åˆ†æ</h3><p>å½“<code>dfs.hosts.exclude</code>çš„åœ°å€å†™åˆ°confä¹‹åï¼Œå°±å¯ä»¥refreshNodesæ‹¿åˆ°exclude listå¹¶è¿›è¡Œæ“ä½œ</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Rereads conf to get hosts and exclude list file names.</span><br><span class="hljs-comment"> * Rereads the files to update the hosts and exclude lists.  It</span><br><span class="hljs-comment"> * checks if any of the hosts have changed states:</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">refreshNodes</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Configuration conf)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>  refreshHostsReader(conf);<br>  namesystem.writeLock();<br>  <span class="hljs-keyword">try</span> &#123;<br>    refreshDatanodes();<br>    countSoftwareVersions();<br>  &#125; <span class="hljs-keyword">finally</span> &#123;<br>    namesystem.writeUnlock();<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>é€šè¿‡<code>dfs.exclude</code>è¯»åˆ°nodeåœ°å€ï¼Œç„¶åæ ‡è®°ä¸ºdecommissionï¼Œå¹¶ä½¿ç”¨monitorå»tracking Node</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">public void startDecommission(DatanodeDescriptor node) &#123;<br>  <span class="hljs-keyword">if</span> (!node.isDecommissionInProgress() &amp;&amp; !node.isDecommissioned()) &#123;<br>    // Update DN stats maintained by HeartbeatManager<br>    hbManager.startDecommission(node);<br>    // hbManager.startDecommission will <span class="hljs-built_in">set</span> dead node to decommissioned.<br>    <span class="hljs-keyword">if</span> (node.isDecommissionInProgress()) &#123;<br>      <span class="hljs-keyword">for</span> (DatanodeStorageInfo storage : node.getStorageInfos()) &#123;<br>        LOG.info(<span class="hljs-string">&quot;Starting decommission of &#123;&#125; &#123;&#125; with &#123;&#125; blocks&quot;</span>,<br>            node, storage, storage.numBlocks());<br>      &#125;<br>      node.getLeavingServiceStatus().setStartTime(monotonicNow());<br>// å¼€å§‹ç›‘æ§è¿™ä¸ªnodeï¼Œå¹¶æŠŠnodeåŠ å…¥pendingNodesé‡Œé¢<br>      monitor.startTrackingNode(node);<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    LOG.trace(<span class="hljs-string">&quot;startDecommission: Node &#123;&#125; in &#123;&#125;, nothing to do.&quot;</span>,<br>        node, node.getAdminState());<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>åœ¨decommissionä¹‹å‰ä¼šå…ˆæŠŠé›†ç¾¤çš„statsè¿›è¡Œé¢„å‡ï¼Œæ¯”å¦‚<code>capacityUsed</code>å’Œ<br><code>capacityTotal</code> ç­‰ç­‰</p><p>monitorçš„run()ä¸­ä¼šè°ƒç”¨processPendingNodes()ï¼Œä»<code>pendingNodes</code>ä¸­æ‹¿å‡ºèŠ‚ç‚¹å¹¶è¿›è¡Œdecommission</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Move any pending nodes into outOfServiceNodeBlocks to initiate the</span><br><span class="hljs-comment"> * decommission or maintenance mode process.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * This method must be executed under the namenode write lock to prevent</span><br><span class="hljs-comment"> * the pendingNodes list from being modified externally.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processPendingNodes</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">while</span> (!pendingNodes.isEmpty() &amp;&amp;<br>      (maxConcurrentTrackedNodes == <span class="hljs-number">0</span> ||<br>          outOfServiceNodeBlocks.size() &lt; maxConcurrentTrackedNodes)) &#123;<br>    outOfServiceNodeBlocks.put(pendingNodes.poll(), <span class="hljs-literal">null</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p> å½“æ‹¿åˆ°nodesä¹‹åä¼šè°ƒç”¨check()æ–¹æ³•ï¼Œä¼šè·å–è¿™äº›nodesçš„blockä¿¡æ¯å¹¶å¤„ç†è¿™äº›pendingReplication Blocks</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">check</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">final</span> List&lt;DatanodeDescriptor&gt; toRemove = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>  <span class="hljs-keyword">if</span> (outOfServiceNodeBlocks.size() == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-comment">// No nodes currently being tracked so simply return</span><br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// Check if there are any pending nodes to process, ie those where the</span><br>  <span class="hljs-comment">// storage has not been scanned yet. For all which are pending, scan</span><br>  <span class="hljs-comment">// the storage and load the under-replicated block list into</span><br>  <span class="hljs-comment">// outOfServiceNodeBlocks. As this does not modify any external structures</span><br>  <span class="hljs-comment">// it can be done under the namenode *read* lock, and the lock can be</span><br>  <span class="hljs-comment">// dropped between each storage on each node.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// TODO - This is an expensive call, depending on how many nodes are</span><br>  <span class="hljs-comment">//        to be processed, but it requires only the read lock and it will</span><br>  <span class="hljs-comment">//        be dropped and re-taken frequently. We may want to throttle this</span><br>  <span class="hljs-comment">//        to process only a few nodes per iteration.</span><br>  outOfServiceNodeBlocks.keySet()<br>      .stream()<br>      .filter(n -&gt; outOfServiceNodeBlocks.get(n) == <span class="hljs-literal">null</span>)<br>      .forEach(n -&gt; scanDatanodeStorage(n, <span class="hljs-literal">true</span>));<br><br>  processMaintenanceNodes();<br>  <span class="hljs-comment">// First check the pending replication list and remove any blocks</span><br>  <span class="hljs-comment">// which are now replicated OK. This list is constrained in size so this</span><br>  <span class="hljs-comment">// call should not be overly expensive.</span><br>  processPendingReplication();<br><br>  <span class="hljs-comment">// Now move a limited number of blocks to pending</span><br>  moveBlocksToPending();<br><br>  <span class="hljs-comment">// Check if any nodes have reached zero blocks and also update the stats</span><br>  <span class="hljs-comment">// exposed via JMX for all nodes still being processed.</span><br>  checkForCompletedNodes(toRemove);<br><br>  <span class="hljs-comment">// Finally move the nodes to their final state if they are ready.</span><br>  processCompletedNodes(toRemove);<br>&#125;<br></code></pre></td></tr></table></figure><ol><li>processPendingReplication()æ–¹æ³•ä¸­ä¼šè°ƒç”¨isBlockReplicatedOk()æ–¹æ³•ï¼ˆæ ¸å¿ƒï¼‰ä¼šåˆ¤æ–­blockæ˜¯å¦éœ€è¦reconstructionï¼Œå¹¶æŠŠä¿¡æ¯æ”¾åˆ°<code>blockManager</code>é‡Œçš„<code>*replication queue*</code></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">blockManager.neededReconstruction.add(block,<br>    liveReplicas, num.readOnlyReplicas(),<br>    num.outOfServiceReplicas(),<br>    blockManager.getExpectedRedundancyNum(block));<br></code></pre></td></tr></table></figure><ol><li>moveBlocksToPending()æ–¹æ³•ä¼šåˆ¤æ–­queueçš„é•¿åº¦å’Œpending replicationçš„limitï¼Œç„¶åä¸ºæ¯ä¸€ä¸ªéœ€è¦maintenanceæˆ–è€…decommissionçš„nodeåˆ›å»ºä¸€ä¸ªblockè¿­ä»£å™¨ï¼Œç„¶åæ¯ä¸ªblockéƒ½ä¼šç»§ç»­è°ƒç”¨ä¸Šé¢æåˆ°çš„isBlockReplicatedOk()æ–¹æ³•ï¼Œç›´åˆ°è¾¾åˆ°blockå¤åˆ¶çš„é™åˆ¶å°±åœæ­¢å¹¶é€€å‡ºå¾ªç¯</li></ol><p>moveBlocksToPending()æ–¹æ³•ä¸­æœ‰ä¸€æ®µå…³äºé”çš„ä»£ç å¾ˆæœ‰æ„æ€</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java">Iterator&lt;DatanodeDescriptor&gt; nodeIter =<br>    Iterables.cycle(iterators.keySet()).iterator();<br><span class="hljs-keyword">while</span> (nodeIter.hasNext()) &#123;<br>  <span class="hljs-comment">// Cycle through each node with blocks which still need processed</span><br>  <span class="hljs-type">DatanodeDescriptor</span> <span class="hljs-variable">dn</span> <span class="hljs-operator">=</span> nodeIter.next();<br>  Iterator&lt;BlockInfo&gt; blockIt = iterators.get(dn);<br>  <span class="hljs-keyword">while</span> (blockIt.hasNext()) &#123;<br>    <span class="hljs-comment">// Process the blocks for the node until we find one that needs</span><br>    <span class="hljs-comment">// replication</span><br>    <span class="hljs-keyword">if</span> (blocksProcessed &gt;= blocksPerLock) &#123;<br>      blocksProcessed = <span class="hljs-number">0</span>;<br>      namesystem.writeUnlock();<br>      namesystem.writeLock();<br>    &#125;<br>    blocksProcessed++;<br>    <span class="hljs-keyword">if</span> (nextBlockAddedToPending(blockIt, dn)) &#123;<br>      <span class="hljs-comment">// Exit the inner &quot;block&quot; loop so an iterator for the next datanode</span><br>      <span class="hljs-comment">// is used for the next block.</span><br>      pendingCount++;<br>      <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure><p>å®ƒåœ¨é‡Šæ”¾å†™é”ä¹‹åç«‹åˆ»åˆç”³è¯·å†™é”ï¼Œè¿™æ˜¯å› ä¸º <strong><code>blocksProcessed</code></strong> å˜é‡ç”¨äºè¿½è¸ªå·²å¤„ç†çš„å—æ•°é‡ã€‚å½“å¤„ç†çš„å—æ•°é‡è¾¾åˆ°é¢„å®šçš„é˜ˆå€¼ <strong><code>blocksPerLock</code></strong> æ—¶ï¼Œé€šè¿‡é‡Šæ”¾å½“å‰çš„å†™é”å¹¶å†æ¬¡è·å–å†™é”ï¼Œå¯ä»¥è®©å…¶ä»–ç­‰å¾…å†™é”çš„çº¿ç¨‹æœ‰æœºä¼šæ‰§è¡Œã€‚è¿™æœ‰åŠ©äºé¿å…é•¿æ—¶é—´æŒæœ‰å†™é”è€Œå¯¼è‡´å…¶ä»–çº¿ç¨‹è¢«é˜»å¡çš„æƒ…å†µå‘ç”Ÿï¼Œä»è€Œæé«˜å¹¶å‘æ€§èƒ½ã€‚</p><aside>ğŸ’¡<p>ä¸ºä»€ä¹ˆcheckè¿™ä¸ªå‡½æ•°è¦å…ˆè°ƒç”¨processPendingReplicationç„¶åè°ƒç”¨moveBlocksToPendingï¼Ÿä¸èƒ½åªè°ƒç”¨ä¸€ä¸ªå—ï¼Ÿ</p><p>åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯ä»¥åªè°ƒç”¨ä¸€ä¸ªå‡½æ•°æ¥å¤„ç†å—çš„å¤åˆ¶çŠ¶æ€ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè°ƒç”¨ä¸¤ä¸ªå‡½æ•°å¯èƒ½æ˜¯å¿…è¦çš„ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸ºä»€ä¹ˆåœ¨ä¸€äº›æƒ…å†µä¸‹éœ€è¦è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°ï¼š</p><ol><li><code>processPendingReplication</code>ï¼š<ul><li>è¿™ä¸ªå‡½æ•°çš„ä¸»è¦ä»»åŠ¡æ˜¯å¤„ç†å½“å‰å¤„äºâ€œpending replicationâ€çŠ¶æ€çš„å—ï¼Œç¡®ä¿å®ƒä»¬çš„å¤åˆ¶æ•°é‡è¾¾åˆ°æ‰€éœ€çš„å‰¯æœ¬æ•°ã€‚å®ƒé€šå¸¸æ˜¯å‘¨æœŸæ€§åœ°ç”±è°ƒåº¦ç¨‹åºè°ƒç”¨çš„ï¼Œä»¥ç¡®ä¿é›†ç¾¤ä¸­çš„å—ä¿æŒè¶³å¤Ÿçš„å†—ä½™åº¦ã€‚</li><li>å½“è°ƒç”¨è¿™ä¸ªå‡½æ•°æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥å½“å‰å“ªäº›å—å¤„äºæŒ‚èµ·çŠ¶æ€ï¼Œå¹¶å°è¯•å¯åŠ¨å¤åˆ¶ä»»åŠ¡æ¥å¤åˆ¶è¿™äº›å—ã€‚</li></ul></li><li><code>moveBlocksToPending</code>ï¼š<ul><li>è¿™ä¸ªå‡½æ•°çš„ä¸»è¦ä»»åŠ¡æ˜¯åœ¨ç‰¹å®šçš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚èŠ‚ç‚¹è¿›å…¥ç»´æŠ¤æ¨¡å¼æˆ–è€…ä¸‹çº¿æ—¶ï¼Œå°†ç›¸å…³å—ç§»åŠ¨åˆ°â€œpending replicationâ€çŠ¶æ€çš„é˜Ÿåˆ—ä¸­ï¼Œä»¥ç­‰å¾…åç»­çš„å¤åˆ¶ä»»åŠ¡å¤„ç†ã€‚</li><li>å½“è°ƒç”¨è¿™ä¸ªå‡½æ•°æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥å½“å‰æ˜¯å¦æœ‰èŠ‚ç‚¹å¤„äºç»´æŠ¤æ¨¡å¼æˆ–è€…ä¸‹çº¿ï¼Œç„¶åå°†ç›¸å…³å—æ·»åŠ åˆ°ç­‰å¾…å¤åˆ¶çš„é˜Ÿåˆ—ä¸­ã€‚</li></ul></li></ol><p>ä¸ºä»€ä¹ˆéœ€è¦åŒæ—¶è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°å‘¢ï¼Ÿå› ä¸ºå®ƒä»¬å¤„ç†çš„é—®é¢˜ä¸å®Œå…¨ä¸€æ ·ï¼š</p><ul><li><strong><code>processPendingReplication</code></strong> ä¸»è¦å…³æ³¨å½“å‰æ­£åœ¨æŒ‚èµ·çš„å—ï¼Œè€Œ <strong><code>moveBlocksToPending</code></strong> ä¸»è¦å…³æ³¨äºæ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€å˜åŒ–åéœ€è¦è¿›è¡Œçš„å—å¤„ç†ã€‚</li><li>åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¼šå‡ºç°æ–°çš„å—éœ€è¦å¤åˆ¶ï¼Œæˆ–è€…ç”±äºèŠ‚ç‚¹çŠ¶æ€å˜åŒ–è€Œéœ€è¦ç§»åŠ¨ä¸€äº›å—åˆ°ç­‰å¾…å¤åˆ¶çš„é˜Ÿåˆ—ä¸­ï¼Œæ‰€ä»¥åŒæ—¶è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°å¯ä»¥ç¡®ä¿å¤„ç†å—å¤åˆ¶çŠ¶æ€çš„å…¨é¢æ€§å’ŒåŠæ—¶æ€§ã€‚</li></ul></aside><ol><li>checkForCompletedNodesæ–¹æ³•ä¼šéå†æ£€æŸ¥èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œå¦‚æœblockçš„è¿ç§»ä»»åŠ¡å®Œæˆäº†çš„è¯ï¼Œå°±æŠŠnodeæ·»åŠ åˆ°toRemoveçš„listä¸­</li><li>processCompletedNodesæ–¹æ³•æ‹¿åˆ°toRemoveçš„listï¼Œéå†æ£€æŸ¥ç„¶åè®¾ç½®çŠ¶æ€ï¼Œæ¯”å¦‚æ”¹ä¸ºdecommissionedï¼Œå¹¶ä» <strong><code>outOfServiceNodeBlocks</code></strong> å’Œ <strong><code>pendingRep</code></strong> ä¸­ç§»é™¤</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>CodeDive</tag>
      
      <tag>Hadoop</tag>
      
      <tag>Architecture</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
