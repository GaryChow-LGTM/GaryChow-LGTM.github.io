

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/icons8-ninja-96.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Gary Chow (Yimin Cao)">
  <meta name="keywords" content="">
  
    <meta name="description" content="HDFS Decomission Codes and IntrosBackground of HDFS decomission Currently there are 200+ 1.22PB HDFS3 and 100- 480T HDFS nodes, the decommissioning nodes are slow and can only migrate about 150k block">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS Decomission Codes and Intros">
<meta property="og:url" content="https://garychow-lgtm.github.io/2024/06/17/HDFS-Decomission-Codes-and-Introduction/index.html">
<meta property="og:site_name" content="QQ Zone">
<meta property="og:description" content="HDFS Decomission Codes and IntrosBackground of HDFS decomission Currently there are 200+ 1.22PB HDFS3 and 100- 480T HDFS nodes, the decommissioning nodes are slow and can only migrate about 150k block">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2024-06-17T07:52:23.000Z">
<meta property="article:modified_time" content="2025-08-21T12:56:48.874Z">
<meta property="article:author" content="Gary Chow (Yimin Cao)">
<meta property="article:tag" content="CodeDive">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="Architecture">
<meta name="twitter:card" content="summary_large_image">
  
  
  
  <title>HDFS Decomission Codes and Intros - QQ Zone</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"garychow-lgtm.github.io","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>QQ Zone</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="HDFS Decomission Codes and Intros"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-06-17 15:52" pubdate>
          June 17, 2024 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          4k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          34 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">HDFS Decomission Codes and Intros</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="HDFS-Decomission-Codes-and-Intros"><a href="#HDFS-Decomission-Codes-and-Intros" class="headerlink" title="HDFS Decomission Codes and Intros"></a>HDFS Decomission Codes and Intros</h1><h2 id="Background-of-HDFS-decomission"><a href="#Background-of-HDFS-decomission" class="headerlink" title="Background of HDFS decomission"></a>Background of HDFS decomission</h2><p> Currently there are 200+ 1.22PB HDFS3 and 100- 480T HDFS nodes, the decommissioning nodes are slow and can only migrate about 150k blocks per hour, on average a node has about 600k blocks and one takes about 4 hours.</p>
<h2 id="Difference-between-node-drop-and-node-retirement"><a href="#Difference-between-node-drop-and-node-retirement" class="headerlink" title="Difference between node drop and node retirement?"></a><strong>Difference between node drop and node retirement?</strong></h2><h3 id="Node-Decommissioning"><a href="#Node-Decommissioning" class="headerlink" title="Node Decommissioning"></a><strong>Node Decommissioning</strong></h3><p> First of all, normally add the node to the decommissioning list, first tell namenode and yarn not to submit new tasks and write data up; and then wait for the node on the data block in the cluster replication is complete; <strong>this time the decommissioned node is prioritized as the srcNode data source (preferred to choose the decommissioned node as a replicated data source src, because it has no write requests, low load</strong> ), the other nodes from the <strong>decommissioned</strong> node to <strong>replicate data source src</strong>. Other nodes copy data blocks from this retired node to other nodes, so the load on this node will be high at this time. All data blocks are replicated and the node status becomes Decommissioned, which can be viewed from the namenodeURL interface. <strong>Note that the data node decommissioned data to start replication time is also 10 minutes and 30s later, and will not start earlier because it is actively decommissioned, because the namenode and datanode will always maintain a simple master-slave relationship, the namenode node will not actively initiate any IPC calls to the datanode node, the datanode node needs to cooperate with the All operations completed by the namenode are returned through the DatanodeCommand carried by both heartbeat answers.</strong></p>
<h3 id="Node-Drop"><a href="#Node-Drop" class="headerlink" title="Node Drop"></a>Node Drop</h3><p> For example, forced stop datanode, the physical machine hangs (such as high load drop, sudden network failure, hardware failure, etc.), these are node drop, the general default 10 minutes after 30s (mainly controlled by two parameters) namenode will detect the node communication anomaly drop. Then namenode according to the nodeâ€™s ip, find out all the nodeâ€™s blockid, as well as the corresponding copy of the machine, through the heartbeat mechanism to arrange for data replication, this time the data replication, the data source is not in the node is not down, but one of the multiple copies of the node, the same this time the copy replication also follow the rack-awareness, copy shelving strategy.</p>
<aside>
ğŸ’¡  The difference between node drop and decommissioning of the two is not only the data replication method is different, there is also namenode Under-Replicated Blocks of data replication strategy is not the same (data block block replication level is divided into five kinds); extreme examples such as single-copy node decommissioning data will not be lost, a single-copy node drop data will be really lost;

</aside>

<h3 id="Network-storm-caused-by-node-drop"><a href="#Network-storm-caused-by-node-drop" class="headerlink" title="Network storm caused by node drop"></a>Network storm caused by node drop</h3><p> dozens of T, or even hundreds of T, millions of block node drop, there will be a large number of RPC storms, especially for large-scale high-load clusters on namenode is a big challenge, not only affects the performance of the production, but also there will be a great deal of hidden danger, especially for the bandwidth bottleneck of the limitations of clusters.</p>
<p> Generally speaking the value of namenode to detect whether datanode is dropped is 10<em>3s (heartbeat time) + 2</em>5min (namenode detection time, the parameter is: <code>dfs.namenode.heartbeat.recheck-interval</code> ) &#x3D; 10min30s. if within 10min30s of time bandwidth continues to hit full, RPC requests are delayed, and datanode and namenode nodes are not communicating well, it is easy to cause other nodes to continue to fall offline, forming a vicious cycle, how should this situation be avoided?</p>
<p> NameNode maintains a replication priority queue, for the file block with insufficient replicas, the file block with only one replica left will enjoy the highest replication priority. So if you look at a cluster with two replicas, as long as there is an exception in one block, there will be only one replica left, which is the highest-priority block replica, and it will be storm mode replication, which will easily affect the cluster performance if not well controlled, and even hang the cluster. Therefore, it is generally not recommended that the cluster copy factor is 2.</p>
<aside>
ğŸ’¡  L1 (highest): there is a risk of data loss of the block, such as: 1. Only one copy of the block (especially for 2 copies of the block, down a node) or these blocks have 0 active copy; 2, single copy in the node is being decommissioned to own the block.

<p> L2:Block replicas whose actual value is much lower than the configured value (e.g., 3 replicas, 2 missing), i.e., blocks whose replica count is less than 1&#x2F;3 of the expected value, and these blocks are replicated with second priority. For example, 4 copies of block, there are 3 lost or broken, it will be replicated with priority than 4 copies of block missing 2.</p>
<p> L3:Insufficient copies are not as high as those with priority L2, which are replicated first. Third priority.</p>
<p> L4:block meets the minimum number of copies required. The replica degree requirement is lower than both L2-L3.</p>
<p> L5:Damaged blocks and currently have available non-damaged replicas</p>
</aside>

<h3 id="Parameters-control-RPC-storms-caused-by-node-drops"><a href="#Parameters-control-RPC-storms-caused-by-node-drops" class="headerlink" title="Parameters control RPC storms caused by node drops"></a>Parameters control RPC storms caused by node drops</h3><p> The three parameters are <code>hdfs-site.xml</code> parameters, you can refer to the apache hadoop official website, in fact, there are two aspects of the block replication speed to determine, one is the speed of namenode distribution tasks, the second is the speed of replication between datanode. The former can be understood as the entrance and the latter can be treated as the exit.</p>
<blockquote>
<p>These parameters are not available in hadoop 2.7.3</p>
</blockquote>
<h4 id="Ingress-Parameters"><a href="#Ingress-Parameters" class="headerlink" title="Ingress Parameters"></a>Ingress Parameters</h4><p> Controls the distribution of tasks from the namenode level. Changes to this parameter require <strong>a restart of the namenode</strong>, not the datanode.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.work.multiplier.per.iteration <br>default=2<br></code></pre></td></tr></table></figure>

<p> This parameter determines the number of blocks that each DN is told to replicate when the NN has a heartbeat (3s) with the DN to send the task list. For example, if the cluster has 500 nodes and this value is set to 10, then the number of data blocks that a heartbeat namnode can send datanode to replicate is 10*500&#x3D;5000 blocks.</p>
<p> If a node drops&#x2F;retires and there are 800000 blocks to be replicated, how long does it take for the namenode to finish distributing the task of replicating the blocks to the datanode.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">task</span> <span class="hljs-string">distribution</span> <span class="hljs-string">time</span> <span class="hljs-string">=</span> <br><span class="hljs-string">wait</span> <span class="hljs-string">for</span> <span class="hljs-string">copy</span> <span class="hljs-string">block</span> <span class="hljs-string">number</span> <span class="hljs-string">/</span> <span class="hljs-string">(datanode</span> <span class="hljs-string">number</span> <span class="hljs-string">*</span> <span class="hljs-string">parameters)</span> <span class="hljs-string">*</span> <span class="hljs-string">heartbeat</span> <span class="hljs-string">interval</span> <span class="hljs-string">time</span><br></code></pre></td></tr></table></figure>

<h4 id="Export-Parameters"><a href="#Export-Parameters" class="headerlink" title="Export Parameters"></a>Export Parameters</h4><p> In contrast to the above, which controls task distribution from the nanode, the following two parameters are controlled at the datanode level, and require <strong>a restart of the namenode</strong>.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">dfs.namenode.replication.max-streams</span><br><span class="hljs-string">default=2</span><br></code></pre></td></tr></table></figure>

<p> The meaning of this parameter is to control the datanode node to carry out data replication of the maximum number of threads, from the above we know that the block replication priority is divided into five kinds. This parameter controls the replication of blocks that do not contain the highest priority. This parameter controls the replication of blocks that do not contain the highest priority.</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">dfs.namenode.replication.max-streams-hard-limit</span><br><span class="hljs-string">hadoop</span> <span class="hljs-string">default=2,</span> <span class="hljs-string">cdh</span> <span class="hljs-string">default=40</span><br></code></pre></td></tr></table></figure>

<p> The meaning of this parameter is to control the number of streams copied by all priority blocks of the datanode, including the highest priority; generally used in conjunction with the above and above two parameters each other.</p>
<aside>
ğŸ’¡  The former parameter controls how often the datanode accepts tasks, and the latter two parameters further limit the maximum amount of parallel threaded network transfers that the DataNode can accomplish at one time. How much to set the value of the above parameters depends on the cluster size and cluster configuration, and cannot be determined in the same way. Generally speaking, it is simpler and easier to control from the entrance. For example, the scale of 500 clusters, dfs.namenode.replication.work.multiplier.per.iteration = 10, then the cluster heartbeat distribution of 5000 blocks at a time, if the cluster file storage is broken up in all 500 nodes, each node at the same time replicated 10 blocks (). The actual will be because of the replica shelving policy, rack awareness and so on will not be all the nodes are involved in data replication), each block size 128Mb, then each node's network load is 128 * 10/3 = 546Mb / s, then you have to look at the combination of the actual bandwidth bottlenecks, such a large network IO will affect the normal task of the computation, if so, the value of this If there is, the value should be adjusted down a bit.

</aside>

<h2 id="How-to-go-offline-quickly"><a href="#How-to-go-offline-quickly" class="headerlink" title="How to go offline quickly"></a>How to go offline quickly</h2><p> The essence of how to make nodes go offline quickly is to improve the replication speed of the replica. It is mainly controlled by the above three parameters. The first is to control namenode task distribution, and the second control datanode replication rate, provided that it does not affect the normal production tasks. The smaller the cluster size, the slower the downline, for example, because the total number of distribution will be much slower.</p>
<p> For example, a 500-unit node <code>dfs.namenode.replication.work.multiplier.per.iteration=10</code>, a 50-unit node this value should be set to 100, both namenode task distribution speed can be consistent. Specifically combined with the actual cluster size settings.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json">&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">10</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams-hard-limit&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">20</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">5</span>&lt;/value&gt;<br>&lt;/property&gt;<br></code></pre></td></tr></table></figure>

<p> In the test cluster, 15 HDFS, an average of 80k blocks per unit, can migrate 63k blocks per hour, than the initial 12k accelerated by 5 times.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json"># cdh é…ç½®<br>dfs.namenode.replication.work.multiplier.per.iteration=<span class="hljs-number">4</span><br>dfs.namenode.replication.max-streams=<span class="hljs-number">20</span>   <br>dfs.namenode.replication.max-streams-hard-limit=<span class="hljs-number">40</span><br></code></pre></td></tr></table></figure>

<h4 id="Impact"><a href="#Impact" class="headerlink" title="Impact"></a>Impact</h4><p> Significantly increase CPU Load, CPU IO Wait, Disk IO Wait and other resource utilization.</p>
<h3 id="Source-Code-Analysis"><a href="#Source-Code-Analysis" class="headerlink" title="Source Code Analysis"></a>Source Code Analysis</h3><p> Once the address of <code>dfs.hosts.exclude</code> is written to conf, refreshNodes can get the exclude list and operate on it.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Rereads conf to get hosts and exclude list file names.</span><br><span class="hljs-comment"> * Rereads the files to update the hosts and exclude lists.  It</span><br><span class="hljs-comment"> * checks if any of the hosts have changed states:</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">refreshNodes</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Configuration conf)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>  refreshHostsReader(conf);<br>  namesystem.writeLock();<br>  <span class="hljs-keyword">try</span> &#123;<br>    refreshDatanodes();<br>    countSoftwareVersions();<br>  &#125; <span class="hljs-keyword">finally</span> &#123;<br>    namesystem.writeUnlock();<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p> Read the address of the node through <code>dfs.exclude</code>, then mark it as decommissioned and use monitor to tracking Node.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">public void startDecommission(DatanodeDescriptor node) &#123;<br>  <span class="hljs-keyword">if</span> (!node.isDecommissionInProgress() &amp;&amp; !node.isDecommissioned()) &#123;<br>    // Update DN stats maintained by HeartbeatManager<br>    hbManager.startDecommission(node);<br>    // hbManager.startDecommission will <span class="hljs-built_in">set</span> dead node to decommissioned.<br>    <span class="hljs-keyword">if</span> (node.isDecommissionInProgress()) &#123;<br>      <span class="hljs-keyword">for</span> (DatanodeStorageInfo storage : node.getStorageInfos()) &#123;<br>        LOG.info(<span class="hljs-string">&quot;Starting decommission of &#123;&#125; &#123;&#125; with &#123;&#125; blocks&quot;</span>,<br>            node, storage, storage.numBlocks());<br>      &#125;<br>      node.getLeavingServiceStatus().setStartTime(monotonicNow());<br>      monitor.startTrackingNode(node);<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    LOG.trace(<span class="hljs-string">&quot;startDecommission: Node &#123;&#125; in &#123;&#125;, nothing to do.&quot;</span>,<br>        node, node.getAdminState());<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p> Before decommissioning, the cluster stats will be pre-decimated, such as <code>capacityUsed</code>, <code>capacityTotal</code>, and so on.</p>
<p> monitorâ€™s run() will call processPendingNodes() to take out nodes from the <code>pending nodes</code> and decommission them.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Move any pending nodes into outOfServiceNodeBlocks to initiate the</span><br><span class="hljs-comment"> * decommission or maintenance mode process.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * This method must be executed under the namenode write lock to prevent</span><br><span class="hljs-comment"> * the pendingNodes list from being modified externally.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processPendingNodes</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">while</span> (!pendingNodes.isEmpty() &amp;&amp;<br>      (maxConcurrentTrackedNodes == <span class="hljs-number">0</span> ||<br>          outOfServiceNodeBlocks.size() &lt; maxConcurrentTrackedNodes)) &#123;<br>    outOfServiceNodeBlocks.put(pendingNodes.poll(), <span class="hljs-literal">null</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p> After getting the nodes, it will call the check() method, which will get the block information of these nodes and process the PendingReplication Blocks.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">check</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">final</span> List&lt;DatanodeDescriptor&gt; toRemove = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>  <span class="hljs-keyword">if</span> (outOfServiceNodeBlocks.size() == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-comment">// No nodes currently being tracked so simply return</span><br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// Check if there are any pending nodes to process, ie those where the</span><br>  <span class="hljs-comment">// storage has not been scanned yet. For all which are pending, scan</span><br>  <span class="hljs-comment">// the storage and load the under-replicated block list into</span><br>  <span class="hljs-comment">// outOfServiceNodeBlocks. As this does not modify any external structures</span><br>  <span class="hljs-comment">// it can be done under the namenode *read* lock, and the lock can be</span><br>  <span class="hljs-comment">// dropped between each storage on each node.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// TODO - This is an expensive call, depending on how many nodes are</span><br>  <span class="hljs-comment">//        to be processed, but it requires only the read lock and it will</span><br>  <span class="hljs-comment">//        be dropped and re-taken frequently. We may want to throttle this</span><br>  <span class="hljs-comment">//        to process only a few nodes per iteration.</span><br>  outOfServiceNodeBlocks.keySet()<br>      .stream()<br>      .filter(n -&gt; outOfServiceNodeBlocks.get(n) == <span class="hljs-literal">null</span>)<br>      .forEach(n -&gt; scanDatanodeStorage(n, <span class="hljs-literal">true</span>));<br><br>  processMaintenanceNodes();<br>  <span class="hljs-comment">// First check the pending replication list and remove any blocks</span><br>  <span class="hljs-comment">// which are now replicated OK. This list is constrained in size so this</span><br>  <span class="hljs-comment">// call should not be overly expensive.</span><br>  processPendingReplication();<br><br>  <span class="hljs-comment">// Now move a limited number of blocks to pending</span><br>  moveBlocksToPending();<br><br>  <span class="hljs-comment">// Check if any nodes have reached zero blocks and also update the stats</span><br>  <span class="hljs-comment">// exposed via JMX for all nodes still being processed.</span><br>  checkForCompletedNodes(toRemove);<br><br>  <span class="hljs-comment">// Finally move the nodes to their final state if they are ready.</span><br>  processCompletedNodes(toRemove);<br>&#125;<br></code></pre></td></tr></table></figure>

<ol>
<li>processPendingReplication() method will call isBlockReplicatedOk() method (the core) will determine whether the block needs reconstruction, and put the information into the <code>*replication queue*</code> in the <code>blockManager</code>.</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">blockManager.neededReconstruction.add(block,<br>    liveReplicas, num.readOnlyReplicas(),<br>    num.outOfServiceReplicas(),<br>    blockManager.getExpectedRedundancyNum(block));<br></code></pre></td></tr></table></figure>

<ol start="2">
<li>The moveBlocksToPending() method determines the length of the queue and the limit of the pending replication, and then creates a block iterator for each node that needs maintenance or delegation, and then each block will continue to call the above mentioned isBlockReplicatedOk() method until the block replication limit is reached, then stop and exit the loop.</li>
</ol>
<p> The moveBlocksToPending() method has an interesting piece of locking code.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java">Iterator&lt;DatanodeDescriptor&gt; nodeIter =<br>    Iterables.cycle(iterators.keySet()).iterator();<br><span class="hljs-keyword">while</span> (nodeIter.hasNext()) &#123;<br>  <span class="hljs-comment">// Cycle through each node with blocks which still need processed</span><br>  <span class="hljs-type">DatanodeDescriptor</span> <span class="hljs-variable">dn</span> <span class="hljs-operator">=</span> nodeIter.next();<br>  Iterator&lt;BlockInfo&gt; blockIt = iterators.get(dn);<br>  <span class="hljs-keyword">while</span> (blockIt.hasNext()) &#123;<br>    <span class="hljs-comment">// Process the blocks for the node until we find one that needs</span><br>    <span class="hljs-comment">// replication</span><br>    <span class="hljs-keyword">if</span> (blocksProcessed &gt;= blocksPerLock) &#123;<br>      blocksProcessed = <span class="hljs-number">0</span>;<br>      namesystem.writeUnlock();<br>      namesystem.writeLock();<br>    &#125;<br>    blocksProcessed++;<br>    <span class="hljs-keyword">if</span> (nextBlockAddedToPending(blockIt, dn)) &#123;<br>      <span class="hljs-comment">// Exit the inner &quot;block&quot; loop so an iterator for the next datanode</span><br>      <span class="hljs-comment">// is used for the next block.</span><br>      pendingCount++;<br>      <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure>

<p> It releases the write lock and then immediately requests a write lock because the <strong><code>blocksProcessed</code></strong> variable is used to keep track of the number of blocks that have been processed. When the number of blocks processed reaches a predetermined threshold of <strong><code>blocksPerLock</code></strong>, it gives other threads waiting for a write lock a chance to execute by releasing the current write lock and acquiring it again. This helps avoid blocking other threads by holding the lock for a long period of time, thus improving concurrency performance.</p>
<aside>
ğŸ’¡

<p> Why does the check function call processPendingReplication and then moveBlocksToPending? Canâ€™t it just call one?</p>
<p> In some cases it is possible to call only one function to process the replication state of a block, but in some cases it may be necessary to call both functions. Letâ€™s see why it is necessary to call both functions in some cases:</p>
<ol>
<li><strong><code>processPendingReplication</code></strong>:<ul>
<li>The main task of this function is to process the blocks that are currently in the â€œpending replicationâ€ state and make sure that they are replicated to the required number of copies. It is usually called periodically by the scheduler to make sure that the blocks in the cluster maintain sufficient redundancy.</li>
<li>When this function is called, it checks to see which blocks are currently in the pending state and attempts to start replication tasks to replicate those blocks.</li>
</ul>
</li>
<li><strong><code>moveBlocksToPending</code></strong>:<ul>
<li>The main task of this function is to move blocks to the â€œpending replicationâ€ queue under certain circumstances, e.g., when a node enters maintenance mode or goes offline, to wait for a subsequent replication task.</li>
<li>When this function is called, it checks if any node is currently in maintenance mode or offline, and then adds the relevant block to the pending replication queue.</li>
</ul>
</li>
</ol>
<p> Why do we need to call both functions at the same time? Because they donâ€™t deal with exactly the same issues:</p>
<ul>
<li><strong><code>processPendingReplication</code></strong> focuses on blocks that are currently pending, while <strong><code>moveBlocksToPending</code></strong> focuses on checking the blocks that need to be processed after a nodeâ€™s state has changed.</li>
<li>In some cases, new blocks may need to be replicated, or some blocks may need to be moved to the queue waiting to be replicated due to a node state change, so calling both functions simultaneously ensures that the processing of block replication status is comprehensive and timely.</li>
</ul>
</aside>

<ol>
<li>The checkForCompletedNodes method iterates through the state of the nodes and adds them to the toRemove list if the migration of the blocks is complete.</li>
<li>The processCompletedNodes method gets the toRemove list, traverses it and sets the status, for example to decommissioned, and removes it from <strong><code>outOfServiceNodeBlocks</code></strong> and <strong><code>pendingRep.</code></strong></li>
</ol>
<hr>
<h1 id="HDFS-Decomission-ä»£ç è§£è¯»ä¸åˆ†æ"><a href="#HDFS-Decomission-ä»£ç è§£è¯»ä¸åˆ†æ" class="headerlink" title="HDFS Decomission ä»£ç è§£è¯»ä¸åˆ†æ"></a>HDFS Decomission ä»£ç è§£è¯»ä¸åˆ†æ</h1><h2 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h2><p>ç›®å‰æœ‰200+ 1.22PB HDFS3å’Œ100- 480T HDFSçš„èŠ‚ç‚¹ï¼Œé€€å½¹èŠ‚ç‚¹çš„é€Ÿåº¦è¾ƒæ…¢ï¼Œæ¯å°æ—¶åªèƒ½è¿ç§»150kå·¦å³çš„blocksï¼Œå¹³å‡ä¸€å°èŠ‚ç‚¹æœ‰600kå·¦å³çš„blocksï¼Œä¸€å°éœ€è¦4å°æ—¶å·¦å³ã€‚</p>
<h2 id="èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ"><a href="#èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ" class="headerlink" title="èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ"></a><strong>èŠ‚ç‚¹æ‰çº¿å’ŒèŠ‚ç‚¹é€€å½¹çš„åŒºåˆ«ï¼Ÿ</strong></h2><h3 id="èŠ‚ç‚¹é€€å½¹"><a href="#èŠ‚ç‚¹é€€å½¹" class="headerlink" title="èŠ‚ç‚¹é€€å½¹"></a><strong>èŠ‚ç‚¹é€€å½¹</strong></h3><p>é¦–å…ˆæ­£å¸¸å°†èŠ‚ç‚¹åŠ å…¥é€€å½¹åå•ï¼Œå…ˆå‘Šè¯‰namenodeå’Œyarnä¸è¦åœ¨å¾€ä¸Šæäº¤æ–°ä»»åŠ¡å’Œå†™å…¥æ•°æ®äº†ï¼›ç„¶åç­‰å¾…èŠ‚ç‚¹ä¸Šçš„æ•°æ®å—åœ¨é›†ç¾¤ä¸­å¤åˆ¶å®Œæˆï¼›<strong>è¿™ä¸ªæ—¶å€™è¯¥é€€å½¹çš„èŠ‚ç‚¹æ˜¯ä¼˜å…ˆä½œä¸ºsrcNodeæ•°æ®æºçš„ï¼ˆä¼˜å…ˆé€‰æ‹©é€€å½¹ä¸­çš„èŠ‚ç‚¹ä½œä¸ºå¤åˆ¶æ•°æ®æºsrcï¼Œå› ä¸ºå…¶æ— å†™å…¥è¯·æ±‚ï¼Œè´Ÿè½½ä½</strong>ï¼‰ï¼Œå…¶ä»–èŠ‚ç‚¹ä»è¯¥é€€å½¹èŠ‚ç‚¹å¤åˆ¶æ•°æ®å—åˆ°å…¶ä»–èŠ‚ç‚¹çš„ï¼Œæ‰€ä»¥è¿™ä¸ªæ—¶å€™è¯¥èŠ‚ç‚¹çš„è´Ÿè½½ä¼šå¾ˆé«˜ã€‚æ‰€æœ‰æ•°æ®å—å¤åˆ¶å®Œæ¯•ï¼ŒèŠ‚ç‚¹çŠ¶æ€å˜æˆDecommissionedï¼Œå¯ä»¥ä»namenodeURLç•Œé¢æŸ¥çœ‹ã€‚<strong>æ³¨æ„æ•°æ®èŠ‚ç‚¹é€€å½¹æ•°æ®å¼€å§‹å¤åˆ¶çš„æ—¶é—´ä¹Ÿæ˜¯10åˆ†30såï¼Œå¹¶ä¸ä¼šå› ä¸ºæ˜¯ä¸»åŠ¨é€€å½¹è€Œæå‰å¼€å§‹ï¼Œå› ä¸ºnannodeå’Œdatanodeæ°¸è¿œéƒ½æ˜¯ç»´æŒç€ç®€å•çš„ä¸»ä»å…³ç³»ï¼ŒnamenodeèŠ‚ç‚¹ä¸ä¼šä¸»åŠ¨å‘datanodeèŠ‚ç‚¹å‘èµ·ä»»ä½•IPCè°ƒç”¨ï¼ŒdatanodeèŠ‚ç‚¹éœ€è¦é…åˆnamenodeå®Œæˆçš„æ‰€æœ‰æ“ä½œéƒ½æ˜¯é€šè¿‡ä¸¤è€…å¿ƒè·³åº”ç­”æ—¶æºå¸¦çš„DatanodeCommandè¿”å›çš„ã€‚</strong></p>
<h3 id="èŠ‚ç‚¹æ‰çº¿"><a href="#èŠ‚ç‚¹æ‰çº¿" class="headerlink" title="èŠ‚ç‚¹æ‰çº¿"></a>èŠ‚ç‚¹æ‰çº¿</h3><p>æ¯”å¦‚å¼ºåˆ¶åœæ­¢datanodeï¼Œç‰©ç†æœºæŒ‚äº†ï¼ˆæ¯”å¦‚è´Ÿè½½é«˜æ‰çº¿ï¼Œçªå‘ç½‘ç»œæ•…éšœï¼Œç¡¬ä»¶æ•…éšœç­‰ï¼‰ï¼Œè¿™äº›éƒ½å±äºèŠ‚ç‚¹æ‰çº¿ï¼Œä¸€èˆ¬é»˜è®¤10åˆ†30såï¼ˆä¸»è¦å—ä¸¤ä¸ªå‚æ•°æ§åˆ¶ï¼‰namenodeä¼šæ£€æµ‹åˆ°è¯¥èŠ‚ç‚¹é€šä¿¡å¼‚å¸¸æ‰çº¿ã€‚ç„¶ånamenodeæ ¹æ®è¯¥èŠ‚ç‚¹çš„ipï¼ŒæŸ¥å‡ºè¯¥èŠ‚ç‚¹æ‰€æœ‰çš„blockidï¼Œä»¥åŠå¯¹åº”å‰¯æœ¬æ‰€åœ¨æœºå™¨ï¼Œé€šè¿‡å¿ƒè·³æœºåˆ¶å®‰æ’æ•°æ®å¤åˆ¶ï¼Œè¿™æ—¶å€™æ•°æ®çš„å¤åˆ¶ï¼Œæ•°æ®æºä¸åœ¨æ˜¯æ‰çº¿èŠ‚ç‚¹ï¼Œè€Œæ˜¯å¤šä¸ªå‰¯æœ¬ä¹‹ä¸€æ‰€åœ¨çš„èŠ‚ç‚¹ï¼ŒåŒæ ·è¿™æ—¶å€™å‰¯æœ¬å¤åˆ¶ä¹Ÿéµå¾ªæœºæ¶æ„ŸçŸ¥ï¼Œå‰¯æœ¬æç½®ç­–ç•¥ã€‚</p>
<aside>
ğŸ’¡ èŠ‚ç‚¹æ‰çº¿å’Œé€€å½¹ä¸¤è€…çš„åŒºåˆ«ä¸ä»…æ˜¯æ•°æ®çš„å¤åˆ¶æ–¹å¼ä¸åŒï¼Œè¿˜æœ‰å°±æ˜¯namenodeå¯¹Under-Replicated Blocks çš„æ•°æ®å¤åˆ¶ç­–ç•¥ä¹Ÿæ˜¯ä¸ä¸€æ ·çš„ï¼ˆæ•°æ®å—blockå¤åˆ¶çš„ç­‰çº§åˆ†æˆ5ç§ï¼‰ï¼›æç«¯çš„ä¾‹å­æ¯”å¦‚å•å‰¯æœ¬èŠ‚ç‚¹é€€å½¹æ•°æ®ä¸ä¼šä¸¢å¤±ï¼Œå•å‰¯æœ¬èŠ‚ç‚¹æ‰çº¿åˆ™ä¼šæ•°æ®çœŸçš„ä¸¢å¤±ï¼›

</aside>

<h3 id="èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´"><a href="#èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´" class="headerlink" title="èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´"></a>èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„ç½‘ç»œé£æš´</h3><p>å‡ åT,ç”šè‡³ä¸Šç™¾T,ä¸Šç™¾ä¸‡blockçš„èŠ‚ç‚¹æ‰çº¿ï¼Œä¼šå‡ºç°å¤§é‡çš„RPCé£æš´ï¼Œå°¤å…¶å¯¹äºå¤§è§„æ¨¡é«˜è´Ÿè½½é›†ç¾¤æ¥è¯´å¯¹namenodeæ˜¯å¾ˆå¤§çš„æŒ‘æˆ˜ï¼Œä¸ä»…å½±å“ç”Ÿäº§æ€§èƒ½ï¼Œä¹Ÿä¼šå­˜åœ¨å¾ˆå¤§çš„éšæ‚£ï¼Œå°¤å…¶æ˜¯å¯¹äºå¸¦å®½æœ‰é™åˆ¶ç“¶é¢ˆçš„é›†ç¾¤ã€‚</p>
<p>ä¸€èˆ¬æ¥è¯´namenodeæ£€æµ‹datanodeæ˜¯å¦æ‰çº¿çš„å€¼æ˜¯10<em>3sï¼ˆå¿ƒè·³æ—¶é—´ï¼‰+2</em>5minï¼ˆnamenodeæ£€æµ‹æ—¶é—´ï¼Œå‚æ•°æ˜¯ï¼š<code>dfs.namenode.heartbeat.recheck-interval</code>ï¼‰&#x3D;10åˆ†30sã€‚å¦‚æœåœ¨10min30så†…çš„æ—¶é—´å†…å¸¦å®½æŒç»­æ‰“æ»¡ï¼ŒRPCè¯·æ±‚å»¶è¿Ÿï¼Œdatanodeå’ŒnamenodeèŠ‚ç‚¹é€šä¿¡ä¸ç•…ï¼Œå¾ˆå®¹æ˜“é€ æˆå…¶ä»–èŠ‚ç‚¹çš„æŒç»­æ‰çº¿ï¼Œå½¢æˆæ¶æ€§å¾ªç¯ï¼Œè¿™ç§æƒ…å†µåº”è¯¥å¦‚ä½•é¿å…ï¼Ÿ</p>
<p>NameNode ç»´æŠ¤ä¸€ä¸ªå¤åˆ¶ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œå¯¹äºå‰¯æœ¬ä¸è¶³çš„æ–‡ä»¶ block æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä»…å‰©ä¸‹ä¸€ä¸ªå‰¯æœ¬çš„æ–‡ä»¶ block äº«æœ‰æœ€é«˜çš„å¤åˆ¶ä¼˜å…ˆçº§ã€‚æ‰€ä»¥ä»è¿™é‡Œçœ‹é›†ç¾¤ä¸¤å‰¯æœ¬çš„è¯ï¼Œåªè¦æœ‰ä¸€ä¸ªblockå‡ºç°å¼‚å¸¸ï¼Œå°±åªå‰©ä¸€ä¸ªå‰¯æœ¬ï¼Œå°±æ˜¯æœ€é«˜ä¼˜å…ˆçº§çš„å—å¤åˆ¶ï¼Œä¼šé£æš´æ¨¡å¼å¤åˆ¶ï¼Œæ§åˆ¶ä¸å¥½å¾ˆå®¹æ˜“å½±å“é›†ç¾¤æ€§èƒ½ï¼Œç”šè‡³ææŒ‚é›†ç¾¤ã€‚æ‰€ä»¥ä¸€èˆ¬ä¸å»ºè®®é›†ç¾¤å‰¯æœ¬å› å­æ˜¯2ã€‚</p>
<aside>
ğŸ’¡ L1(æœ€é«˜)ï¼šæœ‰æ•°æ®ä¸¢å¤±é£é™©çš„å—ï¼Œå¦‚ï¼š1.åªæœ‰ä¸€ä¸ªå‰¯æœ¬çš„å—ï¼ˆå°¤å…¶å¯¹äº2å‰¯æœ¬çš„å—ï¼Œä¸‹çº¿ä¸€å°èŠ‚ç‚¹ï¼‰æˆ–è€…è¿™äº›å—æœ‰0ä¸ªactiveå‰¯æœ¬ï¼›2ï¼Œå•å‰¯æœ¬åœ¨æ­£åœ¨é€€å½¹çš„èŠ‚ç‚¹æ‹¥æœ‰çš„å—ã€‚

<p>L2:blockå‰¯æœ¬å®é™…å€¼è¿œä½äºé…ç½®çš„å€¼ï¼ˆæ¯”å¦‚3å‰¯æœ¬ï¼Œç¼ºå¤±2ä¸ªï¼‰ï¼Œå³å‰¯æœ¬æ•°ä¸åˆ°æœŸæœ›å€¼1&#x2F;3æ—¶çš„å—ï¼Œè¿™äº›blockä¼šè¢«ç¬¬äºŒä¼˜å…ˆçº§å¤åˆ¶ã€‚æ¯”å¦‚4å‰¯æœ¬çš„block,æœ‰3ä¸ªä¸¢å¤±æˆ–è€…åäº†,å®ƒå°±ä¼šæ¯”4å‰¯æœ¬blockä¸¢å¤±2ä¸ªçš„ä¼˜å…ˆå¤åˆ¶ã€‚</p>
<p>L3:å‰¯æœ¬ä¸è¶³æ²¡æœ‰ä¼˜å…ˆçº§L2é«˜çš„é‚£äº›å‰¯æœ¬ï¼Œä¼˜å…ˆå¤åˆ¶ã€‚ç¬¬ä¸‰ä¼˜å…ˆçº§ã€‚</p>
<p>L4:blockæ»¡è¶³è¦æ±‚çš„æœ€å°å‰¯æœ¬æ•°ã€‚å‰¯æœ¬åº¦éœ€æ±‚åº¦æ¯”L2-L3éƒ½ä½ã€‚</p>
<p>L5:å·²æŸåçš„å—ï¼Œå¹¶ä¸”å½“å‰æœ‰å¯ç”¨çš„éæŸåå‰¯æœ¬</p>
</aside>

<h3 id="å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´"><a href="#å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´" class="headerlink" title="å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´"></a>å‚æ•°æ§åˆ¶èŠ‚ç‚¹æ‰çº¿å¯¼è‡´çš„RPCé£æš´</h3><p>ä¸‰ä¸ªå‚æ•°éƒ½æ˜¯<code>hdfs-site.xml</code>ä¸­å‚æ•°ï¼Œå…·ä½“å¯ä»¥å‚è€ƒapache hadoopå®˜ç½‘ï¼Œå…¶å®å—çš„å¤åˆ¶é€Ÿåº¦æœ‰ä¸¤ä¸ªæ–¹é¢å†³å®šï¼Œä¸€æ˜¯namenodeåˆ†å‘ä»»åŠ¡çš„é€Ÿåº¦ï¼ŒäºŒåˆ™æ˜¯datanodeä¹‹é—´è¿›è¡Œå¤åˆ¶çš„é€Ÿåº¦ã€‚å‰è€…å¯ä»¥ç†è§£æˆå…¥å£ï¼Œåè€…å¯ä»¥å½“æˆå‡ºå£ã€‚</p>
<blockquote>
<p>è¿™äº›å‚æ•°åœ¨hadoop2.7.3ä¸­å¹¶æ²¡æœ‰</p>
</blockquote>
<h4 id="å…¥å£å‚æ•°"><a href="#å…¥å£å‚æ•°" class="headerlink" title="å…¥å£å‚æ•°"></a>å…¥å£å‚æ•°</h4><p>ä»namenodeå±‚é¢æ§åˆ¶ä»»åŠ¡åˆ†å‘ï¼Œè¿™ä¸ªå‚æ•°ä¿®æ”¹å¿…é¡»<strong>é‡å¯namenode</strong>ï¼Œä¸éœ€è¦é‡å¯datanode.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.work.multiplier.per.iteration <br>è¿™ä¸ªå‚æ•°apache hadoopé»˜è®¤å€¼2ï¼Œcdhé›†ç¾¤é»˜è®¤å€¼10<br></code></pre></td></tr></table></figure>

<p>è¿™ä¸ªå‚æ•°å†³å®šäº†å½“NNä¸DNè¿›è¡Œå¿ƒè·³ï¼ˆ3sï¼‰å‘é€ä»»åŠ¡åˆ—è¡¨æ—¶ï¼Œå‘Šè¯‰æ¯ä¸ªDNå¯ä»¥è¿›è¡Œå¤åˆ¶çš„blockæ•°é‡ã€‚æ¯”å¦‚é›†ç¾¤æœ‰500ä¸ªèŠ‚ç‚¹ï¼Œè¿™ä¸ªå€¼è®¾ç½®ä¸º10ï¼Œé‚£ä¹ˆä¸€æ¬¡å¿ƒè·³namnodeå¯ä»¥å‘é€datanodeå¤åˆ¶çš„æ•°æ®å—æ•°é‡æ˜¯10*500&#x3D;5000å—ã€‚</p>
<p>å‡å¦‚ä¸€ä¸ªèŠ‚ç‚¹æ‰çº¿&#x2F;é€€å½¹æœ‰800000å—blockéœ€è¦å¤åˆ¶ï¼Œåˆ™namenodeéœ€è¦å¤šé•¿æ—¶é—´å¯ä»¥å°†å¾…å¤åˆ¶å—çš„ä»»åŠ¡åˆ†å‘å®Œç»™datanodeå‘¢ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">æé™è®¡ç®—çš„ç»“æœï¼š<br>ä»»åŠ¡åˆ†å‘æ—¶é—´=å¾…å¤åˆ¶blockæ€»æ•°/(é›†ç¾¤æ´»è·ƒdn*å‚æ•°å€¼)*å¿ƒè·³æ—¶é—´<br>time=800000/(500*10)=160æ¬¡å¿ƒè·³*3s/æ¯æ¬¡å¿ƒè·³=480s=8åˆ†é’Ÿ<br><br>æ‰€ä»¥èŠ‚ç‚¹è¶Šå¤šï¼Œä¼šåˆ†å‘ä»»åŠ¡è¶Šå¿«,åˆ†å‘é€Ÿåº¦è·ŸèŠ‚ç‚¹æ•°å’Œè¿™ä¸ªå‚æ•°éƒ½æˆæ­£æ¯”<br></code></pre></td></tr></table></figure>

<h4 id="å‡ºå£å‚æ•°"><a href="#å‡ºå£å‚æ•°" class="headerlink" title="å‡ºå£å‚æ•°"></a>å‡ºå£å‚æ•°</h4><p>ç›¸æ¯”ä¸Šé¢ä»nanodeä»»åŠ¡åˆ†å‘æ§åˆ¶ï¼Œä¸‹é¢ä¸¤ä¸ªä½¿ç”¨datanodeå±‚é¢æ§åˆ¶ï¼Œè¿™ä¸¤ä¸ªå‚æ•°ä¹Ÿéœ€è¦<strong>é‡å¯namenode</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.max-streams<br><br>apache hadoopé»˜è®¤å€¼æ˜¯2ï¼Œcdhé›†ç¾¤é»˜è®¤20ã€‚<br></code></pre></td></tr></table></figure>

<p>è¿™ä¸ªå‚æ•°å«ä¹‰æ˜¯æ§åˆ¶datanodeèŠ‚ç‚¹è¿›è¡Œæ•°æ®å¤åˆ¶çš„æœ€å¤§çº¿ç¨‹æ•°ï¼Œä»ä¸Šé¢æˆ‘ä»¬çŸ¥é“blockçš„å¤åˆ¶ä¼˜å…ˆçº§åˆ†æˆ5ç§ã€‚è¿™ä¸ªå‚æ•°æ§åˆ¶ä¸åŒ…å«æœ€é«˜ä¼˜å…ˆçº§çš„å—å¤åˆ¶ã€‚æŒ‡é™¤äº†æœ€é«˜ä¼˜å…ˆçº§ä»¥å¤–çš„å¤åˆ¶æµé™åˆ¶ã€‚</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">dfs.namenode.replication.max-streams-hard-limit<br><br>è¿™ä¸ªå€¼apache hadoopé»˜è®¤å€¼2ï¼Œcdhé›†ç¾¤é»˜è®¤å€¼40<br></code></pre></td></tr></table></figure>

<p>è¿™ä¸ªå‚æ•°å«ä¹‰æ˜¯æ§åˆ¶datanodeæ‰€æœ‰ä¼˜å…ˆçº§å—å¤åˆ¶çš„æµä¸ªæ•°ï¼ŒåŒ…å«æœ€é«˜ä¼˜å…ˆçº§ï¼›ä¸€èˆ¬ä¸Šé¢å’Œä¸Šé¢ä¸¤ä¸ªå‚æ•°äº’ç›¸çš„é…åˆä½¿ç”¨ã€‚</p>
<aside>
ğŸ’¡ å‰è€…å‚æ•°æ§åˆ¶datanodeæ¥å—ä»»åŠ¡çš„é¢‘ç‡ï¼Œåè€…è¿™ä¸¤ä¸ªå‚æ•°è¿›ä¸€æ­¥é™åˆ¶ DataNode ä¸€æ¬¡å®Œæˆçš„æœ€å¤§å¹¶è¡Œçº¿ç¨‹ç½‘ç»œä¼ è¾“é‡ã€‚å…·ä½“ä¸Šé¢å‚æ•°çš„å€¼è®¾å®šçš„å¤šå°‘ï¼Œå–å†³äºé›†ç¾¤çš„è§„æ¨¡å’Œé›†ç¾¤çš„é…ç½®ï¼Œä¸èƒ½åŒä¸€è€Œè®ºã€‚
ä¸€èˆ¬æ¥è¯´ä»å…¥å£æ§åˆ¶æ¯”è¾ƒç®€å•å®¹æ˜“äº›ã€‚æ¯”å¦‚è§„æ¨¡500å°é›†ç¾¤ï¼Œdfs.namenode.replication.work.multiplier.per.iteration=10ï¼Œé‚£ä¹ˆé›†ç¾¤ä¸€æ¬¡å¿ƒè·³åˆ†å‘5000ä¸ªblockçš„é‡ï¼Œå‡å¦‚é›†ç¾¤æ–‡ä»¶å­˜å‚¨å…¨éƒ¨æ‰“æ•£åœ¨500å°èŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹åŒæ—¶å¤åˆ¶10ä¸ªblockï¼ˆå®é™…ä¼šå› ä¸ºå‰¯æœ¬æç½®ç­–ç•¥ï¼Œæœºæ¶æ„ŸçŸ¥ç­‰å¹¶ä¸ä¼šæ‰€æœ‰çš„èŠ‚ç‚¹éƒ½å‚ä¸æ•°æ®å¤åˆ¶ï¼‰,æ¯ä¸ªblockå¤§å°128Mb,åˆ™æ¯ä¸ªèŠ‚ç‚¹çš„ç½‘ç»œè´Ÿè½½æ˜¯128*10/3=546Mb/sï¼Œé‚£è¿™æ—¶å€™ä½ å°±è¦çœ‹ä¸‹ç»“åˆå®é™…ä¼šä¸ä¼šæœ‰å¸¦å®½ç“¶é¢ˆï¼Œè¿™ä¹ˆå¤§çš„ç½‘ç»œIOä¼šä¸ä¼šå½±å“æ­£å¸¸ä»»åŠ¡çš„è®¡ç®—ï¼Œå¦‚æœæœ‰çš„è¯ï¼Œè¿™ä¸ªå€¼å°±è¦è°ƒå°ç‚¹ã€‚

</aside>

<h2 id="å¦‚ä½•å¿«é€Ÿä¸‹çº¿"><a href="#å¦‚ä½•å¿«é€Ÿä¸‹çº¿" class="headerlink" title="å¦‚ä½•å¿«é€Ÿä¸‹çº¿"></a>å¦‚ä½•å¿«é€Ÿä¸‹çº¿</h2><p>å¦‚ä½•è®©èŠ‚ç‚¹å¿«é€Ÿä¸‹çº¿çš„æœ¬è´¨å…¶å®å°±æ˜¯æé«˜å‰¯æœ¬çš„å¤åˆ¶é€Ÿåº¦ã€‚ä¸»è¦è¿˜æ˜¯ä¸Šé¢ä¸‰ä¸ªå‚æ•°æ§åˆ¶.ç¬¬ä¸€æ˜¯æ§åˆ¶namenodeä»»åŠ¡åˆ†å‘ï¼Œå…¶æ¬¡æ§åˆ¶datanodeå¤åˆ¶é€Ÿç‡ï¼Œå‰ææ˜¯ä¸å½±å“æ­£å¸¸ç”Ÿäº§ä»»åŠ¡çš„è¿›è¡Œã€‚é›†ç¾¤è§„æ¨¡è¶Šå°ï¼Œä¸‹çº¿çš„è¶Šæ…¢ï¼Œæ¯”å¦‚å› ä¸ºåˆ†å‘çš„æ€»æ•°ä¼šæ…¢å¾ˆå¤šã€‚</p>
<p>æ¯”å¦‚ä¸€ä¸ª500å°çš„èŠ‚ç‚¹ <code>dfs.namenode.replication.work.multiplier.per.iteration=10</code>ï¼Œä¸€ä¸ª50å°çš„èŠ‚ç‚¹è¿™ä¸ªå€¼è¦è®¾ç½®æˆ100ï¼Œä¸¤è€…namenodeä»»åŠ¡åˆ†å‘çš„é€Ÿåº¦æ‰å¯ä»¥ä¸€è‡´ã€‚å…·ä½“ç»“åˆå®é™…é›†ç¾¤è§„æ¨¡è®¾ç½®ã€‚</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json">&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">10</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.max-streams-hard-limit&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">20</span>&lt;/value&gt;<br>&lt;/property&gt;<br>&lt;property&gt;<br>    &lt;name&gt;dfs.namenode.replication.work.multiplier.per.iteration&lt;/name&gt;<br>    &lt;value&gt;<span class="hljs-number">5</span>&lt;/value&gt;<br>&lt;/property&gt;<br></code></pre></td></tr></table></figure>

<p>åœ¨æµ‹è¯•é›†ç¾¤ä¸­ï¼Œ15å°HDFSï¼Œå¹³å‡æ¯å°80k blocksï¼Œæ¯å°æ—¶èƒ½è¿ç§»63k blocksï¼Œæ¯”æœ€åˆçš„12kåŠ é€Ÿäº†5å€ã€‚</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json">## cdh é…ç½®<br>dfs.namenode.replication.work.multiplier.per.iteration=<span class="hljs-number">4</span><br>dfs.namenode.replication.max-streams=<span class="hljs-number">20</span>   <br>dfs.namenode.replication.max-streams-hard-limit=<span class="hljs-number">40</span><br></code></pre></td></tr></table></figure>

<h4 id="å½±å“"><a href="#å½±å“" class="headerlink" title="å½±å“"></a>å½±å“</h4><p>ä¼šæ˜¾è‘—æé«˜CPU Load, CPU IO Wait, Disk IO Waitç­‰èµ„æºä½¿ç”¨ç‡</p>
<h3 id="æºç åˆ†æ"><a href="#æºç åˆ†æ" class="headerlink" title="æºç åˆ†æ"></a>æºç åˆ†æ</h3><p>å½“<code>dfs.hosts.exclude</code>çš„åœ°å€å†™åˆ°confä¹‹åï¼Œå°±å¯ä»¥refreshNodesæ‹¿åˆ°exclude listå¹¶è¿›è¡Œæ“ä½œ</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Rereads conf to get hosts and exclude list file names.</span><br><span class="hljs-comment"> * Rereads the files to update the hosts and exclude lists.  It</span><br><span class="hljs-comment"> * checks if any of the hosts have changed states:</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">refreshNodes</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Configuration conf)</span> <span class="hljs-keyword">throws</span> IOException &#123;<br>  refreshHostsReader(conf);<br>  namesystem.writeLock();<br>  <span class="hljs-keyword">try</span> &#123;<br>    refreshDatanodes();<br>    countSoftwareVersions();<br>  &#125; <span class="hljs-keyword">finally</span> &#123;<br>    namesystem.writeUnlock();<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>é€šè¿‡<code>dfs.exclude</code>è¯»åˆ°nodeåœ°å€ï¼Œç„¶åæ ‡è®°ä¸ºdecommissionï¼Œå¹¶ä½¿ç”¨monitorå»tracking Node</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs bash">public void startDecommission(DatanodeDescriptor node) &#123;<br>  <span class="hljs-keyword">if</span> (!node.isDecommissionInProgress() &amp;&amp; !node.isDecommissioned()) &#123;<br>    // Update DN stats maintained by HeartbeatManager<br>    hbManager.startDecommission(node);<br>    // hbManager.startDecommission will <span class="hljs-built_in">set</span> dead node to decommissioned.<br>    <span class="hljs-keyword">if</span> (node.isDecommissionInProgress()) &#123;<br>      <span class="hljs-keyword">for</span> (DatanodeStorageInfo storage : node.getStorageInfos()) &#123;<br>        LOG.info(<span class="hljs-string">&quot;Starting decommission of &#123;&#125; &#123;&#125; with &#123;&#125; blocks&quot;</span>,<br>            node, storage, storage.numBlocks());<br>      &#125;<br>      node.getLeavingServiceStatus().setStartTime(monotonicNow());<br>		// å¼€å§‹ç›‘æ§è¿™ä¸ªnodeï¼Œå¹¶æŠŠnodeåŠ å…¥pendingNodesé‡Œé¢<br>      monitor.startTrackingNode(node);<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    LOG.trace(<span class="hljs-string">&quot;startDecommission: Node &#123;&#125; in &#123;&#125;, nothing to do.&quot;</span>,<br>        node, node.getAdminState());<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>åœ¨decommissionä¹‹å‰ä¼šå…ˆæŠŠé›†ç¾¤çš„statsè¿›è¡Œé¢„å‡ï¼Œæ¯”å¦‚<code>capacityUsed</code>å’Œ<br><code>capacityTotal</code> ç­‰ç­‰</p>
<p>monitorçš„run()ä¸­ä¼šè°ƒç”¨processPendingNodes()ï¼Œä»<code>pendingNodes</code>ä¸­æ‹¿å‡ºèŠ‚ç‚¹å¹¶è¿›è¡Œdecommission</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * Move any pending nodes into outOfServiceNodeBlocks to initiate the</span><br><span class="hljs-comment"> * decommission or maintenance mode process.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * This method must be executed under the namenode write lock to prevent</span><br><span class="hljs-comment"> * the pendingNodes list from being modified externally.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">processPendingNodes</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">while</span> (!pendingNodes.isEmpty() &amp;&amp;<br>      (maxConcurrentTrackedNodes == <span class="hljs-number">0</span> ||<br>          outOfServiceNodeBlocks.size() &lt; maxConcurrentTrackedNodes)) &#123;<br>    outOfServiceNodeBlocks.put(pendingNodes.poll(), <span class="hljs-literal">null</span>);<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p> å½“æ‹¿åˆ°nodesä¹‹åä¼šè°ƒç”¨check()æ–¹æ³•ï¼Œä¼šè·å–è¿™äº›nodesçš„blockä¿¡æ¯å¹¶å¤„ç†è¿™äº›pendingReplication Blocks</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">check</span><span class="hljs-params">()</span> &#123;<br>  <span class="hljs-keyword">final</span> List&lt;DatanodeDescriptor&gt; toRemove = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>&lt;&gt;();<br><br>  <span class="hljs-keyword">if</span> (outOfServiceNodeBlocks.size() == <span class="hljs-number">0</span>) &#123;<br>    <span class="hljs-comment">// No nodes currently being tracked so simply return</span><br>    <span class="hljs-keyword">return</span>;<br>  &#125;<br><br>  <span class="hljs-comment">// Check if there are any pending nodes to process, ie those where the</span><br>  <span class="hljs-comment">// storage has not been scanned yet. For all which are pending, scan</span><br>  <span class="hljs-comment">// the storage and load the under-replicated block list into</span><br>  <span class="hljs-comment">// outOfServiceNodeBlocks. As this does not modify any external structures</span><br>  <span class="hljs-comment">// it can be done under the namenode *read* lock, and the lock can be</span><br>  <span class="hljs-comment">// dropped between each storage on each node.</span><br>  <span class="hljs-comment">//</span><br>  <span class="hljs-comment">// TODO - This is an expensive call, depending on how many nodes are</span><br>  <span class="hljs-comment">//        to be processed, but it requires only the read lock and it will</span><br>  <span class="hljs-comment">//        be dropped and re-taken frequently. We may want to throttle this</span><br>  <span class="hljs-comment">//        to process only a few nodes per iteration.</span><br>  outOfServiceNodeBlocks.keySet()<br>      .stream()<br>      .filter(n -&gt; outOfServiceNodeBlocks.get(n) == <span class="hljs-literal">null</span>)<br>      .forEach(n -&gt; scanDatanodeStorage(n, <span class="hljs-literal">true</span>));<br><br>  processMaintenanceNodes();<br>  <span class="hljs-comment">// First check the pending replication list and remove any blocks</span><br>  <span class="hljs-comment">// which are now replicated OK. This list is constrained in size so this</span><br>  <span class="hljs-comment">// call should not be overly expensive.</span><br>  processPendingReplication();<br><br>  <span class="hljs-comment">// Now move a limited number of blocks to pending</span><br>  moveBlocksToPending();<br><br>  <span class="hljs-comment">// Check if any nodes have reached zero blocks and also update the stats</span><br>  <span class="hljs-comment">// exposed via JMX for all nodes still being processed.</span><br>  checkForCompletedNodes(toRemove);<br><br>  <span class="hljs-comment">// Finally move the nodes to their final state if they are ready.</span><br>  processCompletedNodes(toRemove);<br>&#125;<br></code></pre></td></tr></table></figure>

<ol>
<li>processPendingReplication()æ–¹æ³•ä¸­ä¼šè°ƒç”¨isBlockReplicatedOk()æ–¹æ³•ï¼ˆæ ¸å¿ƒï¼‰ä¼šåˆ¤æ–­blockæ˜¯å¦éœ€è¦reconstructionï¼Œå¹¶æŠŠä¿¡æ¯æ”¾åˆ°<code>blockManager</code>é‡Œçš„<code>*replication queue*</code></li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">blockManager.neededReconstruction.add(block,<br>    liveReplicas, num.readOnlyReplicas(),<br>    num.outOfServiceReplicas(),<br>    blockManager.getExpectedRedundancyNum(block));<br></code></pre></td></tr></table></figure>

<ol>
<li>moveBlocksToPending()æ–¹æ³•ä¼šåˆ¤æ–­queueçš„é•¿åº¦å’Œpending replicationçš„limitï¼Œç„¶åä¸ºæ¯ä¸€ä¸ªéœ€è¦maintenanceæˆ–è€…decommissionçš„nodeåˆ›å»ºä¸€ä¸ªblockè¿­ä»£å™¨ï¼Œç„¶åæ¯ä¸ªblockéƒ½ä¼šç»§ç»­è°ƒç”¨ä¸Šé¢æåˆ°çš„isBlockReplicatedOk()æ–¹æ³•ï¼Œç›´åˆ°è¾¾åˆ°blockå¤åˆ¶çš„é™åˆ¶å°±åœæ­¢å¹¶é€€å‡ºå¾ªç¯</li>
</ol>
<p>moveBlocksToPending()æ–¹æ³•ä¸­æœ‰ä¸€æ®µå…³äºé”çš„ä»£ç å¾ˆæœ‰æ„æ€</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java">Iterator&lt;DatanodeDescriptor&gt; nodeIter =<br>    Iterables.cycle(iterators.keySet()).iterator();<br><span class="hljs-keyword">while</span> (nodeIter.hasNext()) &#123;<br>  <span class="hljs-comment">// Cycle through each node with blocks which still need processed</span><br>  <span class="hljs-type">DatanodeDescriptor</span> <span class="hljs-variable">dn</span> <span class="hljs-operator">=</span> nodeIter.next();<br>  Iterator&lt;BlockInfo&gt; blockIt = iterators.get(dn);<br>  <span class="hljs-keyword">while</span> (blockIt.hasNext()) &#123;<br>    <span class="hljs-comment">// Process the blocks for the node until we find one that needs</span><br>    <span class="hljs-comment">// replication</span><br>    <span class="hljs-keyword">if</span> (blocksProcessed &gt;= blocksPerLock) &#123;<br>      blocksProcessed = <span class="hljs-number">0</span>;<br>      namesystem.writeUnlock();<br>      namesystem.writeLock();<br>    &#125;<br>    blocksProcessed++;<br>    <span class="hljs-keyword">if</span> (nextBlockAddedToPending(blockIt, dn)) &#123;<br>      <span class="hljs-comment">// Exit the inner &quot;block&quot; loop so an iterator for the next datanode</span><br>      <span class="hljs-comment">// is used for the next block.</span><br>      pendingCount++;<br>      <span class="hljs-keyword">break</span>;<br>    &#125;<br>  &#125;<br></code></pre></td></tr></table></figure>

<p>å®ƒåœ¨é‡Šæ”¾å†™é”ä¹‹åç«‹åˆ»åˆç”³è¯·å†™é”ï¼Œè¿™æ˜¯å› ä¸º <strong><code>blocksProcessed</code></strong> å˜é‡ç”¨äºè¿½è¸ªå·²å¤„ç†çš„å—æ•°é‡ã€‚å½“å¤„ç†çš„å—æ•°é‡è¾¾åˆ°é¢„å®šçš„é˜ˆå€¼ <strong><code>blocksPerLock</code></strong> æ—¶ï¼Œé€šè¿‡é‡Šæ”¾å½“å‰çš„å†™é”å¹¶å†æ¬¡è·å–å†™é”ï¼Œå¯ä»¥è®©å…¶ä»–ç­‰å¾…å†™é”çš„çº¿ç¨‹æœ‰æœºä¼šæ‰§è¡Œã€‚è¿™æœ‰åŠ©äºé¿å…é•¿æ—¶é—´æŒæœ‰å†™é”è€Œå¯¼è‡´å…¶ä»–çº¿ç¨‹è¢«é˜»å¡çš„æƒ…å†µå‘ç”Ÿï¼Œä»è€Œæé«˜å¹¶å‘æ€§èƒ½ã€‚</p>
<aside>
ğŸ’¡

<p>ä¸ºä»€ä¹ˆcheckè¿™ä¸ªå‡½æ•°è¦å…ˆè°ƒç”¨processPendingReplicationç„¶åè°ƒç”¨moveBlocksToPendingï¼Ÿä¸èƒ½åªè°ƒç”¨ä¸€ä¸ªå—ï¼Ÿ</p>
<p>åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯ä»¥åªè°ƒç”¨ä¸€ä¸ªå‡½æ•°æ¥å¤„ç†å—çš„å¤åˆ¶çŠ¶æ€ï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè°ƒç”¨ä¸¤ä¸ªå‡½æ•°å¯èƒ½æ˜¯å¿…è¦çš„ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸ºä»€ä¹ˆåœ¨ä¸€äº›æƒ…å†µä¸‹éœ€è¦è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°ï¼š</p>
<ol>
<li><code>processPendingReplication</code>ï¼š<ul>
<li>è¿™ä¸ªå‡½æ•°çš„ä¸»è¦ä»»åŠ¡æ˜¯å¤„ç†å½“å‰å¤„äºâ€œpending replicationâ€çŠ¶æ€çš„å—ï¼Œç¡®ä¿å®ƒä»¬çš„å¤åˆ¶æ•°é‡è¾¾åˆ°æ‰€éœ€çš„å‰¯æœ¬æ•°ã€‚å®ƒé€šå¸¸æ˜¯å‘¨æœŸæ€§åœ°ç”±è°ƒåº¦ç¨‹åºè°ƒç”¨çš„ï¼Œä»¥ç¡®ä¿é›†ç¾¤ä¸­çš„å—ä¿æŒè¶³å¤Ÿçš„å†—ä½™åº¦ã€‚</li>
<li>å½“è°ƒç”¨è¿™ä¸ªå‡½æ•°æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥å½“å‰å“ªäº›å—å¤„äºæŒ‚èµ·çŠ¶æ€ï¼Œå¹¶å°è¯•å¯åŠ¨å¤åˆ¶ä»»åŠ¡æ¥å¤åˆ¶è¿™äº›å—ã€‚</li>
</ul>
</li>
<li><code>moveBlocksToPending</code>ï¼š<ul>
<li>è¿™ä¸ªå‡½æ•°çš„ä¸»è¦ä»»åŠ¡æ˜¯åœ¨ç‰¹å®šçš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚èŠ‚ç‚¹è¿›å…¥ç»´æŠ¤æ¨¡å¼æˆ–è€…ä¸‹çº¿æ—¶ï¼Œå°†ç›¸å…³å—ç§»åŠ¨åˆ°â€œpending replicationâ€çŠ¶æ€çš„é˜Ÿåˆ—ä¸­ï¼Œä»¥ç­‰å¾…åç»­çš„å¤åˆ¶ä»»åŠ¡å¤„ç†ã€‚</li>
<li>å½“è°ƒç”¨è¿™ä¸ªå‡½æ•°æ—¶ï¼Œå®ƒä¼šæ£€æŸ¥å½“å‰æ˜¯å¦æœ‰èŠ‚ç‚¹å¤„äºç»´æŠ¤æ¨¡å¼æˆ–è€…ä¸‹çº¿ï¼Œç„¶åå°†ç›¸å…³å—æ·»åŠ åˆ°ç­‰å¾…å¤åˆ¶çš„é˜Ÿåˆ—ä¸­ã€‚</li>
</ul>
</li>
</ol>
<p>ä¸ºä»€ä¹ˆéœ€è¦åŒæ—¶è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°å‘¢ï¼Ÿå› ä¸ºå®ƒä»¬å¤„ç†çš„é—®é¢˜ä¸å®Œå…¨ä¸€æ ·ï¼š</p>
<ul>
<li><strong><code>processPendingReplication</code></strong> ä¸»è¦å…³æ³¨å½“å‰æ­£åœ¨æŒ‚èµ·çš„å—ï¼Œè€Œ <strong><code>moveBlocksToPending</code></strong> ä¸»è¦å…³æ³¨äºæ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€å˜åŒ–åéœ€è¦è¿›è¡Œçš„å—å¤„ç†ã€‚</li>
<li>åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯èƒ½ä¼šå‡ºç°æ–°çš„å—éœ€è¦å¤åˆ¶ï¼Œæˆ–è€…ç”±äºèŠ‚ç‚¹çŠ¶æ€å˜åŒ–è€Œéœ€è¦ç§»åŠ¨ä¸€äº›å—åˆ°ç­‰å¾…å¤åˆ¶çš„é˜Ÿåˆ—ä¸­ï¼Œæ‰€ä»¥åŒæ—¶è°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°å¯ä»¥ç¡®ä¿å¤„ç†å—å¤åˆ¶çŠ¶æ€çš„å…¨é¢æ€§å’ŒåŠæ—¶æ€§ã€‚</li>
</ul>
</aside>

<ol>
<li>checkForCompletedNodesæ–¹æ³•ä¼šéå†æ£€æŸ¥èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œå¦‚æœblockçš„è¿ç§»ä»»åŠ¡å®Œæˆäº†çš„è¯ï¼Œå°±æŠŠnodeæ·»åŠ åˆ°toRemoveçš„listä¸­</li>
<li>processCompletedNodesæ–¹æ³•æ‹¿åˆ°toRemoveçš„listï¼Œéå†æ£€æŸ¥ç„¶åè®¾ç½®çŠ¶æ€ï¼Œæ¯”å¦‚æ”¹ä¸ºdecommissionedï¼Œå¹¶ä» <strong><code>outOfServiceNodeBlocks</code></strong> å’Œ <strong><code>pendingRep</code></strong> ä¸­ç§»é™¤</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/CodeDive/" class="print-no-link">#CodeDive</a>
      
        <a href="/tags/Hadoop/" class="print-no-link">#Hadoop</a>
      
        <a href="/tags/Architecture/" class="print-no-link">#Architecture</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>HDFS Decomission Codes and Intros</div>
      <div>https://garychow-lgtm.github.io/2024/06/17/HDFS-Decomission-Codes-and-Introduction/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Gary Chow (Yimin Cao)</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>June 17, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/06/25/Kubernetes-FailedScheduling-Debug/" title="Kubernetes FailedScheduling Debug">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Kubernetes FailedScheduling Debug</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ï¼Œå°†å®ƒä¿æŒåœ¨æœ€åº•éƒ¨ -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
